
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Chapter 19: Cognitive Neuroscience and Deep Learning &#8212; The Neuroscience of AI</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'part6/ch19_cognitive_neuro_dl';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="canonical" href="https://neuroai-handbook.github.io/part6/ch19_cognitive_neuro_dl.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Chapter 20: Case Studies in NeuroAI" href="ch20_case_studies.html" />
    <link rel="prev" title="Chapter 18: Neuromorphic Computing" href="ch18_neuromorphic_computing.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/nai.png" class="logo__image only-light" alt="The Neuroscience of AI - Home"/>
    <script>document.write(`<img src="../_static/nai.png" class="logo__image only-dark" alt="The Neuroscience of AI - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    The Neuroscience of AI
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Cover</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../cover.html">Cover</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Front Matter</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../frontmatter/copyright.html">Copyright</a></li>
<li class="toctree-l1"><a class="reference internal" href="../frontmatter/acknowledgments.html">Acknowledgments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../frontmatter/about.html">About This Book</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part I · Brains &amp; Inspiration</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../part1/ch01_intro.html">Chapter 1: Introduction to Neuroscience ↔ AI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part1/ch02_neuro_foundations.html">Chapter 2: Neuroscience Foundations for AI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part1/ch03_spatial_navigation.html">Chapter 3: Spatial Navigation – Place &amp; Grid Cells</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part1/ch04_perception_pipeline.html">Chapter 4: Perception Pipeline – Visual Cortex → CNNs</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part II · Brains Meet Math &amp; Data</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../part2/ch05_brain_networks.html">Chapter 5: Default-Mode vs Executive Control Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part2/ch06_neurostimulation.html">Chapter 6: Neurostimulation &amp; Plasticity</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part2/ch07_information_theory.html">Chapter 7: Information Theory Essentials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part2/ch08_data_science_pipeline.html">Chapter 8: Data-Science Pipeline in Python</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part III · Learning Machines</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../part3/ch09_ml_foundations.html">Chapter 9: Classical Machine-Learning Foundations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part3/ch10_deep_learning.html">Chapter 10: Deep Learning: Training &amp; Optimisation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part3/ch11_sequence_models.html">Chapter 11: Sequence Models: RNN → Attention → Transformer</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part IV · Frontier Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../part4/ch12_large_language_models.html">Chapter 12: Large Language Models &amp; Fine-Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part4/ch13_multimodal_models.html">Chapter 13: Multimodal &amp; Diffusion Models</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part V · Ethics &amp; Futures</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../part5/ch15_ethical_ai.html">Chapter 15: Ethical AI - Considerations for NeuroAI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part5/ch16_future_directions.html">Chapter 16: Where Next for Neuro-AI?</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part VI · Advanced Applications</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="ch17_bci_human_ai_interfaces.html">Chapter 17: Brain-Computer Interfaces and Human-AI Interaction</a></li>
<li class="toctree-l1"><a class="reference internal" href="ch18_neuromorphic_computing.html">Chapter 18: Neuromorphic Computing</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Chapter 19: Cognitive Neuroscience and Deep Learning</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="ch20_case_studies.html">Case Studies in NeuroAI</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="ch20_interactive.html">Interactive NeuroAI Case Studies</a></li>
<li class="toctree-l2"><a class="reference internal" href="jupyter_ai_demo.html">AI-Assisted Learning with Jupyter AI</a></li>
<li class="toctree-l2"><a class="reference internal" href="rise_slides_demo.html">Creating Presentations with RISE</a></li>


</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="ch21_ai_for_neuro_discovery.html">Chapter 21: AI for Neuroscience Discovery</a></li>
<li class="toctree-l1"><a class="reference internal" href="ch22_embodied_ai_robotics.html">Chapter 22: Embodied AI and Robotics</a></li>
<li class="toctree-l1"><a class="reference internal" href="ch23_lifelong_learning.html">Chapter 23: Lifelong Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="ch24_quantum_computing_neuroai.html">Chapter 24: Quantum Computing and NeuroAI</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Appendices</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../appendices/glossary.html">Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../appendices/math_python_refresher.html">Appendix A: Math &amp; Python Mini-Refresher</a></li>
<li class="toctree-l1"><a class="reference internal" href="../appendices/dataset_catalogue.html">Appendix B: Dataset Catalogue</a></li>
<li class="toctree-l1"><a class="reference internal" href="../appendices/colab_setup.html">Appendix C: Google Colab Setup for NeuroAI</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/edit/master/docs/part6/ch19_cognitive_neuro_dl.md" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fpart6/ch19_cognitive_neuro_dl.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/part6/ch19_cognitive_neuro_dl.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Chapter 19: Cognitive Neuroscience and Deep Learning</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#chapter-goals">Chapter Goals</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-the-convergence-of-minds-and-machines">19.1 Introduction: The Convergence of Minds and Machines</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cognitive-science-principles-in-deep-learning">19.2 Cognitive Science Principles in Deep Learning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#attention-and-working-memory">19.2.1 Attention and Working Memory</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hierarchical-processing-and-compositionality">19.2.2 Hierarchical Processing and Compositionality</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#predictive-coding-and-generative-models">19.2.3 Predictive Coding and Generative Models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#embodied-cognition-and-active-learning">19.2.4 Embodied Cognition and Active Learning</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cognitive-constraints-in-deep-learning">19.3 Cognitive Constraints in Deep Learning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#inductive-biases-from-cognitive-science">19.3.1 Inductive Biases from Cognitive Science</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#neural-architecture-constraints">19.3.2 Neural Architecture Constraints</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cognitively-plausible-learning-mechanisms">19.3.3 Cognitively-Plausible Learning Mechanisms</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deep-learning-models-as-theories-of-cognition">19.4 Deep Learning Models as Theories of Cognition</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-deep-learning-to-test-cognitive-theories">19.4.1 Using Deep Learning to Test Cognitive Theories</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#case-studies-in-cognitive-modeling">19.4.2 Case Studies in Cognitive Modeling</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#comparing-model-behavior-to-human-behavior">19.4.3 Comparing Model Behavior to Human Behavior</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#neural-representation-comparison-methods">19.5 Neural Representation Comparison Methods</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#representational-similarity-analysis">19.5.1 Representational Similarity Analysis</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#neural-encoding-and-decoding-models">19.5.2 Neural Encoding and Decoding Models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#canonical-correlation-analysis">19.5.3 Canonical Correlation Analysis</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-impact-of-deep-learning-on-cognitive-neuroscience">19.6 The Impact of Deep Learning on Cognitive Neuroscience</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#new-frameworks-for-understanding-brain-function">19.6.1 New Frameworks for Understanding Brain Function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tools-for-neural-data-analysis">19.6.2 Tools for Neural Data Analysis</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generating-new-hypotheses">19.6.3 Generating New Hypotheses</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#practical-exercise-comparing-deep-networks-and-brain-representations">19.7 Practical Exercise: Comparing Deep Networks and Brain Representations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#chapter-take-aways">19.8 Chapter Take-aways</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#further-reading">19.9 Further Reading</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="chapter-19-cognitive-neuroscience-and-deep-learning">
<h1>Chapter 19: Cognitive Neuroscience and Deep Learning<a class="headerlink" href="#chapter-19-cognitive-neuroscience-and-deep-learning" title="Link to this heading">#</a></h1>
<div style="page-break-before:always;"></div>
<section id="chapter-goals">
<h2>Chapter Goals<a class="headerlink" href="#chapter-goals" title="Link to this heading">#</a></h2>
<p>After completing this chapter, you will be able to:</p>
<ul class="simple">
<li><p>Understand the bidirectional relationship between cognitive neuroscience and deep learning</p></li>
<li><p>Identify key cognitive neuroscience principles that have inspired deep learning architectures</p></li>
<li><p>Apply cognitive constraints to improve deep learning model performance and interpretability</p></li>
<li><p>Analyze deep learning models as computational models of cognition</p></li>
<li><p>Explain how deep learning has contributed to our understanding of brain function</p></li>
<li><p>Implement methods for comparing neural and artificial network representations</p></li>
<li><p>Design experiments that bridge cognitive neuroscience and deep learning</p></li>
</ul>
</section>
<section id="introduction-the-convergence-of-minds-and-machines">
<h2>19.1 Introduction: The Convergence of Minds and Machines<a class="headerlink" href="#introduction-the-convergence-of-minds-and-machines" title="Link to this heading">#</a></h2>
<p>Cognitive neuroscience and deep learning represent two powerful approaches to understanding intelligence—one through the study of biological brains, and the other through the development of artificial neural systems. While these fields developed largely independently, they have begun to converge in recent years, creating a rich interdisciplinary area that promises to advance both our understanding of natural intelligence and our ability to create artificial intelligence.</p>
<p>This chapter explores this bidirectional relationship: how cognitive neuroscience inspires deep learning architectures and strategies, and how deep learning models serve as computational models of cognition that generate testable predictions about brain function.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Conceptual overview of the relationship between cognitive neuroscience and deep learning</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">matplotlib_venn</span><span class="w"> </span><span class="kn">import</span> <span class="n">venn2</span>

<span class="k">def</span><span class="w"> </span><span class="nf">visualize_field_relationship</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Visualize the bidirectional relationship between cognitive neuroscience and deep learning</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    
    <span class="c1"># Create a Venn diagram showing the overlap</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">venn2</span><span class="p">(</span><span class="n">subsets</span><span class="o">=</span><span class="p">(</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">),</span> <span class="n">set_labels</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;Cognitive Neuroscience&#39;</span><span class="p">,</span> <span class="s1">&#39;Deep Learning&#39;</span><span class="p">),</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
    
    <span class="c1"># Change colors and alpha</span>
    <span class="n">v</span><span class="o">.</span><span class="n">get_patch_by_id</span><span class="p">(</span><span class="s1">&#39;10&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">set_color</span><span class="p">(</span><span class="s1">&#39;lightblue&#39;</span><span class="p">)</span>
    <span class="n">v</span><span class="o">.</span><span class="n">get_patch_by_id</span><span class="p">(</span><span class="s1">&#39;01&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">set_color</span><span class="p">(</span><span class="s1">&#39;lightgreen&#39;</span><span class="p">)</span>
    <span class="n">v</span><span class="o">.</span><span class="n">get_patch_by_id</span><span class="p">(</span><span class="s1">&#39;11&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">set_color</span><span class="p">(</span><span class="s1">&#39;orange&#39;</span><span class="p">)</span>
    
    <span class="n">v</span><span class="o">.</span><span class="n">get_patch_by_id</span><span class="p">(</span><span class="s1">&#39;10&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">set_alpha</span><span class="p">(</span><span class="mf">0.7</span><span class="p">)</span>
    <span class="n">v</span><span class="o">.</span><span class="n">get_patch_by_id</span><span class="p">(</span><span class="s1">&#39;01&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">set_alpha</span><span class="p">(</span><span class="mf">0.7</span><span class="p">)</span>
    <span class="n">v</span><span class="o">.</span><span class="n">get_patch_by_id</span><span class="p">(</span><span class="s1">&#39;11&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">set_alpha</span><span class="p">(</span><span class="mf">0.7</span><span class="p">)</span>
    
    <span class="c1"># Add bidirectional arrow to show mutual influence</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">),</span> <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">),</span>
                 <span class="n">arrowprops</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">arrowstyle</span><span class="o">=</span><span class="s1">&#39;&lt;-&gt;&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
    
    <span class="c1"># Add examples of cross-disciplinary concepts in the overlap</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.55</span><span class="p">,</span> <span class="s2">&quot;Shared Concepts:&quot;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="s2">&quot;• Hierarchical processing&quot;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.45</span><span class="p">,</span> <span class="s2">&quot;• Distributed representations&quot;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="s2">&quot;• Attention mechanisms&quot;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="s2">&quot;• Predictive coding&quot;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
    
    <span class="c1"># Add examples specific to each field</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="s2">&quot;• Neural circuits&quot;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.65</span><span class="p">,</span> <span class="s2">&quot;• Cognitive processes&quot;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="s2">&quot;• Brain imaging&quot;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
    
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="s2">&quot;• Backpropagation&quot;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.65</span><span class="p">,</span> <span class="s2">&quot;• Gradient descent&quot;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="s2">&quot;• Layer architectures&quot;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
    
    <span class="c1"># Set title</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;The Bidirectional Relationship Between Cognitive Neuroscience and Deep Learning&#39;</span><span class="p">,</span> 
                 <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<div style="page-break-before:always;"></div>
</section>
<section id="cognitive-science-principles-in-deep-learning">
<h2>19.2 Cognitive Science Principles in Deep Learning<a class="headerlink" href="#cognitive-science-principles-in-deep-learning" title="Link to this heading">#</a></h2>
<section id="attention-and-working-memory">
<h3>19.2.1 Attention and Working Memory<a class="headerlink" href="#attention-and-working-memory" title="Link to this heading">#</a></h3>
<p>The human attention system allows us to selectively focus on relevant information while filtering out distractions. In deep learning, attention mechanisms have revolutionized performance across domains:</p>
<ul class="simple">
<li><p><strong>Visual attention</strong>: Mechanisms that weight the importance of different regions in an image</p></li>
<li><p><strong>Self-attention</strong>: Found in transformers, allows models to weigh the importance of different elements in a sequence</p></li>
<li><p><strong>Cross-attention</strong>: Allows models to relate elements from different modalities or sequences</p></li>
</ul>
<p>Working memory—our ability to temporarily maintain and manipulate information—has also influenced deep learning through:</p>
<ul class="simple">
<li><p><strong>Memory networks</strong>: Architectures with explicit memory components</p></li>
<li><p><strong>Gating mechanisms</strong>: Control the flow of information through the network</p></li>
<li><p><strong>Meta-learning</strong>: Learning to rapidly adapt to new tasks by maintaining task-relevant information</p></li>
</ul>
</section>
<section id="hierarchical-processing-and-compositionality">
<h3>19.2.2 Hierarchical Processing and Compositionality<a class="headerlink" href="#hierarchical-processing-and-compositionality" title="Link to this heading">#</a></h3>
<p>The brain processes information through hierarchical structures, from simple features to complex concepts. This principle has inspired deep learning architectures:</p>
<ul class="simple">
<li><p><strong>Convolutional neural networks</strong>: Hierarchical visual processing from edges to objects</p></li>
<li><p><strong>Hierarchical reinforcement learning</strong>: Breaking complex tasks into manageable sub-goals</p></li>
<li><p><strong>Compositional generalization</strong>: Combining learned components in novel ways</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">tensorflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tf</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.layers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Conv2D</span><span class="p">,</span> <span class="n">MaxPooling2D</span><span class="p">,</span> <span class="n">Flatten</span>

<span class="k">def</span><span class="w"> </span><span class="nf">create_hierarchical_cnn</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a CNN with hierarchical processing inspired by the visual cortex</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">    --------</span>
<span class="sd">    model : tf.keras.Model</span>
<span class="sd">        A CNN with hierarchical processing</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">([</span>
        <span class="c1"># Input layer (specify for clarity)</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span>
        
        <span class="c1"># Stage 1: Low-level feature extraction (analogous to V1)</span>
        <span class="c1"># Detect edges and simple contours</span>
        <span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;low_level_features&#39;</span><span class="p">),</span>
        <span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">),</span>
        <span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>
        
        <span class="c1"># Stage 2: Mid-level feature extraction (analogous to V2/V4)</span>
        <span class="c1"># Detect shapes and textures</span>
        <span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;mid_level_features&#39;</span><span class="p">),</span>
        <span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">),</span>
        <span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>
        
        <span class="c1"># Stage 3: Higher-level feature extraction (analogous to posterior IT)</span>
        <span class="c1"># Detect parts of objects</span>
        <span class="n">Conv2D</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;high_level_features&#39;</span><span class="p">),</span>
        <span class="n">Conv2D</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">),</span>
        <span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>
        
        <span class="c1"># Stage 4: Object-level representation (analogous to anterior IT)</span>
        <span class="c1"># Detect whole objects</span>
        <span class="n">Conv2D</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;object_level_features&#39;</span><span class="p">),</span>
        <span class="n">Conv2D</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">),</span>
        <span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>
        
        <span class="c1"># Flatten and dense layers (analogous to prefrontal cortex)</span>
        <span class="c1"># Abstract categorization and decision making</span>
        <span class="n">Flatten</span><span class="p">(),</span>
        <span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;abstract_features&#39;</span><span class="p">),</span>
        <span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;classification&#39;</span><span class="p">)</span>
    <span class="p">])</span>
    
    <span class="k">return</span> <span class="n">model</span>

<span class="k">def</span><span class="w"> </span><span class="nf">visualize_activations</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">example_image</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Visualize activations at different stages of the hierarchical network</span>
<span class="sd">    </span>
<span class="sd">    Parameters:</span>
<span class="sd">    -----------</span>
<span class="sd">    model : tf.keras.Model</span>
<span class="sd">        The hierarchical CNN model</span>
<span class="sd">    example_image : numpy.ndarray</span>
<span class="sd">        An example image to visualize activations for</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># This would extract activations from different layers of the network</span>
    <span class="c1"># In a real implementation, you would use a model to extract these</span>
    <span class="c1"># Here we&#39;ll just sketch the concept</span>
    
    <span class="n">layer_names</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s1">&#39;low_level_features&#39;</span><span class="p">,</span> 
        <span class="s1">&#39;mid_level_features&#39;</span><span class="p">,</span>
        <span class="s1">&#39;high_level_features&#39;</span><span class="p">,</span>
        <span class="s1">&#39;object_level_features&#39;</span>
    <span class="p">]</span>
    
    <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer_names</span><span class="p">),</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
    
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">layer_name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">layer_names</span><span class="p">):</span>
        <span class="c1"># In real code, this would extract actual activations</span>
        <span class="c1"># feature_map = get_layer_activation(model, layer_name, example_image)</span>
        
        <span class="c1"># For demonstration, we&#39;ll create mock activations</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># Low-level (edges)</span>
            <span class="n">feature_map</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">56</span><span class="p">,</span> <span class="mi">56</span><span class="p">)</span>  <span class="c1"># Simplified for visualization</span>
        <span class="k">elif</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># Mid-level (textures)</span>
            <span class="n">feature_map</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>  <span class="c1"># High-level (parts)</span>
            <span class="n">feature_map</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">14</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># Object level</span>
            <span class="n">feature_map</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
        
        <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">feature_map</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">layer_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39; &#39;</span><span class="p">)</span><span class="o">.</span><span class="n">title</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="predictive-coding-and-generative-models">
<h3>19.2.3 Predictive Coding and Generative Models<a class="headerlink" href="#predictive-coding-and-generative-models" title="Link to this heading">#</a></h3>
<p>A fundamental principle in cognitive neuroscience is that the brain continuously predicts future inputs, with perception arising from the integration of these predictions with sensory data. This has influenced deep learning through:</p>
<ul class="simple">
<li><p><strong>Generative models</strong>: Systems that learn to generate likely inputs</p></li>
<li><p><strong>Self-supervised learning</strong>: Learning from prediction tasks without explicit labels</p></li>
<li><p><strong>Contrastive predictive coding</strong>: Learning representations by predicting future states</p></li>
<li><p><strong>Variational autoencoders</strong>: Learning latent representations that capture data distribution</p></li>
</ul>
</section>
<section id="embodied-cognition-and-active-learning">
<h3>19.2.4 Embodied Cognition and Active Learning<a class="headerlink" href="#embodied-cognition-and-active-learning" title="Link to this heading">#</a></h3>
<p>Cognitive science increasingly emphasizes that intelligence is embodied—developed through physical interaction with the environment. This has influenced AI through:</p>
<ul class="simple">
<li><p><strong>Reinforcement learning</strong>: Agents learn from interactions with environments</p></li>
<li><p><strong>Active learning</strong>: Systems actively select what data to learn from</p></li>
<li><p><strong>Curriculum learning</strong>: Gradually increasing task difficulty during training</p></li>
<li><p><strong>Curiosity-driven learning</strong>: Using prediction errors to drive exploration</p></li>
</ul>
</section>
</section>
<section id="cognitive-constraints-in-deep-learning">
<h2>19.3 Cognitive Constraints in Deep Learning<a class="headerlink" href="#cognitive-constraints-in-deep-learning" title="Link to this heading">#</a></h2>
<section id="inductive-biases-from-cognitive-science">
<h3>19.3.1 Inductive Biases from Cognitive Science<a class="headerlink" href="#inductive-biases-from-cognitive-science" title="Link to this heading">#</a></h3>
<p>Human cognition demonstrates numerous inductive biases—prior assumptions that guide learning. Incorporating these biases into deep learning models can improve performance:</p>
<ul class="simple">
<li><p><strong>Object-centric representations</strong>: Humans naturally parse scenes into discrete objects</p></li>
<li><p><strong>Causal reasoning</strong>: Humans infer and reason about cause-and-effect relationships</p></li>
<li><p><strong>Compositional structure</strong>: Humans represent concepts as combinations of simpler parts</p></li>
<li><p><strong>Few-shot learning</strong>: Humans can learn from very few examples</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>

<span class="k">class</span><span class="w"> </span><span class="nc">ObjectCentricNetwork</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A network that incorporates an object-centric inductive bias</span>
<span class="sd">    inspired by human visual cognition</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_slots</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">slot_dim</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">64</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the object-centric network</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        n_slots : int</span>
<span class="sd">            Number of object slots</span>
<span class="sd">        slot_dim : int</span>
<span class="sd">            Dimension of each object slot</span>
<span class="sd">        hidden_dim : int</span>
<span class="sd">            Dimension of hidden layers</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">n_slots</span> <span class="o">=</span> <span class="n">n_slots</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">slot_dim</span> <span class="o">=</span> <span class="n">slot_dim</span>
        
        <span class="c1"># Slot attention mechanism</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">slot_attention</span> <span class="o">=</span> <span class="n">SlotAttention</span><span class="p">(</span>
            <span class="n">dim</span><span class="o">=</span><span class="n">hidden_dim</span><span class="p">,</span>
            <span class="n">n_slots</span><span class="o">=</span><span class="n">n_slots</span><span class="p">,</span>
            <span class="n">slot_dim</span><span class="o">=</span><span class="n">slot_dim</span>
        <span class="p">)</span>
        
        <span class="c1"># CNN encoder to extract features from images</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span> <span class="o">*</span> <span class="mi">8</span> <span class="o">*</span> <span class="mi">8</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="p">)</span>
        
        <span class="c1"># Object-wise MLP for classification</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">object_classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">slot_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>  <span class="c1"># 10 object classes</span>
        <span class="p">)</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Forward pass through the network</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        x : torch.Tensor</span>
<span class="sd">            Input images of shape (batch_size, channels, height, width)</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">        --------</span>
<span class="sd">        object_preds : torch.Tensor</span>
<span class="sd">            Object class predictions</span>
<span class="sd">        attention_maps : torch.Tensor</span>
<span class="sd">            Attention maps for each object slot</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        
        <span class="c1"># Extract image features</span>
        <span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="c1"># Apply slot attention to segment into objects</span>
        <span class="n">slots</span><span class="p">,</span> <span class="n">attention_maps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">slot_attention</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        
        <span class="c1"># Classify each object</span>
        <span class="n">object_preds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">object_classifier</span><span class="p">(</span><span class="n">slots</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_slots</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">slot_dim</span><span class="p">))</span>
        <span class="n">object_preds</span> <span class="o">=</span> <span class="n">object_preds</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_slots</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">object_preds</span><span class="p">,</span> <span class="n">attention_maps</span>


<span class="k">class</span><span class="w"> </span><span class="nc">SlotAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Simplified version of Slot Attention mechanism</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">n_slots</span><span class="p">,</span> <span class="n">slot_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">=</span> <span class="n">dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_slots</span> <span class="o">=</span> <span class="n">n_slots</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">slot_dim</span> <span class="o">=</span> <span class="n">slot_dim</span>
        
        <span class="c1"># Initialize slot parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">slots</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_slots</span><span class="p">,</span> <span class="n">slot_dim</span><span class="p">))</span>
        
        <span class="c1"># Projection layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">to_q</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">slot_dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">to_k</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">to_v</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">gru</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRUCell</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">slot_dim</span><span class="p">)</span>
        
        <span class="c1"># MLP for slot update</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">slot_dim</span><span class="p">,</span> <span class="n">slot_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">slot_dim</span><span class="p">,</span> <span class="n">slot_dim</span><span class="p">)</span>
        <span class="p">)</span>
        
        <span class="c1"># Layer norm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm_slots</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">slot_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm_inputs</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">image_shape</span><span class="p">,</span> <span class="n">num_iterations</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Apply slot attention mechanism</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        inputs : torch.Tensor</span>
<span class="sd">            Input features of shape (batch_size, dim)</span>
<span class="sd">        image_shape : tuple</span>
<span class="sd">            Shape of the input images (batch_size, channels, height, width)</span>
<span class="sd">        num_iterations : int</span>
<span class="sd">            Number of attention iterations</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">        --------</span>
<span class="sd">        slots : torch.Tensor</span>
<span class="sd">            Updated slot representations</span>
<span class="sd">        attention_maps : torch.Tensor</span>
<span class="sd">            Attention maps for visualization</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        
        <span class="c1"># Initialize slots</span>
        <span class="n">slots</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">slots</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="c1"># Normalizations</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_inputs</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        
        <span class="c1"># Reshape inputs for attention visualization</span>
        <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">image_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">//</span> <span class="mi">4</span><span class="p">,</span> <span class="n">image_shape</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">//</span> <span class="mi">4</span>  <span class="c1"># Downsampled due to CNN</span>
        
        <span class="c1"># Multiple rounds of attention</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">):</span>
            <span class="n">slots_prev</span> <span class="o">=</span> <span class="n">slots</span>
            
            <span class="c1"># Normalize slots</span>
            <span class="n">slots</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_slots</span><span class="p">(</span><span class="n">slots</span><span class="p">)</span>
            
            <span class="c1"># Attention</span>
            <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_q</span><span class="p">(</span><span class="n">slots</span><span class="p">)</span>
            <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_k</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
            <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_v</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
            
            <span class="c1"># Compute attention scores</span>
            <span class="n">attn_logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">q</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">k</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">attn</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">attn_logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            
            <span class="c1"># Weight values by attention</span>
            <span class="n">updates</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">attn</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">v</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
            
            <span class="c1"># Update slots</span>
            <span class="n">slots</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru</span><span class="p">(</span>
                <span class="n">updates</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">),</span>
                <span class="n">slots_prev</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">slot_dim</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">slots</span> <span class="o">=</span> <span class="n">slots</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_slots</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">slot_dim</span><span class="p">)</span>
            
            <span class="c1"># MLP for additional processing</span>
            <span class="n">slots</span> <span class="o">=</span> <span class="n">slots</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="p">(</span><span class="n">slots</span><span class="p">)</span>
        
        <span class="c1"># Reshape attention for visualization</span>
        <span class="n">attention_maps</span> <span class="o">=</span> <span class="n">attn</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_slots</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">slots</span><span class="p">,</span> <span class="n">attention_maps</span>
</pre></div>
</div>
</section>
<section id="neural-architecture-constraints">
<h3>19.3.2 Neural Architecture Constraints<a class="headerlink" href="#neural-architecture-constraints" title="Link to this heading">#</a></h3>
<p>Beyond specific cognitive principles, the broader architecture of the brain can inform deep learning:</p>
<ul class="simple">
<li><p><strong>Computational resource constraints</strong>: Optimizing for energy efficiency</p></li>
<li><p><strong>Local learning rules</strong>: Alternatives to global backpropagation</p></li>
<li><p><strong>Modular architectures</strong>: Specialized components with distinct functions</p></li>
<li><p><strong>Recurrence and feedback connections</strong>: Incorporating temporal dynamics and top-down processing</p></li>
</ul>
</section>
<section id="cognitively-plausible-learning-mechanisms">
<h3>19.3.3 Cognitively-Plausible Learning Mechanisms<a class="headerlink" href="#cognitively-plausible-learning-mechanisms" title="Link to this heading">#</a></h3>
<p>Human learning differs from standard deep learning approaches in key ways:</p>
<ul class="simple">
<li><p><strong>Hebbian learning</strong>: Connections strengthen when neurons co-activate</p></li>
<li><p><strong>Contrastive learning</strong>: Learning from differences between positive and negative examples</p></li>
<li><p><strong>Curriculum learning</strong>: Gradually increasing task difficulty</p></li>
<li><p><strong>Few-shot and continual learning</strong>: Learning efficiently from limited data while avoiding catastrophic forgetting</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="k">class</span><span class="w"> </span><span class="nc">HebbianNetwork</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Simple implementation of a Hebbian learning network</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">decay_rate</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the Hebbian network</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        input_size : int</span>
<span class="sd">            Size of input features</span>
<span class="sd">        output_size : int</span>
<span class="sd">            Size of output features</span>
<span class="sd">        learning_rate : float</span>
<span class="sd">            Learning rate for weight updates</span>
<span class="sd">        decay_rate : float</span>
<span class="sd">            Weight decay rate to prevent unbounded growth</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="p">(</span><span class="n">output_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decay_rate</span> <span class="o">=</span> <span class="n">decay_rate</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Forward pass through the network</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        x : numpy.ndarray</span>
<span class="sd">            Input data of shape (batch_size, input_size)</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">        --------</span>
<span class="sd">        y : numpy.ndarray</span>
<span class="sd">            Output activations of shape (batch_size, output_size)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Update weights using Hebbian learning rule:</span>
<span class="sd">        &quot;Neurons that fire together, wire together&quot;</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        x : numpy.ndarray</span>
<span class="sd">            Input data of shape (batch_size, input_size)</span>
<span class="sd">        y : numpy.ndarray</span>
<span class="sd">            Output activations of shape (batch_size, output_size)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Basic Hebbian update</span>
        <span class="n">delta_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        
        <span class="c1"># Apply weight decay to prevent unbounded growth</span>
        <span class="n">delta_w</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decay_rate</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span>
        
        <span class="c1"># Update weights</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">+=</span> <span class="n">delta_w</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Train the network for a specified number of epochs</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        x : numpy.ndarray</span>
<span class="sd">            Input data of shape (batch_size, input_size)</span>
<span class="sd">        num_epochs : int</span>
<span class="sd">            Number of training epochs</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
            <span class="c1"># Forward pass</span>
            <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            
            <span class="c1"># Update weights</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            
            <span class="c1"># Optional: Apply normalization to stabilize learning</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="mf">1e-8</span><span class="p">)</span>
            
            <span class="c1"># Print progress</span>
            <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">: Average activation: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">y</span><span class="p">))</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">visualize_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reshape</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Visualize the learned weights</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        reshape : tuple or None</span>
<span class="sd">            Reshape dimensions for visualizing weights as images</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
        
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">axes</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
                <span class="n">weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                
                <span class="k">if</span> <span class="n">reshape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">weight</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">reshape</span><span class="p">)</span>
                    
                <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">)</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Neuron </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
        
        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</section>
</section>
<section id="deep-learning-models-as-theories-of-cognition">
<h2>19.4 Deep Learning Models as Theories of Cognition<a class="headerlink" href="#deep-learning-models-as-theories-of-cognition" title="Link to this heading">#</a></h2>
<section id="using-deep-learning-to-test-cognitive-theories">
<h3>19.4.1 Using Deep Learning to Test Cognitive Theories<a class="headerlink" href="#using-deep-learning-to-test-cognitive-theories" title="Link to this heading">#</a></h3>
<p>Deep learning models can serve as computational implementations of cognitive theories:</p>
<ul class="simple">
<li><p><strong>Explicit formalizations</strong>: Converting verbal theories into precise computations</p></li>
<li><p><strong>Parameter exploration</strong>: Testing hypotheses by manipulating model parameters</p></li>
<li><p><strong>Counterfactual testing</strong>: Exploring alternative mechanisms</p></li>
<li><p><strong>Developmental trajectories</strong>: Studying how learning unfolds over time</p></li>
</ul>
</section>
<section id="case-studies-in-cognitive-modeling">
<h3>19.4.2 Case Studies in Cognitive Modeling<a class="headerlink" href="#case-studies-in-cognitive-modeling" title="Link to this heading">#</a></h3>
<p>Deep learning has been used to model various cognitive domains:</p>
<ul class="simple">
<li><p><strong>Visual perception</strong>: CNNs as models of object recognition</p></li>
<li><p><strong>Language processing</strong>: Transformers as models of language comprehension</p></li>
<li><p><strong>Decision making</strong>: Reinforcement learning as models of value-based choice</p></li>
<li><p><strong>Memory</strong>: Sequence models as models of episodic and working memory</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="k">class</span><span class="w"> </span><span class="nc">VisualCognitiveModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    CNN-based model of visual object recognition designed to test</span>
<span class="sd">    cognitive theories about human visual processing</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">with_recurrence</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">with_feedback</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the visual cognitive model</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        with_recurrence : bool</span>
<span class="sd">            Whether to include recurrent connections</span>
<span class="sd">        with_feedback : bool</span>
<span class="sd">            Whether to include feedback connections</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">with_recurrence</span> <span class="o">=</span> <span class="n">with_recurrence</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">with_feedback</span> <span class="o">=</span> <span class="n">with_feedback</span>
        
        <span class="c1"># Feedforward pathway (V1-like)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pool1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
        
        <span class="c1"># Feedforward pathway (V2-like)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pool2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
        
        <span class="c1"># Feedforward pathway (V4-like)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pool3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
        
        <span class="c1"># Feedforward pathway (IT-like)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv4</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pool4</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
        
        <span class="c1"># Recurrent connections</span>
        <span class="k">if</span> <span class="n">with_recurrence</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">recurrent1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">recurrent2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">recurrent3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="c1"># Feedback connections</span>
        <span class="k">if</span> <span class="n">with_feedback</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">feedback3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">feedback2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="c1"># Readout layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span> <span class="o">*</span> <span class="mi">4</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>  <span class="c1"># 10 object classes</span>
        
        <span class="c1"># Save activations for visualization</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activations</span> <span class="o">=</span> <span class="p">{}</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">timesteps</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Forward pass through the network</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        x : torch.Tensor</span>
<span class="sd">            Input images</span>
<span class="sd">        timesteps : int</span>
<span class="sd">            Number of timesteps for recurrent processing</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">        --------</span>
<span class="sd">        output : torch.Tensor</span>
<span class="sd">            Class predictions</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        
        <span class="c1"># Initial feedforward pass</span>
        <span class="n">x1</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">p1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool1</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span>
        
        <span class="n">x2</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">p1</span><span class="p">))</span>
        <span class="n">p2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool2</span><span class="p">(</span><span class="n">x2</span><span class="p">)</span>
        
        <span class="n">x3</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv3</span><span class="p">(</span><span class="n">p2</span><span class="p">))</span>
        <span class="n">p3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool3</span><span class="p">(</span><span class="n">x3</span><span class="p">)</span>
        
        <span class="n">x4</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv4</span><span class="p">(</span><span class="n">p3</span><span class="p">))</span>
        <span class="n">p4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool4</span><span class="p">(</span><span class="n">x4</span><span class="p">)</span>
        
        <span class="c1"># Store initial activations</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activations</span><span class="p">[</span><span class="s1">&#39;layer1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">p1</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activations</span><span class="p">[</span><span class="s1">&#39;layer2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">p2</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activations</span><span class="p">[</span><span class="s1">&#39;layer3&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">p3</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activations</span><span class="p">[</span><span class="s1">&#39;layer4&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">p4</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        
        <span class="c1"># Recurrent and feedback processing</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">with_recurrence</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">with_feedback</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">timesteps</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
                <span class="c1"># Store activations for this timestep</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">activations</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;layer1_t</span><span class="si">{</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">p1</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">activations</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;layer2_t</span><span class="si">{</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">p2</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">activations</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;layer3_t</span><span class="si">{</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">p3</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                
                <span class="c1"># Apply recurrent connections</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">with_recurrence</span><span class="p">:</span>
                    <span class="n">p1</span> <span class="o">=</span> <span class="n">p1</span> <span class="o">+</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">recurrent1</span><span class="p">(</span><span class="n">p1</span><span class="p">))</span>
                    <span class="n">p2</span> <span class="o">=</span> <span class="n">p2</span> <span class="o">+</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">recurrent2</span><span class="p">(</span><span class="n">p2</span><span class="p">))</span>
                    <span class="n">p3</span> <span class="o">=</span> <span class="n">p3</span> <span class="o">+</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">recurrent3</span><span class="p">(</span><span class="n">p3</span><span class="p">))</span>
                
                <span class="c1"># Apply feedback connections</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">with_feedback</span><span class="p">:</span>
                    <span class="n">feedback_3to2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feedback3</span><span class="p">(</span><span class="n">p3</span><span class="p">)</span>
                    <span class="n">feedback_2to1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feedback2</span><span class="p">(</span><span class="n">p2</span><span class="p">)</span>
                    
                    <span class="c1"># Add feedback to earlier representations</span>
                    <span class="n">p2</span> <span class="o">=</span> <span class="n">p2</span> <span class="o">+</span> <span class="mf">0.2</span> <span class="o">*</span> <span class="n">feedback_3to2</span>
                    <span class="n">p1</span> <span class="o">=</span> <span class="n">p1</span> <span class="o">+</span> <span class="mf">0.2</span> <span class="o">*</span> <span class="n">feedback_2to1</span>
                    
                    <span class="c1"># Update forward pass with feedback influence</span>
                    <span class="n">x2</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">p1</span><span class="p">))</span>
                    <span class="n">p2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool2</span><span class="p">(</span><span class="n">x2</span><span class="p">)</span>
                    
                    <span class="n">x3</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv3</span><span class="p">(</span><span class="n">p2</span><span class="p">))</span>
                    <span class="n">p3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool3</span><span class="p">(</span><span class="n">x3</span><span class="p">)</span>
                    
                    <span class="n">x4</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv4</span><span class="p">(</span><span class="n">p3</span><span class="p">))</span>
                    <span class="n">p4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool4</span><span class="p">(</span><span class="n">x4</span><span class="p">)</span>
        
        <span class="c1"># Final classification</span>
        <span class="n">flat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">p4</span><span class="p">)</span>
        <span class="n">fc1</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">flat</span><span class="p">))</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">fc1</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">output</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">analyze_temporal_dynamics</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">target_class</span><span class="p">,</span> <span class="n">timesteps</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Analyze how representation evolves over time due to</span>
<span class="sd">        recurrent and feedback processing</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        image : torch.Tensor</span>
<span class="sd">            Input image</span>
<span class="sd">        target_class : int</span>
<span class="sd">            Target class for the image</span>
<span class="sd">        timesteps : int</span>
<span class="sd">            Number of timesteps to analyze</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Ensure the model is in evaluation mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        
        <span class="c1"># Forward pass with multiple timesteps</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">timesteps</span><span class="o">=</span><span class="n">timesteps</span><span class="p">)</span>
        
        <span class="c1"># Get class probabilities</span>
        <span class="n">probs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">target_prob</span> <span class="o">=</span> <span class="n">probs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">target_class</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        
        <span class="c1"># Visualize how representations change over time</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">timesteps</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">3</span><span class="o">*</span><span class="n">timesteps</span><span class="p">))</span>
        
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">timesteps</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
                <span class="n">layer_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;layer</span><span class="si">{</span><span class="n">l</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">_t</span><span class="si">{</span><span class="n">t</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">if</span> <span class="n">t</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="sa">f</span><span class="s1">&#39;layer</span><span class="si">{</span><span class="n">l</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span>
                <span class="k">if</span> <span class="n">layer_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">activations</span><span class="p">:</span>
                    <span class="c1"># Take first image in batch, first channel for visualization</span>
                    <span class="n">act</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activations</span><span class="p">[</span><span class="n">layer_name</span><span class="p">][</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
                    <span class="n">axes</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">act</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">)</span>
                    <span class="n">axes</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Layer </span><span class="si">{</span><span class="n">l</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">, Time </span><span class="si">{</span><span class="n">t</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="n">axes</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
        
        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
        
        <span class="c1"># Plot target class probability over time</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">timesteps</span><span class="p">),</span> <span class="p">[</span><span class="n">probs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">target_class</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">timesteps</span><span class="p">)],</span> <span class="s1">&#39;o-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Processing Timestep&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Probability of Class </span><span class="si">{</span><span class="n">target_class</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Temporal Dynamics of Recognition&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
        
        <span class="k">return</span> <span class="n">probs</span>
</pre></div>
</div>
</section>
<section id="comparing-model-behavior-to-human-behavior">
<h3>19.4.3 Comparing Model Behavior to Human Behavior<a class="headerlink" href="#comparing-model-behavior-to-human-behavior" title="Link to this heading">#</a></h3>
<p>A key test of cognitive models is their ability to predict human behavior:</p>
<ul class="simple">
<li><p><strong>Psychophysical experiments</strong>: Testing if models show similar perceptual biases</p></li>
<li><p><strong>Error patterns</strong>: Comparing model and human mistakes</p></li>
<li><p><strong>Reaction times</strong>: Relating model processing to response latencies</p></li>
<li><p><strong>Developmental trajectories</strong>: Comparing learning curves</p></li>
</ul>
</section>
</section>
<section id="neural-representation-comparison-methods">
<h2>19.5 Neural Representation Comparison Methods<a class="headerlink" href="#neural-representation-comparison-methods" title="Link to this heading">#</a></h2>
<section id="representational-similarity-analysis">
<h3>19.5.1 Representational Similarity Analysis<a class="headerlink" href="#representational-similarity-analysis" title="Link to this heading">#</a></h3>
<p>Representational Similarity Analysis (RSA) is a framework for comparing neural representations across species, methods, and models:</p>
<ul class="simple">
<li><p><strong>Constructing similarity matrices</strong>: Computing pairwise similarities between activity patterns</p></li>
<li><p><strong>Computing representational similarity</strong>: Correlating similarity matrices across systems</p></li>
<li><p><strong>Significance testing</strong>: Statistical approaches for assessing similarity</p></li>
<li><p><strong>Visualization techniques</strong>: Visualizing representational spaces</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">spearmanr</span><span class="p">,</span> <span class="n">pearsonr</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.spatial.distance</span><span class="w"> </span><span class="kn">import</span> <span class="n">pdist</span><span class="p">,</span> <span class="n">squareform</span>

<span class="k">class</span><span class="w"> </span><span class="nc">RepresentationalSimilarityAnalysis</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Implementation of Representational Similarity Analysis (RSA)</span>
<span class="sd">    for comparing neural and model representations</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">distance_metric</span><span class="o">=</span><span class="s1">&#39;correlation&#39;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize RSA</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        distance_metric : str</span>
<span class="sd">            Distance metric for computing dissimilarity</span>
<span class="sd">            Options: &#39;correlation&#39;, &#39;euclidean&#39;, &#39;cosine&#39;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">distance_metric</span> <span class="o">=</span> <span class="n">distance_metric</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">compute_rdm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">activations</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute Representational Dissimilarity Matrix (RDM)</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        activations : numpy.ndarray</span>
<span class="sd">            Neural/model activations of shape (n_samples, n_features)</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">        --------</span>
<span class="sd">        rdm : numpy.ndarray</span>
<span class="sd">            Representational Dissimilarity Matrix of shape (n_samples, n_samples)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Compute pairwise distances</span>
        <span class="n">distances</span> <span class="o">=</span> <span class="n">pdist</span><span class="p">(</span><span class="n">activations</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">distance_metric</span><span class="p">)</span>
        
        <span class="c1"># Convert to square form</span>
        <span class="n">rdm</span> <span class="o">=</span> <span class="n">squareform</span><span class="p">(</span><span class="n">distances</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">rdm</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">compare_rdms</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rdm1</span><span class="p">,</span> <span class="n">rdm2</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;spearman&#39;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compare two RDMs to quantify representational similarity</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        rdm1 : numpy.ndarray</span>
<span class="sd">            First RDM of shape (n_samples, n_samples)</span>
<span class="sd">        rdm2 : numpy.ndarray</span>
<span class="sd">            Second RDM of shape (n_samples, n_samples)</span>
<span class="sd">        method : str</span>
<span class="sd">            Correlation method (&#39;spearman&#39; or &#39;pearson&#39;)</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">        --------</span>
<span class="sd">        correlation : float</span>
<span class="sd">            Correlation coefficient between the two RDMs</span>
<span class="sd">        p_value : float</span>
<span class="sd">            p-value for the correlation</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Flatten the upper triangular part of the RDMs (excluding diagonal)</span>
        <span class="n">triu_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">triu_indices</span><span class="p">(</span><span class="n">rdm1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">rdm1_flat</span> <span class="o">=</span> <span class="n">rdm1</span><span class="p">[</span><span class="n">triu_indices</span><span class="p">]</span>
        <span class="n">rdm2_flat</span> <span class="o">=</span> <span class="n">rdm2</span><span class="p">[</span><span class="n">triu_indices</span><span class="p">]</span>
        
        <span class="c1"># Compute correlation</span>
        <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;spearman&#39;</span><span class="p">:</span>
            <span class="n">correlation</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">spearmanr</span><span class="p">(</span><span class="n">rdm1_flat</span><span class="p">,</span> <span class="n">rdm2_flat</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;pearson&#39;</span><span class="p">:</span>
            <span class="n">correlation</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">pearsonr</span><span class="p">(</span><span class="n">rdm1_flat</span><span class="p">,</span> <span class="n">rdm2_flat</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Method must be &#39;spearman&#39; or &#39;pearson&#39;&quot;</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">correlation</span><span class="p">,</span> <span class="n">p_value</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">visualize_rdm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rdm</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Representational Dissimilarity Matrix&#39;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Visualize a Representational Dissimilarity Matrix</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        rdm : numpy.ndarray</span>
<span class="sd">            RDM of shape (n_samples, n_samples)</span>
<span class="sd">        labels : list or None</span>
<span class="sd">            Labels for the samples</span>
<span class="sd">        title : str</span>
<span class="sd">            Title for the plot</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">rdm</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Dissimilarity&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)),</span> <span class="n">labels</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)),</span> <span class="n">labels</span><span class="p">)</span>
        
        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">visualize_comparison</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rdm1</span><span class="p">,</span> <span class="n">rdm2</span><span class="p">,</span> <span class="n">labels1</span><span class="o">=</span><span class="s1">&#39;Model&#39;</span><span class="p">,</span> <span class="n">labels2</span><span class="o">=</span><span class="s1">&#39;Brain&#39;</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;RDM Comparison&#39;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Visualize a comparison between two RDMs</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        rdm1 : numpy.ndarray</span>
<span class="sd">            First RDM</span>
<span class="sd">        rdm2 : numpy.ndarray</span>
<span class="sd">            Second RDM</span>
<span class="sd">        labels1 : str</span>
<span class="sd">            Label for the first RDM</span>
<span class="sd">        labels2 : str</span>
<span class="sd">            Label for the second RDM</span>
<span class="sd">        title : str</span>
<span class="sd">            Title for the plot</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Flatten upper triangular part</span>
        <span class="n">triu_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">triu_indices</span><span class="p">(</span><span class="n">rdm1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">rdm1_flat</span> <span class="o">=</span> <span class="n">rdm1</span><span class="p">[</span><span class="n">triu_indices</span><span class="p">]</span>
        <span class="n">rdm2_flat</span> <span class="o">=</span> <span class="n">rdm2</span><span class="p">[</span><span class="n">triu_indices</span><span class="p">]</span>
        
        <span class="c1"># Compute correlation</span>
        <span class="n">correlation</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compare_rdms</span><span class="p">(</span><span class="n">rdm1</span><span class="p">,</span> <span class="n">rdm2</span><span class="p">)</span>
        
        <span class="c1"># Create scatter plot</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">rdm1_flat</span><span class="p">,</span> <span class="n">rdm2_flat</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">labels1</span><span class="si">}</span><span class="s1"> Dissimilarity&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">labels2</span><span class="si">}</span><span class="s1"> Dissimilarity&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">title</span><span class="si">}</span><span class="se">\n</span><span class="s1">Correlation: </span><span class="si">{</span><span class="n">correlation</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1"> (p=</span><span class="si">{</span><span class="n">p_value</span><span class="si">:</span><span class="s1">.3g</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>
        
        <span class="c1"># Add regression line</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">polyfit</span><span class="p">(</span><span class="n">rdm1_flat</span><span class="p">,</span> <span class="n">rdm2_flat</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">poly1d</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">rdm1_flat</span><span class="p">),</span> <span class="nb">max</span><span class="p">(</span><span class="n">rdm1_flat</span><span class="p">),</span> <span class="mi">100</span><span class="p">),</span> 
                <span class="n">p</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">rdm1_flat</span><span class="p">),</span> <span class="nb">max</span><span class="p">(</span><span class="n">rdm1_flat</span><span class="p">),</span> <span class="mi">100</span><span class="p">)),</span> 
                <span class="s1">&#39;r--&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        
        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">mds_visualization</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rdm</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;MDS Visualization&#39;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Visualize the representational space using Multi-Dimensional Scaling (MDS)</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        rdm : numpy.ndarray</span>
<span class="sd">            RDM of shape (n_samples, n_samples)</span>
<span class="sd">        labels : list or None</span>
<span class="sd">            Labels for the samples</span>
<span class="sd">        title : str</span>
<span class="sd">            Title for the plot</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.manifold</span><span class="w"> </span><span class="kn">import</span> <span class="n">MDS</span>
        
        <span class="c1"># Create MDS model</span>
        <span class="n">mds</span> <span class="o">=</span> <span class="n">MDS</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dissimilarity</span><span class="o">=</span><span class="s1">&#39;precomputed&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
        
        <span class="c1"># Fit MDS model to RDM</span>
        <span class="n">points</span> <span class="o">=</span> <span class="n">mds</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">rdm</span><span class="p">)</span>
        
        <span class="c1"># Plot results</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">points</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">points</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">labels</span><span class="p">):</span>
                <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="p">(</span><span class="n">points</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">points</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span> 
                            <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
        
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
        
        <span class="k">return</span> <span class="n">points</span>
</pre></div>
</div>
</section>
<section id="neural-encoding-and-decoding-models">
<h3>19.5.2 Neural Encoding and Decoding Models<a class="headerlink" href="#neural-encoding-and-decoding-models" title="Link to this heading">#</a></h3>
<p>Neural encoding and decoding create direct mappings between brain activity and model representations:</p>
<ul class="simple">
<li><p><strong>Encoding models</strong>: Predicting neural responses from model activations</p></li>
<li><p><strong>Decoding models</strong>: Predicting stimuli from neural responses</p></li>
<li><p><strong>Cross-validated prediction</strong>: Assessing generalization of encoding/decoding models</p></li>
<li><p><strong>Feature importance analysis</strong>: Identifying critical dimensions of the representation</p></li>
</ul>
</section>
<section id="canonical-correlation-analysis">
<h3>19.5.3 Canonical Correlation Analysis<a class="headerlink" href="#canonical-correlation-analysis" title="Link to this heading">#</a></h3>
<p>Canonical Correlation Analysis (CCA) finds shared dimensions between neural and model representations:</p>
<ul class="simple">
<li><p><strong>Canonical variates</strong>: Identifying maximally correlated dimensions</p></li>
<li><p><strong>Shared variance</strong>: Quantifying overlap between representations</p></li>
<li><p><strong>Dimensionality analysis</strong>: Determining the number of meaningful shared dimensions</p></li>
<li><p><strong>Stimulus associations</strong>: Relating shared dimensions to stimulus properties</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.cross_decomposition</span><span class="w"> </span><span class="kn">import</span> <span class="n">CCA</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="k">class</span><span class="w"> </span><span class="nc">CanonicalCorrelationAnalyzer</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Implementation of Canonical Correlation Analysis (CCA)</span>
<span class="sd">    for comparing neural and model representations</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize CCA</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        n_components : int</span>
<span class="sd">            Number of canonical components to extract</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="o">=</span> <span class="n">n_components</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cca</span> <span class="o">=</span> <span class="n">CCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">n_components</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">correlations</span> <span class="o">=</span> <span class="kc">None</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fit CCA on two sets of features</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        X : numpy.ndarray</span>
<span class="sd">            First feature set (e.g., neural data) of shape (n_samples, n_features_X)</span>
<span class="sd">        Y : numpy.ndarray</span>
<span class="sd">            Second feature set (e.g., model data) of shape (n_samples, n_features_Y)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Fit CCA</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
        
        <span class="c1"># Transform data to canonical space</span>
        <span class="n">X_c</span><span class="p">,</span> <span class="n">Y_c</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
        
        <span class="c1"># Compute correlations between canonical variates</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">correlations</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">X_c</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span> <span class="n">Y_c</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> 
                                     <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">)])</span>
        
        <span class="k">return</span> <span class="n">X_c</span><span class="p">,</span> <span class="n">Y_c</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Transform data to canonical space</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        X : numpy.ndarray</span>
<span class="sd">            First feature set</span>
<span class="sd">        Y : numpy.ndarray</span>
<span class="sd">            Second feature set</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">        --------</span>
<span class="sd">        X_c : numpy.ndarray</span>
<span class="sd">            First feature set in canonical space</span>
<span class="sd">        Y_c : numpy.ndarray</span>
<span class="sd">            Second feature set in canonical space</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">cca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">visualize_correlations</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Visualize canonical correlations</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        labels : list or None</span>
<span class="sd">            Labels for the components</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">correlations</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;CCA must be fit before visualizing correlations&quot;</span><span class="p">)</span>
        
        <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
        
        <span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">correlations</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Canonical Component&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Correlation&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Canonical Correlations&#39;</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">labels</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">labels</span><span class="p">)</span>
        
        <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">visualize_canonical_variates</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_c</span><span class="p">,</span> <span class="n">Y_c</span><span class="p">,</span> <span class="n">sample_labels</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Visualize the first two canonical variates</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        X_c : numpy.ndarray</span>
<span class="sd">            First feature set in canonical space</span>
<span class="sd">        Y_c : numpy.ndarray</span>
<span class="sd">            Second feature set in canonical space</span>
<span class="sd">        sample_labels : list or None</span>
<span class="sd">            Labels for the samples</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">X_c</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">2</span> <span class="ow">or</span> <span class="n">Y_c</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Need at least 2 components for visualization&quot;</span><span class="p">)</span>
        
        <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
        
        <span class="c1"># Plot first set of canonical variates</span>
        <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_c</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_c</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;First Canonical Variate&#39;</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Second Canonical Variate&#39;</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Neural Representation&#39;</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
        
        <span class="c1"># Plot second set of canonical variates</span>
        <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">Y_c</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">Y_c</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;First Canonical Variate&#39;</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Second Canonical Variate&#39;</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Model Representation&#39;</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">sample_labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sample_labels</span><span class="p">):</span>
                <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="p">(</span><span class="n">X_c</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_c</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
                <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="p">(</span><span class="n">Y_c</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">Y_c</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
        
        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">correlation_significance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">n_permutations</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform permutation test to assess significance of canonical correlations</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        X : numpy.ndarray</span>
<span class="sd">            First feature set</span>
<span class="sd">        Y : numpy.ndarray</span>
<span class="sd">            Second feature set</span>
<span class="sd">        n_permutations : int</span>
<span class="sd">            Number of permutations for the test</span>
<span class="sd">        alpha : float</span>
<span class="sd">            Significance level</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">        --------</span>
<span class="sd">        p_values : numpy.ndarray</span>
<span class="sd">            p-values for each canonical correlation</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">correlations</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;CCA must be fit before testing significance&quot;</span><span class="p">)</span>
        
        <span class="c1"># Initialize array to store permutation correlations</span>
        <span class="n">perm_correlations</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_permutations</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">))</span>
        
        <span class="c1"># Original sample size</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        
        <span class="c1"># Perform permutation test</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_permutations</span><span class="p">):</span>
            <span class="c1"># Permute samples in Y</span>
            <span class="n">perm_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>
            <span class="n">Y_perm</span> <span class="o">=</span> <span class="n">Y</span><span class="p">[</span><span class="n">perm_idx</span><span class="p">]</span>
            
            <span class="c1"># Fit CCA on permuted data</span>
            <span class="n">cca_perm</span> <span class="o">=</span> <span class="n">CCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">)</span>
            <span class="n">cca_perm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y_perm</span><span class="p">)</span>
            
            <span class="c1"># Transform data to canonical space</span>
            <span class="n">X_c_perm</span><span class="p">,</span> <span class="n">Y_c_perm</span> <span class="o">=</span> <span class="n">cca_perm</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y_perm</span><span class="p">)</span>
            
            <span class="c1"># Compute correlations</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">):</span>
                <span class="n">perm_correlations</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">X_c_perm</span><span class="p">[:,</span> <span class="n">j</span><span class="p">],</span> <span class="n">Y_c_perm</span><span class="p">[:,</span> <span class="n">j</span><span class="p">])[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
        
        <span class="c1"># Compute p-values (proportion of permutation correlations &gt;= observed)</span>
        <span class="n">p_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">):</span>
            <span class="n">p_values</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">perm_correlations</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">correlations</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
        
        <span class="c1"># Visualize results</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
        
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">):</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">,</span> <span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">perm_correlations</span><span class="p">[:,</span> <span class="n">j</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">correlations</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Component </span><span class="si">{</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">: p=</span><span class="si">{</span><span class="n">p_values</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Correlation&#39;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Frequency&#39;</span><span class="p">)</span>
        
        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
        
        <span class="k">return</span> <span class="n">p_values</span>
</pre></div>
</div>
</section>
</section>
<section id="the-impact-of-deep-learning-on-cognitive-neuroscience">
<h2>19.6 The Impact of Deep Learning on Cognitive Neuroscience<a class="headerlink" href="#the-impact-of-deep-learning-on-cognitive-neuroscience" title="Link to this heading">#</a></h2>
<section id="new-frameworks-for-understanding-brain-function">
<h3>19.6.1 New Frameworks for Understanding Brain Function<a class="headerlink" href="#new-frameworks-for-understanding-brain-function" title="Link to this heading">#</a></h3>
<p>Deep learning has provided cognitive neuroscience with new conceptual tools:</p>
<ul class="simple">
<li><p><strong>Normative theories</strong>: Explaining neural mechanisms as optimizations for specific objectives</p></li>
<li><p><strong>Learning dynamics</strong>: Understanding neural development through gradient-based learning</p></li>
<li><p><strong>Distributed representations</strong>: Conceptualizing neural coding as distributed patterns</p></li>
<li><p><strong>End-to-end optimization</strong>: Viewing brain regions as components in differentiable systems</p></li>
</ul>
</section>
<section id="tools-for-neural-data-analysis">
<h3>19.6.2 Tools for Neural Data Analysis<a class="headerlink" href="#tools-for-neural-data-analysis" title="Link to this heading">#</a></h3>
<p>Beyond conceptual advances, deep learning has provided practical tools for neuroscience:</p>
<ul class="simple">
<li><p><strong>Neural decoding</strong>: Better extraction of information from brain recordings</p></li>
<li><p><strong>Dimensionality reduction</strong>: Discovering meaningful latent structures in neural data</p></li>
<li><p><strong>Generative modeling</strong>: Creating detailed models of neural activity</p></li>
<li><p><strong>Automated analysis</strong>: Processing and classifying large neural datasets</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="k">class</span><span class="w"> </span><span class="nc">LatentDynamicsModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Neural latent dynamics model for analyzing neural population activity</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_neurons</span><span class="p">,</span> <span class="n">latent_dim</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="s1">&#39;tanh&#39;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the latent dynamics model</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        n_neurons : int</span>
<span class="sd">            Number of neurons in the population</span>
<span class="sd">        latent_dim : int</span>
<span class="sd">            Dimensionality of the latent space</span>
<span class="sd">        nonlinearity : str</span>
<span class="sd">            Nonlinearity to use (&#39;relu&#39;, &#39;tanh&#39;, or &#39;sigmoid&#39;)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">n_neurons</span> <span class="o">=</span> <span class="n">n_neurons</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">latent_dim</span> <span class="o">=</span> <span class="n">latent_dim</span>
        
        <span class="c1"># Encoder: neural activity -&gt; latent variables</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">latent_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># Mean and log-variance</span>
        <span class="p">)</span>
        
        <span class="c1"># Latent dynamics model</span>
        <span class="k">if</span> <span class="n">nonlinearity</span> <span class="o">==</span> <span class="s1">&#39;relu&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dynamics_nonlinearity</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="k">elif</span> <span class="n">nonlinearity</span> <span class="o">==</span> <span class="s1">&#39;tanh&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dynamics_nonlinearity</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()</span>
        <span class="k">elif</span> <span class="n">nonlinearity</span> <span class="o">==</span> <span class="s1">&#39;sigmoid&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dynamics_nonlinearity</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Nonlinearity must be &#39;relu&#39;, &#39;tanh&#39;, or &#39;sigmoid&#39;&quot;</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">dynamics</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dynamics_nonlinearity</span>
        <span class="p">)</span>
        
        <span class="c1"># Decoder: latent variables -&gt; neural activity</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">n_neurons</span><span class="p">)</span>
        <span class="p">)</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Encode neural activity to latent variables</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        x : torch.Tensor</span>
<span class="sd">            Neural activity of shape (batch_size, n_neurons)</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">        --------</span>
<span class="sd">        mean : torch.Tensor</span>
<span class="sd">            Mean of latent distribution</span>
<span class="sd">        logvar : torch.Tensor</span>
<span class="sd">            Log-variance of latent distribution</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">mean</span><span class="p">,</span> <span class="n">logvar</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mean</span><span class="p">,</span> <span class="n">logvar</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">reparameterize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">logvar</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Reparameterization trick for sampling from latent distribution</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        mean : torch.Tensor</span>
<span class="sd">            Mean of latent distribution</span>
<span class="sd">        logvar : torch.Tensor</span>
<span class="sd">            Log-variance of latent distribution</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">        --------</span>
<span class="sd">        z : torch.Tensor</span>
<span class="sd">            Sampled latent variables</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">std</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">logvar</span><span class="p">)</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">std</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mean</span> <span class="o">+</span> <span class="n">eps</span> <span class="o">*</span> <span class="n">std</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Decode latent variables to neural activity</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        z : torch.Tensor</span>
<span class="sd">            Latent variables of shape (batch_size, latent_dim)</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">        --------</span>
<span class="sd">        x_recon : torch.Tensor</span>
<span class="sd">            Reconstructed neural activity</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Forward pass through the model</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        x : torch.Tensor</span>
<span class="sd">            Neural activity of shape (batch_size, n_neurons)</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">        --------</span>
<span class="sd">        x_recon : torch.Tensor</span>
<span class="sd">            Reconstructed neural activity</span>
<span class="sd">        mean : torch.Tensor</span>
<span class="sd">            Mean of latent distribution</span>
<span class="sd">        logvar : torch.Tensor</span>
<span class="sd">            Log-variance of latent distribution</span>
<span class="sd">        z : torch.Tensor</span>
<span class="sd">            Sampled latent variables</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">mean</span><span class="p">,</span> <span class="n">logvar</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reparameterize</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">logvar</span><span class="p">)</span>
        <span class="n">x_recon</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x_recon</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">logvar</span><span class="p">,</span> <span class="n">z</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">predict_next_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Predict the next state in the latent space</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        x : torch.Tensor</span>
<span class="sd">            Current neural activity</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">        --------</span>
<span class="sd">        x_next : torch.Tensor</span>
<span class="sd">            Predicted next neural activity</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">mean</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">z_next</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dynamics</span><span class="p">(</span><span class="n">mean</span><span class="p">)</span>
        <span class="n">x_next</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">z_next</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x_next</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">loss_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_recon</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">logvar</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the VAE loss function</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        x_recon : torch.Tensor</span>
<span class="sd">            Reconstructed neural activity</span>
<span class="sd">        x : torch.Tensor</span>
<span class="sd">            Original neural activity</span>
<span class="sd">        mean : torch.Tensor</span>
<span class="sd">            Mean of latent distribution</span>
<span class="sd">        logvar : torch.Tensor</span>
<span class="sd">            Log-variance of latent distribution</span>
<span class="sd">        beta : float</span>
<span class="sd">            Weight of the KL divergence term</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">        --------</span>
<span class="sd">        loss : torch.Tensor</span>
<span class="sd">            Total loss</span>
<span class="sd">        recon_loss : torch.Tensor</span>
<span class="sd">            Reconstruction loss</span>
<span class="sd">        kl_loss : torch.Tensor</span>
<span class="sd">            KL divergence loss</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Reconstruction loss (mean squared error)</span>
        <span class="n">recon_loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">x_recon</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">)</span>
        
        <span class="c1"># KL divergence loss</span>
        <span class="n">kl_loss</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">logvar</span> <span class="o">-</span> <span class="n">mean</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="n">logvar</span><span class="o">.</span><span class="n">exp</span><span class="p">())</span>
        
        <span class="c1"># Total loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">recon_loss</span> <span class="o">+</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">kl_loss</span>
        
        <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">recon_loss</span><span class="p">,</span> <span class="n">kl_loss</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">visualize_latent_space</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Latent Space Visualization&#39;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Visualize the latent space</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        data : torch.Tensor</span>
<span class="sd">            Neural activity data</span>
<span class="sd">        labels : numpy.ndarray or None</span>
<span class="sd">            Labels for color-coding points</span>
<span class="sd">        title : str</span>
<span class="sd">            Plot title</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Switch to evaluation mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        
        <span class="c1"># Encode data to get latent representations</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">mean</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">mean</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        
        <span class="c1"># Create scatter plot</span>
        <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
        
        <span class="k">if</span> <span class="n">z</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">3</span><span class="p">:</span>
            <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s1">&#39;3d&#39;</span><span class="p">)</span>
            
            <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">labels</span><span class="p">)):</span>
                    <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">labels</span> <span class="o">==</span> <span class="n">label</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">z</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">z</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">z</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Class </span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">z</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">z</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">z</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
                
            <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Latent Dim 1&#39;</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Latent Dim 2&#39;</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_zlabel</span><span class="p">(</span><span class="s1">&#39;Latent Dim 3&#39;</span><span class="p">)</span>
            
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
            
            <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">labels</span><span class="p">)):</span>
                    <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">labels</span> <span class="o">==</span> <span class="n">label</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">z</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">z</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Class </span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">z</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">z</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
                
            <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Latent Dim 1&#39;</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Latent Dim 2&#39;</span><span class="p">)</span>
            
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
            
        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
        
        <span class="k">return</span> <span class="n">z</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">visualize_trajectory</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_sequence</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Neural Trajectory in Latent Space&#39;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Visualize a neural trajectory in the latent space</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        data_sequence : torch.Tensor</span>
<span class="sd">            Sequence of neural activity patterns</span>
<span class="sd">        title : str</span>
<span class="sd">            Plot title</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Switch to evaluation mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        
        <span class="c1"># Encode sequence to get latent representations</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">latent_sequence</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">data_sequence</span><span class="p">:</span>
                <span class="n">mean</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
                <span class="n">latent_sequence</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mean</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
            
            <span class="n">latent_sequence</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">latent_sequence</span><span class="p">)</span>
        
        <span class="c1"># Create 3D plot for trajectory</span>
        <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
        
        <span class="k">if</span> <span class="n">latent_sequence</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">3</span><span class="p">:</span>
            <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s1">&#39;3d&#39;</span><span class="p">)</span>
            
            <span class="c1"># Plot trajectory</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">latent_sequence</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">latent_sequence</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">latent_sequence</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> 
                   <span class="s1">&#39;o-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
            
            <span class="c1"># Highlight start and end points</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">latent_sequence</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">latent_sequence</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">latent_sequence</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> 
                      <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Start&#39;</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">latent_sequence</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">latent_sequence</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">latent_sequence</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> 
                      <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;End&#39;</span><span class="p">)</span>
            
            <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Latent Dim 1&#39;</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Latent Dim 2&#39;</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_zlabel</span><span class="p">(</span><span class="s1">&#39;Latent Dim 3&#39;</span><span class="p">)</span>
            
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
            
            <span class="c1"># Plot trajectory</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">latent_sequence</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">latent_sequence</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;o-&#39;</span><span class="p">,</span> 
                   <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
            
            <span class="c1"># Highlight start and end points</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">latent_sequence</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">latent_sequence</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> 
                      <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Start&#39;</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">latent_sequence</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">latent_sequence</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> 
                      <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;End&#39;</span><span class="p">)</span>
            
            <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Latent Dim 1&#39;</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Latent Dim 2&#39;</span><span class="p">)</span>
            
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
        
        <span class="k">return</span> <span class="n">latent_sequence</span>
</pre></div>
</div>
</section>
<section id="generating-new-hypotheses">
<h3>19.6.3 Generating New Hypotheses<a class="headerlink" href="#generating-new-hypotheses" title="Link to this heading">#</a></h3>
<p>Deep learning models can suggest novel hypotheses about brain function:</p>
<ul class="simple">
<li><p><strong>Optimization principles</strong>: What objectives drive neural organization?</p></li>
<li><p><strong>Architectural principles</strong>: What network structures enable robust computation?</p></li>
<li><p><strong>Learning mechanisms</strong>: How does the brain learn efficiently from experience?</p></li>
<li><p><strong>Feature representations</strong>: What information is encoded in neural activity?</p></li>
</ul>
</section>
</section>
<section id="practical-exercise-comparing-deep-networks-and-brain-representations">
<h2>19.7 Practical Exercise: Comparing Deep Networks and Brain Representations<a class="headerlink" href="#practical-exercise-comparing-deep-networks-and-brain-representations" title="Link to this heading">#</a></h2>
<p>In this exercise, we’ll demonstrate how to compare representations between a deep neural network and fMRI brain activity patterns in response to the same visual stimuli.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">spearmanr</span>

<span class="k">def</span><span class="w"> </span><span class="nf">simulate_fmri_data</span><span class="p">(</span><span class="n">n_stimuli</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">n_voxels</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">n_roi</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">noise_level</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Simulate fMRI data for a visual experiment</span>
<span class="sd">    </span>
<span class="sd">    Parameters:</span>
<span class="sd">    -----------</span>
<span class="sd">    n_stimuli : int</span>
<span class="sd">        Number of stimuli (images)</span>
<span class="sd">    n_voxels : int</span>
<span class="sd">        Total number of voxels</span>
<span class="sd">    n_roi : int</span>
<span class="sd">        Number of brain regions (ROIs)</span>
<span class="sd">    noise_level : float</span>
<span class="sd">        Level of noise to add</span>
<span class="sd">        </span>
<span class="sd">    Returns:</span>
<span class="sd">    --------</span>
<span class="sd">    fmri_data : numpy.ndarray</span>
<span class="sd">        fMRI response patterns of shape (n_stimuli, n_voxels)</span>
<span class="sd">    roi_masks : list</span>
<span class="sd">        Binary masks for each ROI</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Create random fMRI patterns</span>
    <span class="n">fmri_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_stimuli</span><span class="p">,</span> <span class="n">n_voxels</span><span class="p">))</span>
    
    <span class="c1"># Create ROI masks (which voxels belong to which brain region)</span>
    <span class="n">voxels_per_roi</span> <span class="o">=</span> <span class="n">n_voxels</span> <span class="o">//</span> <span class="n">n_roi</span>
    <span class="n">roi_masks</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_roi</span><span class="p">):</span>
        <span class="c1"># Create binary mask for this ROI</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_voxels</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
        <span class="n">start_idx</span> <span class="o">=</span> <span class="n">r</span> <span class="o">*</span> <span class="n">voxels_per_roi</span>
        <span class="n">end_idx</span> <span class="o">=</span> <span class="p">(</span><span class="n">r</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">voxels_per_roi</span> <span class="k">if</span> <span class="n">r</span> <span class="o">&lt;</span> <span class="n">n_roi</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">n_voxels</span>
        <span class="n">mask</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:</span><span class="n">end_idx</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">roi_masks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
        
        <span class="c1"># Generate patterns for this ROI</span>
        <span class="c1"># We&#39;ll make each ROI sensitive to different stimulus features</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_stimuli</span><span class="p">):</span>
            <span class="c1"># Create a pattern that depends on stimulus index in different ways for each ROI</span>
            <span class="k">if</span> <span class="n">r</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># Early visual (e.g., V1) - sensitive to low-level features</span>
                <span class="n">pattern</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">i</span> <span class="o">/</span> <span class="mf">5.0</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">i</span> <span class="o">/</span> <span class="mf">3.0</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">r</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># Mid-level visual (e.g., V4) - sensitive to shapes</span>
                <span class="n">pattern</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">i</span> <span class="o">/</span> <span class="mf">8.0</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">i</span> <span class="o">/</span> <span class="mf">2.0</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">r</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>  <span class="c1"># Higher visual (e.g., LOC) - sensitive to objects</span>
                <span class="n">pattern</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">i</span> <span class="o">/</span> <span class="mf">10.0</span> <span class="o">-</span> <span class="mf">2.5</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>  <span class="c1"># Object category (e.g., IT) - sensitive to categories</span>
                <span class="n">pattern</span> <span class="o">=</span> <span class="p">(</span><span class="n">i</span> <span class="o">%</span> <span class="mi">5</span><span class="p">)</span> <span class="o">/</span> <span class="mf">5.0</span>  <span class="c1"># 5 categories</span>
                
            <span class="n">fmri_data</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="n">pattern</span>
    
    <span class="c1"># Add noise</span>
    <span class="n">fmri_data</span> <span class="o">+=</span> <span class="n">noise_level</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="n">fmri_data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">fmri_data</span><span class="p">,</span> <span class="n">roi_masks</span>

<span class="k">def</span><span class="w"> </span><span class="nf">simulate_cnn_activations</span><span class="p">(</span><span class="n">n_stimuli</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">units_per_layer</span><span class="o">=</span><span class="mi">250</span><span class="p">,</span> <span class="n">noise_level</span><span class="o">=</span><span class="mf">0.05</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Simulate CNN activations for the same stimuli</span>
<span class="sd">    </span>
<span class="sd">    Parameters:</span>
<span class="sd">    -----------</span>
<span class="sd">    n_stimuli : int</span>
<span class="sd">        Number of stimuli (images)</span>
<span class="sd">    n_layers : int</span>
<span class="sd">        Number of CNN layers</span>
<span class="sd">    units_per_layer : int</span>
<span class="sd">        Number of units per layer</span>
<span class="sd">    noise_level : float</span>
<span class="sd">        Level of noise to add</span>
<span class="sd">        </span>
<span class="sd">    Returns:</span>
<span class="sd">    --------</span>
<span class="sd">    cnn_activations : dict</span>
<span class="sd">        Dictionary mapping layer names to activation patterns</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">cnn_activations</span> <span class="o">=</span> <span class="p">{}</span>
    
    <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span><span class="p">):</span>
        <span class="c1"># Create activations for this layer</span>
        <span class="n">layer_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;layer</span><span class="si">{</span><span class="n">l</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="n">activations</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_stimuli</span><span class="p">,</span> <span class="n">units_per_layer</span><span class="p">))</span>
        
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_stimuli</span><span class="p">):</span>
            <span class="c1"># Create activations that depend on stimulus index in different ways for each layer</span>
            <span class="k">if</span> <span class="n">l</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># Conv1 - sensitive to edges</span>
                <span class="n">pattern</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">i</span> <span class="o">/</span> <span class="mf">5.0</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">i</span> <span class="o">/</span> <span class="mf">3.0</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">l</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># Conv2 - sensitive to textures</span>
                <span class="n">pattern</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">i</span> <span class="o">/</span> <span class="mf">7.0</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">i</span> <span class="o">/</span> <span class="mf">2.0</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">l</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>  <span class="c1"># Conv3 - sensitive to parts</span>
                <span class="n">pattern</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">i</span> <span class="o">/</span> <span class="mf">10.0</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">i</span> <span class="o">/</span> <span class="mf">4.0</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>  <span class="c1"># Conv4 - sensitive to objects</span>
                <span class="n">pattern</span> <span class="o">=</span> <span class="p">(</span><span class="n">i</span> <span class="o">%</span> <span class="mi">5</span><span class="p">)</span> <span class="o">/</span> <span class="mf">5.0</span>  <span class="c1"># 5 categories</span>
                
            <span class="n">activations</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">pattern</span> <span class="o">+</span> <span class="n">noise_level</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">units_per_layer</span><span class="p">)</span>
        
        <span class="n">cnn_activations</span><span class="p">[</span><span class="n">layer_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">activations</span>
    
    <span class="k">return</span> <span class="n">cnn_activations</span>

<span class="k">def</span><span class="w"> </span><span class="nf">compute_rdms</span><span class="p">(</span><span class="n">data_dict</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute Representational Dissimilarity Matrices (RDMs) for different regions/layers</span>
<span class="sd">    </span>
<span class="sd">    Parameters:</span>
<span class="sd">    -----------</span>
<span class="sd">    data_dict : dict</span>
<span class="sd">        Dictionary mapping region/layer names to activation patterns</span>
<span class="sd">        </span>
<span class="sd">    Returns:</span>
<span class="sd">    --------</span>
<span class="sd">    rdms : dict</span>
<span class="sd">        Dictionary mapping region/layer names to RDMs</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rdms</span> <span class="o">=</span> <span class="p">{}</span>
    
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">data_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="c1"># Compute pairwise correlation distances</span>
        <span class="n">n_stimuli</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">rdm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_stimuli</span><span class="p">,</span> <span class="n">n_stimuli</span><span class="p">))</span>
        
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_stimuli</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_stimuli</span><span class="p">):</span>
                <span class="c1"># 1 - correlation as a distance metric</span>
                <span class="n">corr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="n">j</span><span class="p">])[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
                <span class="n">dist</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">corr</span>
                <span class="n">rdm</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">dist</span>
                <span class="n">rdm</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">dist</span>
        
        <span class="n">rdms</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">rdm</span>
    
    <span class="k">return</span> <span class="n">rdms</span>

<span class="k">def</span><span class="w"> </span><span class="nf">compare_representations</span><span class="p">(</span><span class="n">brain_rdms</span><span class="p">,</span> <span class="n">model_rdms</span><span class="p">,</span> <span class="n">roi_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">layer_names</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compare brain and model representations</span>
<span class="sd">    </span>
<span class="sd">    Parameters:</span>
<span class="sd">    -----------</span>
<span class="sd">    brain_rdms : dict</span>
<span class="sd">        Dictionary mapping ROI names to brain RDMs</span>
<span class="sd">    model_rdms : dict</span>
<span class="sd">        Dictionary mapping layer names to model RDMs</span>
<span class="sd">    roi_names : list or None</span>
<span class="sd">        Names of brain ROIs</span>
<span class="sd">    layer_names : list or None</span>
<span class="sd">        Names of model layers</span>
<span class="sd">        </span>
<span class="sd">    Returns:</span>
<span class="sd">    --------</span>
<span class="sd">    similarity_matrix : numpy.ndarray</span>
<span class="sd">        Matrix of correlations between brain ROIs and model layers</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">roi_names</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">roi_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">brain_rdms</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="k">if</span> <span class="n">layer_names</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">layer_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">model_rdms</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    
    <span class="n">n_rois</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">roi_names</span><span class="p">)</span>
    <span class="n">n_layers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer_names</span><span class="p">)</span>
    
    <span class="n">similarity_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_rois</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">))</span>
    
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">roi</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">roi_names</span><span class="p">):</span>
        <span class="n">brain_rdm</span> <span class="o">=</span> <span class="n">brain_rdms</span><span class="p">[</span><span class="n">roi</span><span class="p">]</span>
        
        <span class="c1"># Extract upper triangular part (excluding diagonal)</span>
        <span class="n">triu_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">triu_indices_from</span><span class="p">(</span><span class="n">brain_rdm</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">brain_rdm_triu</span> <span class="o">=</span> <span class="n">brain_rdm</span><span class="p">[</span><span class="n">triu_indices</span><span class="p">]</span>
        
        <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">layer_names</span><span class="p">):</span>
            <span class="n">model_rdm</span> <span class="o">=</span> <span class="n">model_rdms</span><span class="p">[</span><span class="n">layer</span><span class="p">]</span>
            <span class="n">model_rdm_triu</span> <span class="o">=</span> <span class="n">model_rdm</span><span class="p">[</span><span class="n">triu_indices</span><span class="p">]</span>
            
            <span class="c1"># Compute Spearman correlation between RDMs</span>
            <span class="n">corr</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">spearmanr</span><span class="p">(</span><span class="n">brain_rdm_triu</span><span class="p">,</span> <span class="n">model_rdm_triu</span><span class="p">)</span>
            <span class="n">similarity_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">corr</span>
    
    <span class="k">return</span> <span class="n">similarity_matrix</span>

<span class="k">def</span><span class="w"> </span><span class="nf">main</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Main function to run the analysis</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># 1. Simulate brain fMRI data</span>
    <span class="n">n_stimuli</span> <span class="o">=</span> <span class="mi">50</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Simulating fMRI data...&quot;</span><span class="p">)</span>
    <span class="n">fmri_data</span><span class="p">,</span> <span class="n">roi_masks</span> <span class="o">=</span> <span class="n">simulate_fmri_data</span><span class="p">(</span><span class="n">n_stimuli</span><span class="o">=</span><span class="n">n_stimuli</span><span class="p">)</span>
    
    <span class="c1"># 2. Create brain ROI data dictionary</span>
    <span class="n">brain_data</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">roi_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;V1&quot;</span><span class="p">,</span> <span class="s2">&quot;V4&quot;</span><span class="p">,</span> <span class="s2">&quot;LOC&quot;</span><span class="p">,</span> <span class="s2">&quot;IT&quot;</span><span class="p">]</span>
    
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">roi_names</span><span class="p">,</span> <span class="n">roi_masks</span><span class="p">)):</span>
        <span class="n">brain_data</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">fmri_data</span><span class="p">[:,</span> <span class="n">mask</span><span class="p">]</span>
    
    <span class="c1"># 3. Simulate CNN activations</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Simulating CNN activations...&quot;</span><span class="p">)</span>
    <span class="n">cnn_activations</span> <span class="o">=</span> <span class="n">simulate_cnn_activations</span><span class="p">(</span><span class="n">n_stimuli</span><span class="o">=</span><span class="n">n_stimuli</span><span class="p">)</span>
    
    <span class="c1"># 4. Compute RDMs for brain ROIs and CNN layers</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Computing RDMs...&quot;</span><span class="p">)</span>
    <span class="n">brain_rdms</span> <span class="o">=</span> <span class="n">compute_rdms</span><span class="p">(</span><span class="n">brain_data</span><span class="p">)</span>
    <span class="n">model_rdms</span> <span class="o">=</span> <span class="n">compute_rdms</span><span class="p">(</span><span class="n">cnn_activations</span><span class="p">)</span>
    
    <span class="c1"># 5. Compare representations</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Comparing representations...&quot;</span><span class="p">)</span>
    <span class="n">similarity_matrix</span> <span class="o">=</span> <span class="n">compare_representations</span><span class="p">(</span><span class="n">brain_rdms</span><span class="p">,</span> <span class="n">model_rdms</span><span class="p">,</span> <span class="n">roi_names</span><span class="p">)</span>
    
    <span class="c1"># 6. Visualize results</span>
    <span class="n">layer_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">cnn_activations</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">similarity_matrix</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Representational Similarity (Spearman ρ)&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;CNN Layers&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Brain ROIs&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Brain-CNN Representational Similarity&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">layer_names</span><span class="p">)),</span> <span class="n">layer_names</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">roi_names</span><span class="p">)),</span> <span class="n">roi_names</span><span class="p">)</span>
    
    <span class="c1"># Add text annotations</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">roi_names</span><span class="p">)):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">layer_names</span><span class="p">)):</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">similarity_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">j</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> 
                    <span class="n">ha</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;white&quot;</span> <span class="k">if</span> <span class="n">similarity_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="k">else</span> <span class="s2">&quot;black&quot;</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    
    <span class="c1"># 7. Visualize RDMs</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
    
    <span class="c1"># Plot brain RDMs</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">roi_names</span><span class="p">):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">brain_rdms</span><span class="p">[</span><span class="n">name</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Brain: </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Dissimilarity&#39;</span><span class="p">)</span>
    
    <span class="c1"># Plot model RDMs</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">layer_names</span><span class="p">):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">5</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">model_rdms</span><span class="p">[</span><span class="n">name</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;CNN: </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Dissimilarity&#39;</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    
    <span class="c1"># 8. Find the best matching layer for each ROI</span>
    <span class="n">best_layers</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">roi</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">roi_names</span><span class="p">):</span>
        <span class="n">best_layer_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">similarity_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="n">best_layer</span> <span class="o">=</span> <span class="n">layer_names</span><span class="p">[</span><span class="n">best_layer_idx</span><span class="p">]</span>
        <span class="n">best_corr</span> <span class="o">=</span> <span class="n">similarity_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">best_layer_idx</span><span class="p">]</span>
        <span class="n">best_layers</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">roi</span><span class="p">,</span> <span class="n">best_layer</span><span class="p">,</span> <span class="n">best_corr</span><span class="p">))</span>
        
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Best matching CNN layer for each brain ROI:&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">roi</span><span class="p">,</span> <span class="n">layer</span><span class="p">,</span> <span class="n">corr</span> <span class="ow">in</span> <span class="n">best_layers</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">roi</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">layer</span><span class="si">}</span><span class="s2"> (ρ = </span><span class="si">{</span><span class="n">corr</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="chapter-take-aways">
<h2>19.8 Chapter Take-aways<a class="headerlink" href="#chapter-take-aways" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Cognitive neuroscience and deep learning have a bidirectional relationship, with each field informing the other</p></li>
<li><p>Key cognitive principles like attention, hierarchical processing, and predictive coding have inspired advances in deep learning architectures</p></li>
<li><p>Incorporating cognitive constraints and inductive biases can improve deep learning model performance and generalization</p></li>
<li><p>Deep learning models serve as computational theories of cognition, generating testable predictions about brain function</p></li>
<li><p>Methods like RSA, encoding models, and CCA enable direct comparisons between neural and artificial representations</p></li>
<li><p>Deep learning has provided new frameworks and tools for understanding and analyzing brain function</p></li>
<li><p>The convergence of these fields promises advances in both artificial intelligence and our understanding of human cognition</p></li>
</ul>
</section>
<section id="further-reading">
<h2>19.9 Further Reading<a class="headerlink" href="#further-reading" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Kriegeskorte, N., &amp; Douglas, P. K. (2018). Cognitive computational neuroscience. <em>Nature Neuroscience, 21</em>(9), 1148-1160.</p></li>
<li><p>Richards, B. A., et al. (2019). A deep learning framework for neuroscience. <em>Nature Neuroscience, 22</em>(11), 1761-1770.</p></li>
<li><p>Yamins, D. L., &amp; DiCarlo, J. J. (2016). Using goal-driven deep learning models to understand sensory cortex. <em>Nature Neuroscience, 19</em>(3), 356-365.</p></li>
<li><p>Saxe, A., Nelli, S., &amp; Summerfield, C. (2021). If deep learning is the answer, what is the question? <em>Nature Reviews Neuroscience, 22</em>(1), 55-67.</p></li>
<li><p>Kietzmann, T. C., McClure, P., &amp; Kriegeskorte, N. (2019). Deep neural networks in computational neuroscience. <em>Oxford Research Encyclopedia of Neuroscience</em>.</p></li>
<li><p>Naselaris, T., et al. (2021). Cognitive computational neuroscience: A normative theory of brain function. <em>Nature Neuroscience, 24</em>(2), 291-306.</p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "executablebooks/jupyter-book",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./part6"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="ch18_neuromorphic_computing.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Chapter 18: Neuromorphic Computing</p>
      </div>
    </a>
    <a class="right-next"
       href="ch20_case_studies.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Chapter 20: Case Studies in NeuroAI</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#chapter-goals">Chapter Goals</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-the-convergence-of-minds-and-machines">19.1 Introduction: The Convergence of Minds and Machines</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cognitive-science-principles-in-deep-learning">19.2 Cognitive Science Principles in Deep Learning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#attention-and-working-memory">19.2.1 Attention and Working Memory</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hierarchical-processing-and-compositionality">19.2.2 Hierarchical Processing and Compositionality</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#predictive-coding-and-generative-models">19.2.3 Predictive Coding and Generative Models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#embodied-cognition-and-active-learning">19.2.4 Embodied Cognition and Active Learning</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cognitive-constraints-in-deep-learning">19.3 Cognitive Constraints in Deep Learning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#inductive-biases-from-cognitive-science">19.3.1 Inductive Biases from Cognitive Science</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#neural-architecture-constraints">19.3.2 Neural Architecture Constraints</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cognitively-plausible-learning-mechanisms">19.3.3 Cognitively-Plausible Learning Mechanisms</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deep-learning-models-as-theories-of-cognition">19.4 Deep Learning Models as Theories of Cognition</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-deep-learning-to-test-cognitive-theories">19.4.1 Using Deep Learning to Test Cognitive Theories</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#case-studies-in-cognitive-modeling">19.4.2 Case Studies in Cognitive Modeling</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#comparing-model-behavior-to-human-behavior">19.4.3 Comparing Model Behavior to Human Behavior</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#neural-representation-comparison-methods">19.5 Neural Representation Comparison Methods</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#representational-similarity-analysis">19.5.1 Representational Similarity Analysis</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#neural-encoding-and-decoding-models">19.5.2 Neural Encoding and Decoding Models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#canonical-correlation-analysis">19.5.3 Canonical Correlation Analysis</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-impact-of-deep-learning-on-cognitive-neuroscience">19.6 The Impact of Deep Learning on Cognitive Neuroscience</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#new-frameworks-for-understanding-brain-function">19.6.1 New Frameworks for Understanding Brain Function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tools-for-neural-data-analysis">19.6.2 Tools for Neural Data Analysis</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generating-new-hypotheses">19.6.3 Generating New Hypotheses</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#practical-exercise-comparing-deep-networks-and-brain-representations">19.7 Practical Exercise: Comparing Deep Networks and Brain Representations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#chapter-take-aways">19.8 Chapter Take-aways</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#further-reading">19.9 Further Reading</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Richard Young
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2025.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>