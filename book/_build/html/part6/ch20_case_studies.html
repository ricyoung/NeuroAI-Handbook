
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Chapter 20: Case Studies in NeuroAI &#8212; The Neuroscience of AI</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'part6/ch20_case_studies';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="canonical" href="https://neuroai-handbook.github.io/part6/ch20_case_studies.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Interactive Examples for Case Studies in NeuroAI" href="ch20_interactive.html" />
    <link rel="prev" title="Cognitive Neuroscience and Deep Learning" href="ch19_cognitive_neuro_dl.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/nai.png" class="logo__image only-light" alt="The Neuroscience of AI - Home"/>
    <script>document.write(`<img src="../_static/nai.png" class="logo__image only-dark" alt="The Neuroscience of AI - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    The Neuroscience of AI
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Part I · Brains &amp; Inspiration</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../part1/ch01_intro.html">Chapter 1: Introduction to Neuroscience ↔ AI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part1/ch02_neuro_foundations.html">Chapter 2: Neuroscience Foundations for AI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part1/ch03_spatial_navigation.html">Chapter 3: Spatial Navigation – Place &amp; Grid Cells</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part1/ch04_perception_pipeline.html">Chapter 4: Perception Pipeline – Visual Cortex → CNNs</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part II · Brains Meet Math &amp; Data</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../part2/ch05_brain_networks.html">Chapter 5: Default-Mode vs Executive Control Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part2/ch06_neurostimulation.html">Chapter 6: Neurostimulation &amp; Plasticity</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part2/ch07_information_theory.html">Chapter 7: Information Theory Essentials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part2/ch08_data_science_pipeline.html">Chapter 8: Data-Science Pipeline in Python</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part III · Learning Machines</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../part3/ch09_ml_foundations.html">Chapter 9: Classical Machine-Learning Foundations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part3/ch10_deep_learning.html">Chapter 10: Deep Learning: Training &amp; Optimisation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part3/ch11_sequence_models.html">Chapter 11: Sequence Models: RNN → Attention → Transformer</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part IV · Frontier Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../part4/ch12_large_language_models.html">Chapter 12: Large Language Models &amp; Fine-Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part4/ch13_multimodal_models.html">Chapter 13: Multimodal &amp; Diffusion Models</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part V · Ethics &amp; Futures</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../part5/ch15_ethical_ai.html">Chapter 15: Ethical AI - Considerations for NeuroAI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part5/ch16_future_directions.html">Chapter 16: Where Next for Neuro-AI?</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part VI · Advanced Applications</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="ch17_bci_human_ai_interfaces.html">Brain-Computer Interfaces and Human-AI Interaction</a></li>
<li class="toctree-l1"><a class="reference internal" href="ch18_neuromorphic_computing.html">Chapter 18: Neuromorphic Computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="ch19_cognitive_neuro_dl.html">Cognitive Neuroscience and Deep Learning</a></li>
<li class="toctree-l1 current active has-children"><a class="current reference internal" href="#">Case Studies in NeuroAI</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="ch20_interactive.html">Interactive NeuroAI Case Studies</a></li>
<li class="toctree-l2"><a class="reference internal" href="jupyter_ai_demo.html">AI-Assisted Learning with Jupyter AI</a></li>
<li class="toctree-l2"><a class="reference internal" href="rise_slides_demo.html">Creating Presentations with RISE</a></li>


</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="ch21_ai_for_neuro_discovery.html">Chapter 21: AI for Neuroscience Discovery</a></li>
<li class="toctree-l1"><a class="reference internal" href="ch22_embodied_ai_robotics.html">Chapter 22: Embodied AI and Robotics</a></li>
<li class="toctree-l1"><a class="reference internal" href="ch23_lifelong_learning.html">Chapter 23: Lifelong Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="ch24_quantum_computing_neuroai.html">Chapter 24: Quantum Computing and NeuroAI</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Appendices</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../appendices/glossary.html">Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../appendices/math_python_refresher.html">Appendix A: Math &amp; Python Mini-Refresher</a></li>
<li class="toctree-l1"><a class="reference internal" href="../appendices/dataset_catalogue.html">Appendix B: Dataset Catalogue</a></li>
<li class="toctree-l1"><a class="reference internal" href="../appendices/colab_setup.html">Appendix C: Google Colab Setup for NeuroAI</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/edit/master/docs/part6/ch20_case_studies.md" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fpart6/ch20_case_studies.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/part6/ch20_case_studies.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Chapter 20: Case Studies in NeuroAI</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#chapter-goals">Chapter Goals</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-from-theory-to-practice">20.1 Introduction: From Theory to Practice</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#case-study-deep-predictive-coding-networks">20.2 Case Study: Deep Predictive Coding Networks</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#background-and-motivation">20.2.1 Background and Motivation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implementation-prednet-architecture">20.2.2 Implementation: PredNet Architecture</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#results-and-evaluation">20.2.3 Results and Evaluation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#neuroscience-connection">20.2.4 Neuroscience Connection</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#limitations-and-future-directions">20.2.5 Limitations and Future Directions</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#case-study-hippocampal-replay-for-reinforcement-learning">20.3 Case Study: Hippocampal Replay for Reinforcement Learning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">20.3.1 Background and Motivation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implementation-prioritized-experience-replay">20.3.2 Implementation: Prioritized Experience Replay</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">20.3.3 Results and Evaluation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">20.3.4 Neuroscience Connection</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">20.3.5 Limitations and Future Directions</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#case-study-attention-mechanisms-in-vision-transformers">20.4 Case Study: Attention Mechanisms in Vision Transformers</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">20.4.1 Background and Motivation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implementation-vision-transformer">20.4.2 Implementation: Vision Transformer</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">20.4.3 Results and Evaluation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">20.4.4 Neuroscience Connection</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">20.4.5 Limitations and Future Directions</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#case-study-neural-data-analysis-with-latent-variable-models">20.5 Case Study: Neural Data Analysis with Latent Variable Models</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">20.5.1 Background and Motivation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implementation-latent-factor-analysis-via-dynamical-systems-lfads">20.5.2 Implementation: Latent Factor Analysis via Dynamical Systems (LFADS)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">20.5.3 Results and Evaluation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">20.5.4 Neuroscience Connection</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">20.5.5 Limitations and Future Directions</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lessons-from-successful-neuroai-integration">20.6 Lessons from Successful NeuroAI Integration</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#common-patterns-of-success">20.6.1 Common Patterns of Success</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#practical-implementation-strategies">20.6.2 Practical Implementation Strategies</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interdisciplinary-collaboration-best-practices">20.6.3 Interdisciplinary Collaboration Best Practices</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#practical-exercise-implementing-a-neuroscience-inspired-ai-component">20.7 Practical Exercise: Implementing a Neuroscience-Inspired AI Component</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#chapter-take-aways">20.8 Chapter Take-aways</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interactive-materials-and-exercises">20.9 Interactive Materials and Exercises</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ai-assisted-learning">AI-Assisted Learning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#presentation-materials">Presentation Materials</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#further-reading">20.10 Further Reading</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="chapter-20-case-studies-in-neuroai">
<h1>Chapter 20: Case Studies in NeuroAI<a class="headerlink" href="#chapter-20-case-studies-in-neuroai" title="Link to this heading">#</a></h1>
<section id="chapter-goals">
<h2>Chapter Goals<a class="headerlink" href="#chapter-goals" title="Link to this heading">#</a></h2>
<p>After completing this chapter, you will be able to:</p>
<ul class="simple">
<li><p>Analyze real-world applications where neuroscience has successfully informed AI development</p></li>
<li><p>Evaluate the practical benefits of incorporating neuroscience principles into AI systems</p></li>
<li><p>Identify common patterns and successful strategies across different NeuroAI projects</p></li>
<li><p>Apply lessons from case studies to your own research or development projects</p></li>
<li><p>Understand the specific challenges and solutions in translating neuroscience insights to AI implementations</p></li>
<li><p>Recognize key success factors for interdisciplinary collaboration between neuroscience and AI</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This chapter features interactive examples to help you explore key concepts. Click the “launch binder” button at the top of the page or access the <a class="reference internal" href="ch20_interactive.html"><span class="std std-doc">interactive notebook</span></a> to experiment with:</p>
<ul class="simple">
<li><p>Interactive PredNet visualization</p></li>
<li><p>Prioritized Experience Replay simulation</p></li>
<li><p>Vision Transformer attention mechanism</p></li>
<li><p>Interactive glossary with neural-AI connections</p></li>
</ul>
<p>For an enhanced learning experience, we’ve also integrated <a class="reference internal" href="jupyter_ai_demo.html"><span class="std std-doc">Jupyter AI assistance</span></a> to help you generate code, get explanations, and create visualizations based on the case studies.</p>
</div>
</section>
<section id="introduction-from-theory-to-practice">
<h2>20.1 Introduction: From Theory to Practice<a class="headerlink" href="#introduction-from-theory-to-practice" title="Link to this heading">#</a></h2>
<p>Throughout this handbook, we’ve explored the theoretical foundations of both neuroscience and artificial intelligence, examining how these fields inform and enrich each other. This chapter shifts our focus to real-world implementations, presenting detailed case studies that demonstrate how neuroscience principles have been successfully translated into practical AI systems.</p>
<p>These case studies represent the cutting edge of NeuroAI—where theory meets application, where biological insights drive technological innovation, and where interdisciplinary collaboration yields solutions that neither field could achieve alone. By examining these concrete examples, we gain valuable insights into the practical challenges and benefits of neuroscience-inspired AI approaches.</p>
</section>
<section id="case-study-deep-predictive-coding-networks">
<h2>20.2 Case Study: Deep Predictive Coding Networks<a class="headerlink" href="#case-study-deep-predictive-coding-networks" title="Link to this heading">#</a></h2>
<section id="background-and-motivation">
<h3>20.2.1 Background and Motivation<a class="headerlink" href="#background-and-motivation" title="Link to this heading">#</a></h3>
<p>Predictive coding is a neuroscience theory proposing that the brain constantly generates predictions about incoming sensory information and updates its internal models based on prediction errors. This first case study examines how predictive coding has been implemented in deep learning architectures to improve robustness and efficiency.</p>
</section>
<section id="implementation-prednet-architecture">
<h3>20.2.2 Implementation: PredNet Architecture<a class="headerlink" href="#implementation-prednet-architecture" title="Link to this heading">#</a></h3>
<p>The PredNet architecture, developed by William Lotter, Gabriel Kreiman, and David Cox, implements hierarchical predictive coding in a deep learning framework:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tensorflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tf</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras</span><span class="w"> </span><span class="kn">import</span> <span class="n">layers</span><span class="p">,</span> <span class="n">Model</span>

<span class="k">class</span><span class="w"> </span><span class="nc">PredNetBlock</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Implementation of a single layer of the PredNet architecture</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_channels</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize PredNet block</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        num_channels : int</span>
<span class="sd">            Number of feature channels in this layer</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PredNetBlock</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_channels</span> <span class="o">=</span> <span class="n">num_channels</span>
        
        <span class="c1"># Convolutional layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv_pred</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">num_channels</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv_error_pos</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">num_channels</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv_error_neg</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">num_channels</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv_representation</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">num_channels</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)</span>
        
        <span class="c1"># Pooling and upsampling</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
        
    <span class="k">def</span><span class="w"> </span><span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Forward pass through the PredNet block</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        inputs : tuple</span>
<span class="sd">            (current_input, representation_from_higher_layer)</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">        --------</span>
<span class="sd">        outputs : tuple</span>
<span class="sd">            (error, updated_representation, pooled_representation)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">current_input</span><span class="p">,</span> <span class="n">higher_representation</span> <span class="o">=</span> <span class="n">inputs</span>
        
        <span class="c1"># Generate prediction from higher layer representation</span>
        <span class="k">if</span> <span class="n">higher_representation</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">prediction</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_pred</span><span class="p">(</span><span class="n">higher_representation</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># For the top layer, prediction is zeros</span>
            <span class="n">prediction</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">current_input</span><span class="p">)</span>
        
        <span class="c1"># Compute prediction error</span>
        <span class="n">error</span> <span class="o">=</span> <span class="n">current_input</span> <span class="o">-</span> <span class="n">prediction</span>
        
        <span class="c1"># Split error into positive and negative components</span>
        <span class="n">pos_error</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>
        <span class="n">neg_error</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="o">-</span><span class="n">error</span><span class="p">)</span>
        
        <span class="c1"># Process error</span>
        <span class="n">error_processed_pos</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_error_pos</span><span class="p">(</span><span class="n">pos_error</span><span class="p">)</span>
        <span class="n">error_processed_neg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_error_neg</span><span class="p">(</span><span class="n">neg_error</span><span class="p">)</span>
        
        <span class="c1"># Combine processed errors</span>
        <span class="n">combined_error</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">error_processed_pos</span><span class="p">,</span> <span class="n">error_processed_neg</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="c1"># Update representation based on combined error</span>
        <span class="n">representation</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_representation</span><span class="p">(</span><span class="n">combined_error</span><span class="p">)</span>
        
        <span class="c1"># Pool representation for the next higher layer</span>
        <span class="n">pooled_representation</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">representation</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">error</span><span class="p">,</span> <span class="n">representation</span><span class="p">,</span> <span class="n">pooled_representation</span>

<span class="k">class</span><span class="w"> </span><span class="nc">PredNet</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Implementation of the PredNet architecture for predictive coding</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stack_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize PredNet model</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        stack_sizes : tuple of int</span>
<span class="sd">            Number of channels in each layer of the network,</span>
<span class="sd">            from input to highest layer</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PredNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stack_sizes</span> <span class="o">=</span> <span class="n">stack_sizes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">stack_sizes</span><span class="p">)</span>
        
        <span class="c1"># Create PredNet blocks for each layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">blocks</span> <span class="o">=</span> <span class="p">[</span><span class="n">PredNetBlock</span><span class="p">(</span><span class="n">stack_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span><span class="p">)]</span>
        
        <span class="c1"># Upsampling layers for top-down connections</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">upsample_layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">layers</span><span class="o">.</span><span class="n">UpSampling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)]</span>
        
    <span class="k">def</span><span class="w"> </span><span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Forward pass through the PredNet</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        inputs : tf.Tensor</span>
<span class="sd">            Input image or sequence</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">        --------</span>
<span class="sd">        outputs : dict</span>
<span class="sd">            Dictionary containing predictions, errors, and representations</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Initialize lists to store layer-wise outputs</span>
        <span class="n">errors</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">representations</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="c1"># Bottom-up pass</span>
        <span class="n">current_input</span> <span class="o">=</span> <span class="n">inputs</span>
        <span class="n">higher_representations</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span>
        
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span><span class="p">):</span>
            <span class="c1"># Process through current layer</span>
            <span class="n">error</span><span class="p">,</span> <span class="n">representation</span><span class="p">,</span> <span class="n">pooled</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">blocks</span><span class="p">[</span><span class="n">i</span><span class="p">]([</span><span class="n">current_input</span><span class="p">,</span> <span class="n">higher_representations</span><span class="p">[</span><span class="n">i</span><span class="p">]])</span>
            
            <span class="c1"># Store results</span>
            <span class="n">errors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>
            <span class="n">representations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">representation</span><span class="p">)</span>
            
            <span class="c1"># Set input for next layer</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">current_input</span> <span class="o">=</span> <span class="n">pooled</span>
        
        <span class="c1"># Top-down pass to update higher representations</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)):</span>
            <span class="c1"># Upsample representation from higher layer</span>
            <span class="n">higher_rep</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">upsample_layers</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">representations</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>
            <span class="n">higher_representations</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">higher_rep</span>
        
        <span class="c1"># Return all outputs</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;errors&#39;</span><span class="p">:</span> <span class="n">errors</span><span class="p">,</span>
            <span class="s1">&#39;representations&#39;</span><span class="p">:</span> <span class="n">representations</span>
        <span class="p">}</span>
        
        <span class="k">return</span> <span class="n">outputs</span>

<span class="k">def</span><span class="w"> </span><span class="nf">build_prednet_model</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">sequence_length</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Build a PredNet model for sequence prediction</span>
<span class="sd">    </span>
<span class="sd">    Parameters:</span>
<span class="sd">    -----------</span>
<span class="sd">    input_shape : tuple</span>
<span class="sd">        Shape of input images (height, width, channels)</span>
<span class="sd">    sequence_length : int</span>
<span class="sd">        Number of frames in input sequences</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">    --------</span>
<span class="sd">    model : tf.keras.Model</span>
<span class="sd">        Complete PredNet model</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Create input layer for sequence</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">sequence_length</span><span class="p">,)</span> <span class="o">+</span> <span class="n">input_shape</span><span class="p">)</span>
    
    <span class="c1"># Time-distributed PredNet to process sequences</span>
    <span class="n">prednet</span> <span class="o">=</span> <span class="n">PredNet</span><span class="p">()</span>
    <span class="n">td_prednet</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">TimeDistributed</span><span class="p">(</span><span class="n">prednet</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
    
    <span class="c1"># Combine outputs across time steps</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">):</span>
        <span class="c1"># Use previous frame&#39;s representation to predict next frame</span>
        <span class="n">prev_representation</span> <span class="o">=</span> <span class="n">td_prednet</span><span class="p">[:,</span> <span class="n">t</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="s1">&#39;representations&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># Top layer representation</span>
        <span class="n">prediction</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">)(</span><span class="n">prev_representation</span><span class="p">)</span>
        <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">prediction</span><span class="p">)</span>
    
    <span class="c1"># Stack predictions along time dimension</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))(</span><span class="n">outputs</span><span class="p">)</span>
    
    <span class="c1"># Create model</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">predictions</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
</section>
<section id="results-and-evaluation">
<h3>20.2.3 Results and Evaluation<a class="headerlink" href="#results-and-evaluation" title="Link to this heading">#</a></h3>
<p>The PredNet architecture was evaluated on several computer vision tasks:</p>
<ol class="arabic simple">
<li><p><strong>Video prediction</strong>: PredNet demonstrated superior performance in predicting future frames in natural video sequences, particularly in handling object motion and occlusion.</p></li>
<li><p><strong>Sample efficiency</strong>: Compared to standard CNNs, PredNet required significantly fewer training examples to achieve comparable performance on object recognition tasks.</p></li>
<li><p><strong>Error representation</strong>: The explicit representation of prediction errors allowed the model to highlight unexpected or novel events in sequences.</p></li>
</ol>
</section>
<section id="neuroscience-connection">
<h3>20.2.4 Neuroscience Connection<a class="headerlink" href="#neuroscience-connection" title="Link to this heading">#</a></h3>
<p>This implementation connects to neuroscience in several ways:</p>
<ul class="simple">
<li><p><strong>Hierarchical processing</strong>: The layer-wise organization mirrors the hierarchical structure of the visual cortex.</p></li>
<li><p><strong>Prediction errors</strong>: The explicit computation of prediction errors corresponds to theories about error-signaling neurons in the brain.</p></li>
<li><p><strong>Bidirectional processing</strong>: The combination of bottom-up and top-down signals aligns with bidirectional information flow in the visual system.</p></li>
</ul>
</section>
<section id="limitations-and-future-directions">
<h3>20.2.5 Limitations and Future Directions<a class="headerlink" href="#limitations-and-future-directions" title="Link to this heading">#</a></h3>
<p>While successful, the PredNet implementation faced several challenges:</p>
<ol class="arabic simple">
<li><p><strong>Computational efficiency</strong>: The bidirectional processing increases computational demands compared to standard feed-forward networks.</p></li>
<li><p><strong>Hyperparameter sensitivity</strong>: Performance is sensitive to the balance between bottom-up and top-down signals.</p></li>
<li><p><strong>Future work</strong>: Ongoing research is exploring adaptive weighting of prediction errors and integration with reinforcement learning frameworks.</p></li>
</ol>
</section>
</section>
<section id="case-study-hippocampal-replay-for-reinforcement-learning">
<h2>20.3 Case Study: Hippocampal Replay for Reinforcement Learning<a class="headerlink" href="#case-study-hippocampal-replay-for-reinforcement-learning" title="Link to this heading">#</a></h2>
<section id="id1">
<h3>20.3.1 Background and Motivation<a class="headerlink" href="#id1" title="Link to this heading">#</a></h3>
<p>The hippocampus plays a crucial role in memory consolidation, with “replay” events during sleep and rest periods helping to transfer experiences to long-term memory. This case study examines how hippocampal replay mechanisms have been incorporated into reinforcement learning systems to improve learning efficiency and generalization.</p>
</section>
<section id="implementation-prioritized-experience-replay">
<h3>20.3.2 Implementation: Prioritized Experience Replay<a class="headerlink" href="#implementation-prioritized-experience-replay" title="Link to this heading">#</a></h3>
<p>Deep Q-Networks with Prioritized Experience Replay, developed by researchers at DeepMind, implement a biologically-inspired memory system:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tensorflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tf</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">random</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras</span><span class="w"> </span><span class="kn">import</span> <span class="n">layers</span><span class="p">,</span> <span class="n">Model</span><span class="p">,</span> <span class="n">optimizers</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">deque</span>

<span class="k">class</span><span class="w"> </span><span class="nc">SumTree</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A sum tree data structure for efficient sampling based on priorities</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">capacity</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the sum tree</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        capacity : int</span>
<span class="sd">            Maximum number of experiences to store</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">capacity</span> <span class="o">=</span> <span class="n">capacity</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tree</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">capacity</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">capacity</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_entries</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">write_index</span> <span class="o">=</span> <span class="mi">0</span>
        
    <span class="k">def</span><span class="w"> </span><span class="nf">_propagate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="n">change</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Update the sum tree by propagating a value change up the tree</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">parent</span> <span class="o">=</span> <span class="p">(</span><span class="n">idx</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">tree</span><span class="p">[</span><span class="n">parent</span><span class="p">]</span> <span class="o">+=</span> <span class="n">change</span>
        
        <span class="k">if</span> <span class="n">parent</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_propagate</span><span class="p">(</span><span class="n">parent</span><span class="p">,</span> <span class="n">change</span><span class="p">)</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">_retrieve</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="n">s</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Find the index of the leaf node where s falls within its priority range</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">left</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">right</span> <span class="o">=</span> <span class="n">left</span> <span class="o">+</span> <span class="mi">1</span>
        
        <span class="k">if</span> <span class="n">left</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tree</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">idx</span>
        
        <span class="k">if</span> <span class="n">s</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tree</span><span class="p">[</span><span class="n">left</span><span class="p">]:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_retrieve</span><span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_retrieve</span><span class="p">(</span><span class="n">right</span><span class="p">,</span> <span class="n">s</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">tree</span><span class="p">[</span><span class="n">left</span><span class="p">])</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">total</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return the total priority sum</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tree</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">add</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a new experience with priority p</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">write_index</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">capacity</span> <span class="o">-</span> <span class="mi">1</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">write_index</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">write_index</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">write_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">capacity</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_entries</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">capacity</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_entries</span> <span class="o">+=</span> <span class="mi">1</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Update the priority of an existing experience</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">change</span> <span class="o">=</span> <span class="n">p</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">tree</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">tree</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">p</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_propagate</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="n">change</span><span class="p">)</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">get</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">s</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get an experience using priority-based sampling</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_retrieve</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
        <span class="n">data_idx</span> <span class="o">=</span> <span class="n">idx</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">capacity</span> <span class="o">+</span> <span class="mi">1</span>
        
        <span class="k">return</span> <span class="n">idx</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tree</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">data_idx</span><span class="p">]</span>

<span class="k">class</span><span class="w"> </span><span class="nc">PrioritizedReplayBuffer</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Prioritized experience replay buffer for efficient and effective learning</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">capacity</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">beta_increment</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the prioritized replay buffer</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        capacity : int</span>
<span class="sd">            Maximum number of experiences to store</span>
<span class="sd">        alpha : float</span>
<span class="sd">            Controls how much prioritization is used (0 = no prioritization, 1 = full prioritization)</span>
<span class="sd">        beta : float</span>
<span class="sd">            Controls importance sampling weights (0 = no correction, 1 = full correction)</span>
<span class="sd">        beta_increment : float</span>
<span class="sd">            Amount to increase beta over time</span>
<span class="sd">        epsilon : float</span>
<span class="sd">            Small value added to priorities to ensure non-zero probabilities</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tree</span> <span class="o">=</span> <span class="n">SumTree</span><span class="p">(</span><span class="n">capacity</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">capacity</span> <span class="o">=</span> <span class="n">capacity</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">beta</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta_increment</span> <span class="o">=</span> <span class="n">beta_increment</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_priority</span> <span class="o">=</span> <span class="mf">1.0</span>
        
    <span class="k">def</span><span class="w"> </span><span class="nf">add</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">experience</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add an experience to the buffer with maximum priority</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">priority</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_priority</span> <span class="o">**</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tree</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">priority</span><span class="p">,</span> <span class="n">experience</span><span class="p">)</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sample a batch of experiences based on their priorities</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">priorities</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        
        <span class="c1"># Calculate the priority segment</span>
        <span class="n">total_priority</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tree</span><span class="o">.</span><span class="n">total</span><span class="p">()</span>
        <span class="n">segment</span> <span class="o">=</span> <span class="n">total_priority</span> <span class="o">/</span> <span class="n">batch_size</span>
        
        <span class="c1"># Increase beta each time we sample</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta_increment</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
            <span class="c1"># Sample a value from the segment</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">segment</span> <span class="o">*</span> <span class="n">i</span>
            <span class="n">b</span> <span class="o">=</span> <span class="n">segment</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">s</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
            
            <span class="c1"># Retrieve the experience</span>
            <span class="n">idx</span><span class="p">,</span> <span class="n">priority</span><span class="p">,</span> <span class="n">experience</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tree</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
            
            <span class="c1"># Store the experience and its index</span>
            <span class="n">batch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">experience</span><span class="p">)</span>
            <span class="n">indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>
            <span class="n">priorities</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">priority</span>
        
        <span class="c1"># Calculate importance sampling weights</span>
        <span class="n">sampling_probabilities</span> <span class="o">=</span> <span class="n">priorities</span> <span class="o">/</span> <span class="n">total_priority</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">capacity</span> <span class="o">*</span> <span class="n">sampling_probabilities</span><span class="p">)</span> <span class="o">**</span> <span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">)</span>
        <span class="n">weights</span> <span class="o">/=</span> <span class="n">weights</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>  <span class="c1"># Normalize weights</span>
        
        <span class="k">return</span> <span class="n">batch</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">weights</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">update_priorities</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">priorities</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Update the priorities of sampled experiences</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">priority</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">priorities</span><span class="p">):</span>
            <span class="c1"># Add a small value to ensure non-zero probabilities</span>
            <span class="n">priority</span> <span class="o">=</span> <span class="p">(</span><span class="n">priority</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">)</span> <span class="o">**</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">max_priority</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_priority</span><span class="p">,</span> <span class="n">priority</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tree</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="n">priority</span><span class="p">)</span>

<span class="k">class</span><span class="w"> </span><span class="nc">DQNWithPER</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Deep Q-Network with Prioritized Experience Replay</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dim</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">,</span> 
                 <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> 
                 <span class="n">gamma</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span>
                 <span class="n">per_alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span>
                 <span class="n">per_beta</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span>
                 <span class="n">per_beta_increment</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
                 <span class="n">replay_capacity</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span>
                 <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
                 <span class="n">target_update_freq</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the DQN with PER agent</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        state_dim : tuple</span>
<span class="sd">            Dimensions of the state space</span>
<span class="sd">        action_dim : int</span>
<span class="sd">            Dimension of the action space</span>
<span class="sd">        learning_rate : float</span>
<span class="sd">            Learning rate for the optimizer</span>
<span class="sd">        gamma : float</span>
<span class="sd">            Discount factor for future rewards</span>
<span class="sd">        per_alpha : float</span>
<span class="sd">            Controls how much prioritization is used</span>
<span class="sd">        per_beta : float</span>
<span class="sd">            Controls importance sampling weights</span>
<span class="sd">        per_beta_increment : float</span>
<span class="sd">            Amount to increase beta over time</span>
<span class="sd">        replay_capacity : int</span>
<span class="sd">            Capacity of the replay buffer</span>
<span class="sd">        batch_size : int</span>
<span class="sd">            Size of batches for training</span>
<span class="sd">        target_update_freq : int</span>
<span class="sd">            Frequency of target network updates</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state_dim</span> <span class="o">=</span> <span class="n">state_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_dim</span> <span class="o">=</span> <span class="n">action_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_update_freq</span> <span class="o">=</span> <span class="n">target_update_freq</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">step_counter</span> <span class="o">=</span> <span class="mi">0</span>
        
        <span class="c1"># Create replay buffer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span> <span class="o">=</span> <span class="n">PrioritizedReplayBuffer</span><span class="p">(</span>
            <span class="n">capacity</span><span class="o">=</span><span class="n">replay_capacity</span><span class="p">,</span>
            <span class="n">alpha</span><span class="o">=</span><span class="n">per_alpha</span><span class="p">,</span>
            <span class="n">beta</span><span class="o">=</span><span class="n">per_beta</span><span class="p">,</span>
            <span class="n">beta_increment</span><span class="o">=</span><span class="n">per_beta_increment</span>
        <span class="p">)</span>
        
        <span class="c1"># Create Q networks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q_network</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_q_network</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_q_network</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_q_network</span><span class="p">()</span>
        
        <span class="c1"># Use Mean Squared Error for loss</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
        
        <span class="c1"># Initialize target network weights to match Q-network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_update_target_network</span><span class="p">()</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">_build_q_network</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Build the Q-network</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">        --------</span>
<span class="sd">        model : tf.keras.Model</span>
<span class="sd">            The Q-network model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dim</span><span class="p">)</span>
        
        <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_dim</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">model</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">_update_target_network</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Update target network weights</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_q_network</span><span class="o">.</span><span class="n">set_weights</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_network</span><span class="o">.</span><span class="n">get_weights</span><span class="p">())</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">select_action</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Select an action using epsilon-greedy policy</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        state : np.ndarray</span>
<span class="sd">            Current state</span>
<span class="sd">        epsilon : float</span>
<span class="sd">            Exploration rate</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">        --------</span>
<span class="sd">        action : int</span>
<span class="sd">            Selected action</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">epsilon</span><span class="p">:</span>
            <span class="c1"># Explore: select a random action</span>
            <span class="k">return</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Exploit: select the best action according to the Q-network</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">q_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_network</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">state</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">q_values</span><span class="p">)</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">store_experience</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">done</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Store an experience in the replay buffer</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        state : np.ndarray</span>
<span class="sd">            Current state</span>
<span class="sd">        action : int</span>
<span class="sd">            Selected action</span>
<span class="sd">        reward : float</span>
<span class="sd">            Received reward</span>
<span class="sd">        next_state : np.ndarray</span>
<span class="sd">            Next state</span>
<span class="sd">        done : bool</span>
<span class="sd">            Whether the episode is done</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">experience</span> <span class="o">=</span> <span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">done</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">experience</span><span class="p">)</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Train the Q-network</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">        --------</span>
<span class="sd">        loss : float</span>
<span class="sd">            Training loss</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Check if we have enough experiences</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="o">.</span><span class="n">tree</span><span class="o">.</span><span class="n">n_entries</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">0</span>
        
        <span class="c1"># Sample a batch from the replay buffer</span>
        <span class="n">batch</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
        
        <span class="c1"># Unzip the batch</span>
        <span class="n">states</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">next_states</span><span class="p">,</span> <span class="n">dones</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">batch</span><span class="p">)</span>
        
        <span class="c1"># Convert to numpy arrays</span>
        <span class="n">states</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">states</span><span class="p">)</span>
        <span class="n">next_states</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">next_states</span><span class="p">)</span>
        <span class="n">actions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span>
        <span class="n">rewards</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">rewards</span><span class="p">)</span>
        <span class="n">dones</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dones</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
        
        <span class="c1"># Calculate target Q-values</span>
        <span class="n">target_q_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_q_network</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">next_states</span><span class="p">)</span>
        <span class="n">max_target_q_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">target_q_values</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">targets</span> <span class="o">=</span> <span class="n">rewards</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">dones</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">max_target_q_values</span>
        
        <span class="c1"># Train the Q-network</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
            <span class="c1"># Get the Q-values for the selected actions</span>
            <span class="n">q_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_network</span><span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">one_hot_actions</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">actions</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_dim</span><span class="p">)</span>
            <span class="n">selected_q_values</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">q_values</span> <span class="o">*</span> <span class="n">one_hot_actions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            
            <span class="c1"># Calculate TD errors for priority update</span>
            <span class="n">td_errors</span> <span class="o">=</span> <span class="n">targets</span> <span class="o">-</span> <span class="n">selected_q_values</span>
            
            <span class="c1"># Calculate weighted loss</span>
            <span class="n">losses</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">td_errors</span><span class="p">)</span> <span class="o">*</span> <span class="n">weights</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span>
        
        <span class="c1"># Get gradients and apply them</span>
        <span class="n">grads</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_network</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_network</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>
        
        <span class="c1"># Update priorities in the replay buffer</span>
        <span class="n">priorities</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">td_errors</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">replay_buffer</span><span class="o">.</span><span class="n">update_priorities</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">priorities</span><span class="p">)</span>
        
        <span class="c1"># Update target network periodically</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">step_counter</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">step_counter</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_update_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_update_target_network</span><span class="p">()</span>
        
        <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="id2">
<h3>20.3.3 Results and Evaluation<a class="headerlink" href="#id2" title="Link to this heading">#</a></h3>
<p>PER demonstrated significant improvements over standard experience replay in reinforcement learning tasks:</p>
<ol class="arabic simple">
<li><p><strong>Faster learning</strong>: Systems with PER converged to optimal policies in 50% fewer training steps on Atari games.</p></li>
<li><p><strong>Better performance</strong>: Final performance was improved by approximately 20% across a range of reinforcement learning benchmarks.</p></li>
<li><p><strong>Improved exploration</strong>: The prioritization of surprising experiences led to more effective exploration of the state space.</p></li>
</ol>
</section>
<section id="id3">
<h3>20.3.4 Neuroscience Connection<a class="headerlink" href="#id3" title="Link to this heading">#</a></h3>
<p>The implementation connects to hippocampal replay in several ways:</p>
<ul class="simple">
<li><p><strong>Memory prioritization</strong>: Just as the hippocampus preferentially replays behaviorally relevant experiences, PER revisits experiences with high learning value.</p></li>
<li><p><strong>Surprise-based learning</strong>: The prioritization based on TD error parallels the brain’s tendency to strengthen memories associated with unexpected outcomes.</p></li>
<li><p><strong>Interleaved learning</strong>: Both biological replay and PER address the stability-plasticity dilemma by interleaving experiences.</p></li>
</ul>
</section>
<section id="id4">
<h3>20.3.5 Limitations and Future Directions<a class="headerlink" href="#id4" title="Link to this heading">#</a></h3>
<p>Key challenges and future directions include:</p>
<ol class="arabic simple">
<li><p><strong>Efficient implementation</strong>: The tree-based sampling structure introduces additional computational overhead.</p></li>
<li><p><strong>Parameter sensitivity</strong>: Performance depends on appropriate settings for alpha and beta parameters.</p></li>
<li><p><strong>Future work</strong>: Ongoing research is exploring integrating episodic memory structures and context-dependent replay strategies.</p></li>
</ol>
</section>
</section>
<section id="case-study-attention-mechanisms-in-vision-transformers">
<h2>20.4 Case Study: Attention Mechanisms in Vision Transformers<a class="headerlink" href="#case-study-attention-mechanisms-in-vision-transformers" title="Link to this heading">#</a></h2>
<section id="id5">
<h3>20.4.1 Background and Motivation<a class="headerlink" href="#id5" title="Link to this heading">#</a></h3>
<p>Visual attention in humans allows for selective processing of relevant information while filtering out distractions. This case study examines how principles from visual neuroscience informed the development of Vision Transformers (ViT), which revolutionized computer vision by applying attention mechanisms to visual data.</p>
</section>
<section id="implementation-vision-transformer">
<h3>20.4.2 Implementation: Vision Transformer<a class="headerlink" href="#implementation-vision-transformer" title="Link to this heading">#</a></h3>
<p>The Vision Transformer, developed by researchers at Google, applies the transformer architecture to image classification:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">tensorflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tf</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras</span><span class="w"> </span><span class="kn">import</span> <span class="n">layers</span><span class="p">,</span> <span class="n">Model</span>

<span class="k">class</span><span class="w"> </span><span class="nc">PatchExtractor</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Extract patches from images</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">patch_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PatchExtractor</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">patch_size</span> <span class="o">=</span> <span class="n">patch_size</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">images</span><span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">images</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">patches</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">extract_patches</span><span class="p">(</span>
            <span class="n">images</span><span class="o">=</span><span class="n">images</span><span class="p">,</span>
            <span class="n">sizes</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">patch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">patch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">patch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">patch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">rates</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;VALID&quot;</span>
        <span class="p">)</span>
        <span class="n">patch_dims</span> <span class="o">=</span> <span class="n">patches</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">patches</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">patches</span><span class="p">,</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">patch_dims</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">patches</span>

<span class="k">class</span><span class="w"> </span><span class="nc">PositionalEmbedding</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Add positional embeddings to patch embeddings</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_patches</span><span class="p">,</span> <span class="n">projection_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PositionalEmbedding</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">position_embedding</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span>
            <span class="n">input_dim</span><span class="o">=</span><span class="n">num_patches</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>  <span class="c1"># +1 for the class token</span>
            <span class="n">output_dim</span><span class="o">=</span><span class="n">projection_dim</span>
        <span class="p">)</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">patch_embeddings</span><span class="p">,</span> <span class="n">class_token</span><span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">patch_embeddings</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1"># Add class token to patch embeddings</span>
        <span class="n">cls_tokens</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">class_token</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span>
        <span class="p">)</span>
        <span class="n">embeddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">cls_tokens</span><span class="p">,</span> <span class="n">patch_embeddings</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="c1"># Add positional embeddings</span>
        <span class="n">positions</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="n">embeddings</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">delta</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">position_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">position_embedding</span><span class="p">(</span><span class="n">positions</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">embeddings</span> <span class="o">+</span> <span class="n">position_embeddings</span>

<span class="k">class</span><span class="w"> </span><span class="nc">MultiHeadSelfAttention</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Multi-head self-attention mechanism</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">projection_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MultiHeadSelfAttention</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span> <span class="o">=</span> <span class="n">num_heads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">projection_dim</span> <span class="o">=</span> <span class="n">projection_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span> <span class="o">=</span> <span class="n">projection_dim</span> <span class="o">//</span> <span class="n">num_heads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span> <span class="o">**</span> <span class="o">-</span><span class="mf">0.5</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">query</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">projection_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">key</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">projection_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">projection_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">combine_heads</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">projection_dim</span><span class="p">)</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">split_heads</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">head_dim</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">inputs</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        
        <span class="c1"># Linear projections</span>
        <span class="n">query</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">key</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">value</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        
        <span class="c1"># Split heads</span>
        <span class="n">query</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_heads</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="n">key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_heads</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_heads</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
        
        <span class="c1"># Scaled dot-product attention</span>
        <span class="n">attention_scores</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">transpose_b</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span>
        <span class="n">attention_weights</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">attention_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="c1"># Apply attention to values</span>
        <span class="n">context</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">attention_weights</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
        <span class="n">context</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
        <span class="n">context</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">projection_dim</span><span class="p">])</span>
        
        <span class="c1"># Combine heads</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">combine_heads</span><span class="p">(</span><span class="n">context</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>

<span class="k">class</span><span class="w"> </span><span class="nc">TransformerBlock</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Transformer block with self-attention and MLP</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">projection_dim</span><span class="p">,</span> <span class="n">mlp_dim</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TransformerBlock</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">MultiHeadSelfAttention</span><span class="p">(</span><span class="n">num_heads</span><span class="p">,</span> <span class="n">projection_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">mlp_dim</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">gelu</span><span class="p">),</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">),</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">projection_dim</span><span class="p">),</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm1</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">LayerNormalization</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm2</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">LayerNormalization</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">training</span><span class="p">):</span>
        <span class="c1"># Normalize and apply attention</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm1</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">attention_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">attention_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span><span class="p">(</span><span class="n">attention_output</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
        <span class="n">out1</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">add</span><span class="p">([</span><span class="n">inputs</span><span class="p">,</span> <span class="n">attention_output</span><span class="p">])</span>
        
        <span class="c1"># Normalize and apply MLP</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm2</span><span class="p">(</span><span class="n">out1</span><span class="p">)</span>
        <span class="n">mlp_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">mlp_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span><span class="p">(</span><span class="n">mlp_output</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">layers</span><span class="o">.</span><span class="n">add</span><span class="p">([</span><span class="n">out1</span><span class="p">,</span> <span class="n">mlp_output</span><span class="p">])</span>

<span class="k">class</span><span class="w"> </span><span class="nc">VisionTransformer</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Vision Transformer (ViT) model for image classification</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">image_size</span><span class="o">=</span><span class="mi">224</span><span class="p">,</span>
        <span class="n">patch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
        <span class="n">num_layers</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
        <span class="n">num_heads</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
        <span class="n">projection_dim</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span>
        <span class="n">mlp_dim</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span>
        <span class="n">num_classes</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
        <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">VisionTransformer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        
        <span class="c1"># Calculate number of patches</span>
        <span class="n">num_patches</span> <span class="o">=</span> <span class="p">(</span><span class="n">image_size</span> <span class="o">//</span> <span class="n">patch_size</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">patch_size</span> <span class="o">=</span> <span class="n">patch_size</span>
        
        <span class="c1"># Patch extraction and projection</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">patch_extractor</span> <span class="o">=</span> <span class="n">PatchExtractor</span><span class="p">(</span><span class="n">patch_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">projection</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">projection_dim</span><span class="p">)</span>
        
        <span class="c1"># Class token</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">class_token</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span>
            <span class="n">initial_value</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="n">projection_dim</span><span class="p">]),</span>
            <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;class_token&quot;</span>
        <span class="p">)</span>
        
        <span class="c1"># Positional embedding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">position_embedding</span> <span class="o">=</span> <span class="n">PositionalEmbedding</span><span class="p">(</span>
            <span class="n">num_patches</span><span class="p">,</span> <span class="n">projection_dim</span>
        <span class="p">)</span>
        
        <span class="c1"># Transformer blocks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transformer_blocks</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">TransformerBlock</span><span class="p">(</span><span class="n">num_heads</span><span class="p">,</span> <span class="n">projection_dim</span><span class="p">,</span> <span class="n">mlp_dim</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">)</span>
        <span class="p">]</span>
        
        <span class="c1"># Layer normalization and classifier</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">LayerNormalization</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">num_classes</span><span class="p">)</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="c1"># Extract patches from images</span>
        <span class="n">patches</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">patch_extractor</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        
        <span class="c1"># Project patches to embedding dimension</span>
        <span class="n">patch_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">projection</span><span class="p">(</span><span class="n">patches</span><span class="p">)</span>
        
        <span class="c1"># Add positional embeddings</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">position_embedding</span><span class="p">(</span><span class="n">patch_embeddings</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">class_token</span><span class="p">)</span>
        
        <span class="c1"># Apply transformer blocks</span>
        <span class="k">for</span> <span class="n">transformer_block</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer_blocks</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">transformer_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
        
        <span class="c1"># Layer normalization</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="c1"># Get class token output</span>
        <span class="n">class_token_output</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
        
        <span class="c1"># Classification</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">class_token_output</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">build_vit_model</span><span class="p">(</span>
    <span class="n">image_size</span><span class="o">=</span><span class="mi">224</span><span class="p">,</span>
    <span class="n">patch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">num_layers</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
    <span class="n">num_heads</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
    <span class="n">projection_dim</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span>
    <span class="n">mlp_dim</span><span class="o">=</span><span class="mi">3072</span><span class="p">,</span>
    <span class="n">num_classes</span><span class="o">=</span><span class="mi">1000</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Build a Vision Transformer model</span>
<span class="sd">    </span>
<span class="sd">    Parameters:</span>
<span class="sd">    -----------</span>
<span class="sd">    image_size : int</span>
<span class="sd">        Size of input images (assuming square images)</span>
<span class="sd">    patch_size : int</span>
<span class="sd">        Size of image patches</span>
<span class="sd">    num_layers : int</span>
<span class="sd">        Number of transformer blocks</span>
<span class="sd">    num_heads : int</span>
<span class="sd">        Number of attention heads</span>
<span class="sd">    projection_dim : int</span>
<span class="sd">        Dimension of patch embeddings</span>
<span class="sd">    mlp_dim : int</span>
<span class="sd">        Hidden dimension in the MLP</span>
<span class="sd">    num_classes : int</span>
<span class="sd">        Number of output classes</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">    --------</span>
<span class="sd">    model : tf.keras.Model</span>
<span class="sd">        Vision Transformer model</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">image_size</span><span class="p">,</span> <span class="n">image_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
    
    <span class="n">vit</span> <span class="o">=</span> <span class="n">VisionTransformer</span><span class="p">(</span>
        <span class="n">image_size</span><span class="o">=</span><span class="n">image_size</span><span class="p">,</span>
        <span class="n">patch_size</span><span class="o">=</span><span class="n">patch_size</span><span class="p">,</span>
        <span class="n">num_layers</span><span class="o">=</span><span class="n">num_layers</span><span class="p">,</span>
        <span class="n">num_heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span>
        <span class="n">projection_dim</span><span class="o">=</span><span class="n">projection_dim</span><span class="p">,</span>
        <span class="n">mlp_dim</span><span class="o">=</span><span class="n">mlp_dim</span><span class="p">,</span>
        <span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span>
    <span class="p">)</span>
    
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">vit</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id6">
<h3>20.4.3 Results and Evaluation<a class="headerlink" href="#id6" title="Link to this heading">#</a></h3>
<p>Vision Transformers have demonstrated impressive performance on computer vision tasks:</p>
<ol class="arabic simple">
<li><p><strong>Competitive accuracy</strong>: When trained on sufficient data, ViT outperformed CNNs on image classification benchmarks like ImageNet.</p></li>
<li><p><strong>Data efficiency</strong>: With pre-training on large datasets, ViTs showed better transfer learning efficiency than CNNs.</p></li>
<li><p><strong>Interpretability</strong>: The attention maps provide visual explanations of which image regions contribute to decisions.</p></li>
</ol>
</section>
<section id="id7">
<h3>20.4.4 Neuroscience Connection<a class="headerlink" href="#id7" title="Link to this heading">#</a></h3>
<p>The ViT architecture connects to visual neuroscience in several ways:</p>
<ul class="simple">
<li><p><strong>Parallel processing</strong>: Like the visual system, ViT processes multiple parts of the visual field in parallel.</p></li>
<li><p><strong>Hierarchical integration</strong>: The transformer layers build increasingly abstract representations similar to the visual cortex.</p></li>
<li><p><strong>Attention allocation</strong>: The self-attention mechanism parallels how humans selectively attend to parts of a scene.</p></li>
<li><p><strong>Context integration</strong>: ViT’s ability to relate distant parts of an image mirrors how the visual system integrates across the visual field.</p></li>
</ul>
</section>
<section id="id8">
<h3>20.4.5 Limitations and Future Directions<a class="headerlink" href="#id8" title="Link to this heading">#</a></h3>
<p>Key challenges and future directions include:</p>
<ol class="arabic simple">
<li><p><strong>Computational efficiency</strong>: ViTs typically require more computation than CNNs for similar performance at small scales.</p></li>
<li><p><strong>Data requirements</strong>: ViTs need more data to achieve good results without pre-training.</p></li>
<li><p><strong>Future work</strong>: Ongoing research is exploring hybrid architectures combining CNNs and transformers, and biologically-inspired attention constraints.</p></li>
</ol>
</section>
</section>
<section id="case-study-neural-data-analysis-with-latent-variable-models">
<h2>20.5 Case Study: Neural Data Analysis with Latent Variable Models<a class="headerlink" href="#case-study-neural-data-analysis-with-latent-variable-models" title="Link to this heading">#</a></h2>
<section id="id9">
<h3>20.5.1 Background and Motivation<a class="headerlink" href="#id9" title="Link to this heading">#</a></h3>
<p>Analyzing high-dimensional neural data requires methods that can identify underlying patterns and structures. This case study examines how latent variable models influenced by neuroscience principles have been used to extract meaningful representations from neural recordings.</p>
</section>
<section id="implementation-latent-factor-analysis-via-dynamical-systems-lfads">
<h3>20.5.2 Implementation: Latent Factor Analysis via Dynamical Systems (LFADS)<a class="headerlink" href="#implementation-latent-factor-analysis-via-dynamical-systems-lfads" title="Link to this heading">#</a></h3>
<p>LFADS, developed by researchers at Stanford and Google, uses recurrent neural networks to model neural population dynamics:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">tensorflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tf</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras</span><span class="w"> </span><span class="kn">import</span> <span class="n">layers</span><span class="p">,</span> <span class="n">Model</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="k">class</span><span class="w"> </span><span class="nc">Encoder</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Bidirectional RNN encoder for LFADS</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Encoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        
        <span class="c1"># Forward and backward RNNs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">forward_rnn</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span>
            <span class="n">hidden_size</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_state</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;encoder_forward_rnn&quot;</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">backward_rnn</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span>
            <span class="n">hidden_size</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_state</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">go_backwards</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;encoder_backward_rnn&quot;</span>
        <span class="p">)</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="c1"># Forward pass</span>
        <span class="n">forward_outputs</span><span class="p">,</span> <span class="n">forward_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward_rnn</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        
        <span class="c1"># Backward pass</span>
        <span class="n">backward_outputs</span><span class="p">,</span> <span class="n">backward_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">backward_rnn</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">backward_outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reverse</span><span class="p">(</span><span class="n">backward_outputs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        
        <span class="c1"># Combine states</span>
        <span class="n">encoder_state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">forward_state</span><span class="p">,</span> <span class="n">backward_state</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">encoder_state</span>

<span class="k">class</span><span class="w"> </span><span class="nc">LatentDistribution</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Variational distribution for latent variables</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">latent_dim</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LatentDistribution</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">latent_dim</span> <span class="o">=</span> <span class="n">latent_dim</span>
        
        <span class="c1"># Dense layers for mean and logvar</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;mean_layer&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logvar_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;logvar_layer&quot;</span><span class="p">)</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="c1"># Compute mean and logvar</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_layer</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">logvar</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">logvar_layer</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        
        <span class="c1"># If training, sample from the distribution</span>
        <span class="k">if</span> <span class="n">training</span><span class="p">:</span>
            <span class="n">epsilon</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">mean</span><span class="p">))</span>
            <span class="n">sample</span> <span class="o">=</span> <span class="n">mean</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">logvar</span><span class="p">)</span> <span class="o">*</span> <span class="n">epsilon</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">sample</span> <span class="o">=</span> <span class="n">mean</span>
        
        <span class="k">return</span> <span class="n">sample</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">logvar</span>

<span class="k">class</span><span class="w"> </span><span class="nc">Controller</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Controller RNN for generating inputs to the generator</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Controller</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        
        <span class="c1"># Controller RNN</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span>
            <span class="n">hidden_size</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_state</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;controller_rnn&quot;</span>
        <span class="p">)</span>
        
        <span class="c1"># Dense layer for controller outputs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dense</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;controller_output&quot;</span><span class="p">)</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">initial_state</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">):</span>
        <span class="c1"># Create dummy input tensor</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">initial_state</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">dummy_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
        
        <span class="c1"># Initialize RNN state</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">initial_state</span>
        
        <span class="c1"># Run RNN and get outputs</span>
        <span class="n">outputs</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">dummy_input</span><span class="p">,</span> <span class="n">initial_state</span><span class="o">=</span><span class="n">state</span><span class="p">)</span>
        
        <span class="c1"># Apply dense layer to outputs</span>
        <span class="n">controller_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">controller_outputs</span>

<span class="k">class</span><span class="w"> </span><span class="nc">Generator</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generator RNN for modeling neural dynamics</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">factors_dim</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">output_dim</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Generator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">factors_dim</span> <span class="o">=</span> <span class="n">factors_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_dim</span> <span class="o">=</span> <span class="n">output_dim</span>
        
        <span class="c1"># Generator RNN</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span>
            <span class="n">hidden_size</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_state</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;generator_rnn&quot;</span>
        <span class="p">)</span>
        
        <span class="c1"># Dense layers for outputs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">factors_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">factors_dim</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;factors_layer&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rates_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">output_dim</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softplus</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;rates_layer&quot;</span><span class="p">)</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">initial_state</span><span class="p">,</span> <span class="n">controller_outputs</span><span class="p">):</span>
        <span class="c1"># Run RNN with controller outputs as inputs</span>
        <span class="n">outputs</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">controller_outputs</span><span class="p">,</span> <span class="n">initial_state</span><span class="o">=</span><span class="n">initial_state</span><span class="p">)</span>
        
        <span class="c1"># Generate factors (latent neural dynamics)</span>
        <span class="n">factors</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">factors_layer</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
        
        <span class="c1"># Generate rates (expected neural firing rates)</span>
        <span class="n">rates</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rates_layer</span><span class="p">(</span><span class="n">factors</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">rates</span><span class="p">,</span> <span class="n">factors</span>

<span class="k">class</span><span class="w"> </span><span class="nc">LFADS</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Latent Factor Analysis via Dynamical Systems (LFADS) model</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">encoder_dim</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">latent_dim</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
        <span class="n">controller_dim</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">generator_dim</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">factors_dim</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LFADS</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        
        <span class="c1"># Model components</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span><span class="n">hidden_size</span><span class="o">=</span><span class="n">encoder_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">latent_distribution</span> <span class="o">=</span> <span class="n">LatentDistribution</span><span class="p">(</span><span class="n">latent_dim</span><span class="o">=</span><span class="n">latent_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">controller</span> <span class="o">=</span> <span class="n">Controller</span><span class="p">(</span><span class="n">hidden_size</span><span class="o">=</span><span class="n">controller_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generator_initial_dense</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">generator_dim</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;tanh&quot;</span><span class="p">)</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        <span class="c1"># Build the generator once we know the output dimension</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span> <span class="o">=</span> <span class="n">Generator</span><span class="p">(</span>
            <span class="n">hidden_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">generator_initial_dense</span><span class="o">.</span><span class="n">units</span><span class="p">,</span>
            <span class="n">factors_dim</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
            <span class="n">output_dim</span><span class="o">=</span><span class="n">input_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="p">)</span>
        
        <span class="nb">super</span><span class="p">(</span><span class="n">LFADS</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="c1"># Get sequence length</span>
        <span class="n">sequence_length</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">inputs</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="c1"># Encode input</span>
        <span class="n">encoder_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        
        <span class="c1"># Sample from latent distribution</span>
        <span class="n">latent_sample</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">logvar</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">latent_distribution</span><span class="p">(</span><span class="n">encoder_state</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
        
        <span class="c1"># Generate controller outputs</span>
        <span class="n">controller_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">controller</span><span class="p">(</span><span class="n">latent_sample</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">)</span>
        
        <span class="c1"># Generate initial state for generator</span>
        <span class="n">generator_initial_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generator_initial_dense</span><span class="p">(</span><span class="n">latent_sample</span><span class="p">)</span>
        
        <span class="c1"># Generate neural rates and factors</span>
        <span class="n">rates</span><span class="p">,</span> <span class="n">factors</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="p">(</span><span class="n">generator_initial_state</span><span class="p">,</span> <span class="n">controller_outputs</span><span class="p">)</span>
        
        <span class="c1"># Create model outputs dictionary</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;rates&quot;</span><span class="p">:</span> <span class="n">rates</span><span class="p">,</span>
            <span class="s2">&quot;factors&quot;</span><span class="p">:</span> <span class="n">factors</span><span class="p">,</span>
            <span class="s2">&quot;latent_mean&quot;</span><span class="p">:</span> <span class="n">mean</span><span class="p">,</span>
            <span class="s2">&quot;latent_logvar&quot;</span><span class="p">:</span> <span class="n">logvar</span>
        <span class="p">}</span>
        
        <span class="k">return</span> <span class="n">outputs</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">compute_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute LFADS loss function</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        x : tf.Tensor</span>
<span class="sd">            Input spike data</span>
<span class="sd">        training : bool</span>
<span class="sd">            Whether model is in training mode</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">        --------</span>
<span class="sd">        total_loss : tf.Tensor</span>
<span class="sd">            Combined loss</span>
<span class="sd">        reconstruction_loss : tf.Tensor</span>
<span class="sd">            Poisson reconstruction loss</span>
<span class="sd">        kl_loss : tf.Tensor</span>
<span class="sd">            KL divergence loss</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Get model outputs</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
        <span class="n">rates</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="s2">&quot;rates&quot;</span><span class="p">]</span>
        <span class="n">latent_mean</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="s2">&quot;latent_mean&quot;</span><span class="p">]</span>
        <span class="n">latent_logvar</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="s2">&quot;latent_logvar&quot;</span><span class="p">]</span>
        
        <span class="c1"># Compute Poisson reconstruction loss</span>
        <span class="c1"># log p(x|z) = sum_t sum_i (x_i,t * log(r_i,t) - r_i,t - log(x_i,t!))</span>
        <span class="c1"># We drop the factorial term as it&#39;s constant with respect to the parameters</span>
        <span class="n">reconstruction_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span>
            <span class="n">rates</span> <span class="o">-</span> <span class="n">x</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">rates</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">),</span>
            <span class="n">axis</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="n">reconstruction_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">reconstruction_loss</span><span class="p">)</span>
        
        <span class="c1"># Compute KL divergence loss</span>
        <span class="c1"># KL(q(z|x) || p(z)) = 0.5 * sum_j (1 + log(sigma_j^2) - mu_j^2 - sigma_j^2)</span>
        <span class="n">kl_loss</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span>
            <span class="mi">1</span> <span class="o">+</span> <span class="n">latent_logvar</span> <span class="o">-</span> <span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">latent_mean</span><span class="p">)</span> <span class="o">-</span> <span class="n">tf</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">latent_logvar</span><span class="p">),</span>
            <span class="n">axis</span><span class="o">=</span><span class="mi">1</span>
        <span class="p">)</span>
        <span class="n">kl_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">kl_loss</span><span class="p">)</span>
        
        <span class="c1"># Combine losses</span>
        <span class="c1"># Optionally add weight for KL term (beta-VAE style)</span>
        <span class="n">kl_weight</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="n">total_loss</span> <span class="o">=</span> <span class="n">reconstruction_loss</span> <span class="o">+</span> <span class="n">kl_weight</span> <span class="o">*</span> <span class="n">kl_loss</span>
        
        <span class="k">return</span> <span class="n">total_loss</span><span class="p">,</span> <span class="n">reconstruction_loss</span><span class="p">,</span> <span class="n">kl_loss</span>

<span class="k">def</span><span class="w"> </span><span class="nf">build_lfads_model</span><span class="p">(</span>
    <span class="n">input_shape</span><span class="p">,</span>
    <span class="n">encoder_dim</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">latent_dim</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">controller_dim</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">generator_dim</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">factors_dim</span><span class="o">=</span><span class="mi">50</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Build an LFADS model</span>
<span class="sd">    </span>
<span class="sd">    Parameters:</span>
<span class="sd">    -----------</span>
<span class="sd">    input_shape : tuple</span>
<span class="sd">        Shape of input data (sequence_length, num_neurons)</span>
<span class="sd">    encoder_dim : int</span>
<span class="sd">        Hidden dimension of encoder RNN</span>
<span class="sd">    latent_dim : int</span>
<span class="sd">        Dimension of latent variables</span>
<span class="sd">    controller_dim : int</span>
<span class="sd">        Hidden dimension of controller RNN</span>
<span class="sd">    generator_dim : int</span>
<span class="sd">        Hidden dimension of generator RNN</span>
<span class="sd">    factors_dim : int</span>
<span class="sd">        Dimension of latent factors</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">    --------</span>
<span class="sd">    model : LFADS</span>
<span class="sd">        LFADS model</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Create LFADS model</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">LFADS</span><span class="p">(</span>
        <span class="n">encoder_dim</span><span class="o">=</span><span class="n">encoder_dim</span><span class="p">,</span>
        <span class="n">latent_dim</span><span class="o">=</span><span class="n">latent_dim</span><span class="p">,</span>
        <span class="n">controller_dim</span><span class="o">=</span><span class="n">controller_dim</span><span class="p">,</span>
        <span class="n">generator_dim</span><span class="o">=</span><span class="n">generator_dim</span><span class="p">,</span>
        <span class="n">factors_dim</span><span class="o">=</span><span class="n">factors_dim</span>
    <span class="p">)</span>
    
    <span class="c1"># Build the model with sample input</span>
    <span class="n">sample_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,)</span> <span class="o">+</span> <span class="n">input_shape</span><span class="p">)</span>
    <span class="n">model</span><span class="p">(</span><span class="n">sample_input</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
</section>
<section id="id10">
<h3>20.5.3 Results and Evaluation<a class="headerlink" href="#id10" title="Link to this heading">#</a></h3>
<p>LFADS has demonstrated several benefits in analyzing neural data:</p>
<ol class="arabic simple">
<li><p><strong>Improved decoding</strong>: Using LFADS-inferred latent factors improved neural decoding accuracy by 40% compared to raw neural data.</p></li>
<li><p><strong>Single-trial analysis</strong>: By inferring the underlying dynamics from noisy spike trains, LFADS enables meaningful analysis of individual trials rather than requiring trial averaging.</p></li>
<li><p><strong>Identification of dynamics</strong>: LFADS successfully recovered the underlying dynamical structure in both simulated and real neural populations.</p></li>
</ol>
</section>
<section id="id11">
<h3>20.5.4 Neuroscience Connection<a class="headerlink" href="#id11" title="Link to this heading">#</a></h3>
<p>The LFADS model connects to neuroscience theories in several ways:</p>
<ul class="simple">
<li><p><strong>Low-dimensional dynamics</strong>: LFADS is built on the neuroscience insight that high-dimensional neural activity often reflects low-dimensional latent dynamics.</p></li>
<li><p><strong>Temporal constraints</strong>: The recurrent generator mirrors the continuous-time dynamics of neural circuits.</p></li>
<li><p><strong>Initial condition encoding</strong>: The model’s focus on initial state mirrors theories about how neural trajectories are initialized based on sensory inputs.</p></li>
</ul>
</section>
<section id="id12">
<h3>20.5.5 Limitations and Future Directions<a class="headerlink" href="#id12" title="Link to this heading">#</a></h3>
<p>Key challenges and future directions include:</p>
<ol class="arabic simple">
<li><p><strong>Model complexity</strong>: The full LFADS model is computationally intensive to train.</p></li>
<li><p><strong>Interpretability</strong>: The biological meaning of extracted latent factors requires careful interpretation.</p></li>
<li><p><strong>Future work</strong>: Ongoing research is exploring extensions to multi-area recordings and incorporating more detailed biophysical constraints.</p></li>
</ol>
</section>
</section>
<section id="lessons-from-successful-neuroai-integration">
<h2>20.6 Lessons from Successful NeuroAI Integration<a class="headerlink" href="#lessons-from-successful-neuroai-integration" title="Link to this heading">#</a></h2>
<p>Across these case studies, several patterns emerge that highlight successful strategies for integrating neuroscience and AI:</p>
<section id="common-patterns-of-success">
<h3>20.6.1 Common Patterns of Success<a class="headerlink" href="#common-patterns-of-success" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p><strong>Focus on computational principles</strong>: Successful NeuroAI implementations focus on computational principles rather than precise biological details.</p></li>
<li><p><strong>Iterative refinement</strong>: The most successful projects involved multiple iterations between neuroscience insights and AI implementations.</p></li>
<li><p><strong>Cross-disciplinary teams</strong>: Projects typically involved researchers with expertise in both neuroscience and AI working closely together.</p></li>
<li><p><strong>Translation flexibility</strong>: Successful implementations allowed for flexible translation of neuroscience principles to match the constraints of deep learning architectures.</p></li>
</ol>
</section>
<section id="practical-implementation-strategies">
<h3>20.6.2 Practical Implementation Strategies<a class="headerlink" href="#practical-implementation-strategies" title="Link to this heading">#</a></h3>
<p>Based on these case studies, several practical strategies emerge:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">neuroai_implementation_framework</span><span class="p">(</span><span class="n">neuroscience_principle</span><span class="p">,</span> <span class="n">existing_ai_system</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A framework for implementing neuroscience principles in AI systems</span>
<span class="sd">    </span>
<span class="sd">    Parameters:</span>
<span class="sd">    -----------</span>
<span class="sd">    neuroscience_principle : dict</span>
<span class="sd">        Description of the neuroscience principle to implement</span>
<span class="sd">    existing_ai_system : object</span>
<span class="sd">        The AI system to enhance</span>
<span class="sd">        </span>
<span class="sd">    Returns:</span>
<span class="sd">    --------</span>
<span class="sd">    enhanced_system : object</span>
<span class="sd">        The enhanced AI system</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Step 1: Extract the computational essence of the neuroscience principle</span>
    <span class="n">computational_essence</span> <span class="o">=</span> <span class="n">extract_computational_essence</span><span class="p">(</span><span class="n">neuroscience_principle</span><span class="p">)</span>
    
    <span class="c1"># Step 2: Analyze compatibility with existing AI system</span>
    <span class="n">compatibility_analysis</span> <span class="o">=</span> <span class="n">analyze_compatibility</span><span class="p">(</span><span class="n">computational_essence</span><span class="p">,</span> <span class="n">existing_ai_system</span><span class="p">)</span>
    
    <span class="c1"># Step 3: Implement a minimal version to test the principle</span>
    <span class="n">prototype</span> <span class="o">=</span> <span class="n">implement_minimal_version</span><span class="p">(</span><span class="n">computational_essence</span><span class="p">,</span> <span class="n">existing_ai_system</span><span class="p">)</span>
    
    <span class="c1"># Step 4: Evaluate and iterate</span>
    <span class="n">evaluation_results</span> <span class="o">=</span> <span class="n">evaluate_prototype</span><span class="p">(</span><span class="n">prototype</span><span class="p">)</span>
    <span class="n">enhanced_system</span> <span class="o">=</span> <span class="n">iterative_refinement</span><span class="p">(</span><span class="n">prototype</span><span class="p">,</span> <span class="n">evaluation_results</span><span class="p">)</span>
    
    <span class="c1"># Step 5: Scale up implementation</span>
    <span class="n">enhanced_system</span> <span class="o">=</span> <span class="n">scale_implementation</span><span class="p">(</span><span class="n">enhanced_system</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">enhanced_system</span>

<span class="k">def</span><span class="w"> </span><span class="nf">extract_computational_essence</span><span class="p">(</span><span class="n">neuroscience_principle</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Extract the core computational principle from neuroscience findings</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Focus on functional aspects, not biological implementation</span>
    <span class="c1"># Identify the information processing role</span>
    <span class="c1"># Abstract away biological details</span>
    <span class="c1"># Identify the computational advantage</span>
    <span class="k">pass</span>

<span class="k">def</span><span class="w"> </span><span class="nf">analyze_compatibility</span><span class="p">(</span><span class="n">computational_essence</span><span class="p">,</span> <span class="n">existing_ai_system</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Analyze how compatible the principle is with existing AI</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Identify integration points</span>
    <span class="c1"># Assess computational overhead</span>
    <span class="c1"># Determine architectural modifications needed</span>
    <span class="c1"># Evaluate training implications</span>
    <span class="k">pass</span>

<span class="k">def</span><span class="w"> </span><span class="nf">implement_minimal_version</span><span class="p">(</span><span class="n">computational_essence</span><span class="p">,</span> <span class="n">existing_ai_system</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Implement a minimal version to test the principle</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Focus on core functionality</span>
    <span class="c1"># Implement the simplest version that could work</span>
    <span class="c1"># Ensure measurable outcomes</span>
    <span class="c1"># Document assumptions and simplifications</span>
    <span class="k">pass</span>

<span class="k">def</span><span class="w"> </span><span class="nf">evaluate_prototype</span><span class="p">(</span><span class="n">prototype</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Evaluate the prototype against baselines</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Compare to baseline</span>
    <span class="c1"># Test on simplified tasks</span>
    <span class="c1"># Analyze failure modes</span>
    <span class="c1"># Identity promising directions</span>
    <span class="k">pass</span>

<span class="k">def</span><span class="w"> </span><span class="nf">iterative_refinement</span><span class="p">(</span><span class="n">prototype</span><span class="p">,</span> <span class="n">evaluation_results</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Refine implementation based on evaluation</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Address failure modes</span>
    <span class="c1"># Optimize computational efficiency</span>
    <span class="c1"># Reduce complexity where possible</span>
    <span class="c1"># Enhance successful components</span>
    <span class="k">pass</span>

<span class="k">def</span><span class="w"> </span><span class="nf">scale_implementation</span><span class="p">(</span><span class="n">enhanced_system</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Scale up implementation for real-world use</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Optimize for computational efficiency</span>
    <span class="c1"># Address edge cases</span>
    <span class="c1"># Add necessary complexity for general use</span>
    <span class="c1"># Document implementation details</span>
    <span class="k">pass</span>
</pre></div>
</div>
</section>
<section id="interdisciplinary-collaboration-best-practices">
<h3>20.6.3 Interdisciplinary Collaboration Best Practices<a class="headerlink" href="#interdisciplinary-collaboration-best-practices" title="Link to this heading">#</a></h3>
<p>The case studies highlight the importance of effective collaboration between neuroscientists and AI researchers:</p>
<ol class="arabic simple">
<li><p><strong>Establish shared vocabulary</strong>: Develop a common language that bridges neuroscience and AI concepts.</p></li>
<li><p><strong>Focus on translatable insights</strong>: Prioritize neuroscience findings with clear computational implications.</p></li>
<li><p><strong>Prototype and iterate</strong>: Build small-scale prototypes to test neuroscience concepts before large-scale implementation.</p></li>
<li><p><strong>Mutual education</strong>: Invest time in cross-disciplinary education to ensure deep understanding of both fields.</p></li>
</ol>
</section>
</section>
<section id="practical-exercise-implementing-a-neuroscience-inspired-ai-component">
<h2>20.7 Practical Exercise: Implementing a Neuroscience-Inspired AI Component<a class="headerlink" href="#practical-exercise-implementing-a-neuroscience-inspired-ai-component" title="Link to this heading">#</a></h2>
<p>This exercise guides you through implementing a simplified hippocampal-inspired memory system for reinforcement learning:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">deque</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">random</span>

<span class="k">class</span><span class="w"> </span><span class="nc">EpisodicMemoryBuffer</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A simple episodic memory buffer inspired by hippocampal function</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">capacity</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">similarity_threshold</span><span class="o">=</span><span class="mf">0.8</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the episodic memory buffer</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        capacity : int</span>
<span class="sd">            Maximum number of episodes to store</span>
<span class="sd">        similarity_threshold : float</span>
<span class="sd">            Threshold for determining similar experiences</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">buffer</span> <span class="o">=</span> <span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="n">capacity</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">similarity_threshold</span> <span class="o">=</span> <span class="n">similarity_threshold</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">add_experience</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">done</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add an experience to the buffer</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        state : np.ndarray</span>
<span class="sd">            Current state</span>
<span class="sd">        action : int</span>
<span class="sd">            Action taken</span>
<span class="sd">        reward : float</span>
<span class="sd">            Reward received</span>
<span class="sd">        next_state : np.ndarray</span>
<span class="sd">            Next state</span>
<span class="sd">        done : bool</span>
<span class="sd">            Whether the episode is done</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">experience</span> <span class="o">=</span> <span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">done</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">buffer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">experience</span><span class="p">)</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">find_similar_experiences</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query_state</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Find experiences with similar states</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        query_state : np.ndarray</span>
<span class="sd">            State to compare against</span>
<span class="sd">        k : int</span>
<span class="sd">            Number of similar experiences to retrieve</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">        --------</span>
<span class="sd">        similar_experiences : list</span>
<span class="sd">            List of similar experiences</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">similarities</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="k">for</span> <span class="n">experience</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">buffer</span><span class="p">:</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">experience</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="c1"># Compute cosine similarity</span>
            <span class="n">similarity</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">query_state</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">query_state</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">state</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span>
            <span class="n">similarities</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">similarity</span><span class="p">,</span> <span class="n">experience</span><span class="p">))</span>
        
        <span class="c1"># Sort by similarity</span>
        <span class="n">similarities</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        
        <span class="c1"># Filter by threshold and get top k</span>
        <span class="n">similar_experiences</span> <span class="o">=</span> <span class="p">[</span><span class="n">exp</span> <span class="k">for</span> <span class="n">sim</span><span class="p">,</span> <span class="n">exp</span> <span class="ow">in</span> <span class="n">similarities</span> <span class="k">if</span> <span class="n">sim</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">similarity_threshold</span><span class="p">][:</span><span class="n">k</span><span class="p">]</span>
        
        <span class="k">return</span> <span class="n">similar_experiences</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">sample_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">include_similar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">query_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sample a batch of experiences</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        batch_size : int</span>
<span class="sd">            Size of the batch to sample</span>
<span class="sd">        include_similar : bool</span>
<span class="sd">            Whether to include similar experiences</span>
<span class="sd">        query_state : np.ndarray or None</span>
<span class="sd">            State to find similar experiences for</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">        --------</span>
<span class="sd">        batch : list</span>
<span class="sd">            Sampled batch of experiences</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Regular random sampling</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">buffer</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">batch_size</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">buffer</span><span class="p">)</span>
        
        <span class="c1"># Regular random batch</span>
        <span class="n">random_batch</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">buffer</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">-</span> <span class="mi">5</span> <span class="k">if</span> <span class="n">include_similar</span> <span class="k">else</span> <span class="n">batch_size</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">include_similar</span> <span class="ow">and</span> <span class="n">query_state</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Find similar experiences</span>
            <span class="n">similar_experiences</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">find_similar_experiences</span><span class="p">(</span><span class="n">query_state</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
            
            <span class="c1"># Combine random and similar experiences</span>
            <span class="n">combined_batch</span> <span class="o">=</span> <span class="n">random_batch</span> <span class="o">+</span> <span class="n">similar_experiences</span>
            
            <span class="k">return</span> <span class="n">combined_batch</span>
        
        <span class="k">return</span> <span class="n">random_batch</span>

<span class="k">class</span><span class="w"> </span><span class="nc">EpisodicReinforcementLearningAgent</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A reinforcement learning agent with episodic memory</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dim</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.99</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the agent</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        state_dim : int</span>
<span class="sd">            Dimension of the state space</span>
<span class="sd">        action_dim : int</span>
<span class="sd">            Dimension of the action space</span>
<span class="sd">        learning_rate : float</span>
<span class="sd">            Learning rate for the model</span>
<span class="sd">        gamma : float</span>
<span class="sd">            Discount factor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state_dim</span> <span class="o">=</span> <span class="n">state_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_dim</span> <span class="o">=</span> <span class="n">action_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span>
        
        <span class="c1"># Create episodic memory</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">episodic_memory</span> <span class="o">=</span> <span class="n">EpisodicMemoryBuffer</span><span class="p">()</span>
        
        <span class="c1"># Simple Q-table for this example</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q_table</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">state_dim</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">))</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">select_action</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Select an action using epsilon-greedy policy with episodic memory</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        -----------</span>
<span class="sd">        state : np.ndarray</span>
<span class="sd">            Current state</span>
<span class="sd">        epsilon : float</span>
<span class="sd">            Exploration rate</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">        --------</span>
<span class="sd">        action : int</span>
<span class="sd">            Selected action</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">epsilon</span><span class="p">:</span>
            <span class="c1"># Random exploration</span>
            <span class="k">return</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Check episodic memory for similar states</span>
            <span class="n">similar_experiences</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">episodic_memory</span><span class="o">.</span><span class="n">find_similar_experiences</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
            
            <span class="k">if</span> <span class="n">similar_experiences</span> <span class="ow">and</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.3</span><span class="p">:</span>  <span class="c1"># 30% chance to use episodic memory</span>
                <span class="c1"># Use action from a similar experience with high reward</span>
                <span class="n">similar_experiences</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># Sort by reward</span>
                <span class="k">return</span> <span class="n">similar_experiences</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># Return action from highest-reward experience</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Use Q-table</span>
                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_table</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">discretize_state</span><span class="p">(</span><span class="n">state</span><span class="p">)])</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">discretize_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Discretize continuous state (simplification for this example)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># This is a placeholder; in a real implementation, </span>
        <span class="c1"># you would properly discretize the state space</span>
        <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">state</span><span class="p">)</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_dim</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">store_experience</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">done</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Store experience in episodic memory</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">episodic_memory</span><span class="o">.</span><span class="n">add_experience</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">done</span><span class="p">)</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">learn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">done</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Update Q-table based on experience</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Discretize states for Q-table</span>
        <span class="n">state_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">discretize_state</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="n">next_state_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">discretize_state</span><span class="p">(</span><span class="n">next_state</span><span class="p">)</span>
        
        <span class="c1"># Q-learning update</span>
        <span class="n">best_next_action</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_table</span><span class="p">[</span><span class="n">next_state_idx</span><span class="p">])</span>
        <span class="n">td_target</span> <span class="o">=</span> <span class="n">reward</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">done</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_table</span><span class="p">[</span><span class="n">next_state_idx</span><span class="p">,</span> <span class="n">best_next_action</span><span class="p">]</span>
        <span class="n">td_error</span> <span class="o">=</span> <span class="n">td_target</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_table</span><span class="p">[</span><span class="n">state_idx</span><span class="p">,</span> <span class="n">action</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q_table</span><span class="p">[</span><span class="n">state_idx</span><span class="p">,</span> <span class="n">action</span><span class="p">]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">td_error</span>
        
        <span class="c1"># Store experience in episodic memory</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">store_experience</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">done</span><span class="p">)</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">train_from_episodic_memory</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Train using experiences from episodic memory</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Sample batch from episodic memory</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">episodic_memory</span><span class="o">.</span><span class="n">sample_batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
        
        <span class="c1"># Learn from each experience</span>
        <span class="k">for</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">done</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">done</span><span class="p">)</span>

<span class="c1"># Example usage</span>
<span class="k">def</span><span class="w"> </span><span class="nf">run_episodic_memory_example</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Run a simple example of episodic memory in reinforcement learning</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Create environment (simplified for this example)</span>
    <span class="n">state_dim</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="n">action_dim</span> <span class="o">=</span> <span class="mi">4</span>
    
    <span class="c1"># Create agent</span>
    <span class="n">agent</span> <span class="o">=</span> <span class="n">EpisodicReinforcementLearningAgent</span><span class="p">(</span><span class="n">state_dim</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">)</span>
    
    <span class="c1"># Run episodes</span>
    <span class="n">num_episodes</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="n">max_steps</span> <span class="o">=</span> <span class="mi">200</span>
    
    <span class="k">for</span> <span class="n">episode</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_episodes</span><span class="p">):</span>
        <span class="c1"># Reset environment</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>  <span class="c1"># 10-dimensional state</span>
        <span class="n">total_reward</span> <span class="o">=</span> <span class="mi">0</span>
        
        <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_steps</span><span class="p">):</span>
            <span class="c1"># Select action</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">select_action</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
            
            <span class="c1"># Take action (simplified environment dynamics)</span>
            <span class="n">next_state</span> <span class="o">=</span> <span class="n">state</span> <span class="o">+</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
            <span class="n">next_state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">next_state</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            
            <span class="c1"># Get reward (simplified)</span>
            <span class="n">reward</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">next_state</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">state</span><span class="p">)</span> <span class="k">else</span> <span class="o">-</span><span class="mf">0.1</span>
            <span class="n">done</span> <span class="o">=</span> <span class="n">step</span> <span class="o">==</span> <span class="n">max_steps</span> <span class="o">-</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">next_state</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mf">9.0</span>
            
            <span class="c1"># Learn from experience</span>
            <span class="n">agent</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">done</span><span class="p">)</span>
            
            <span class="c1"># Update state and total reward</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">next_state</span>
            <span class="n">total_reward</span> <span class="o">+=</span> <span class="n">reward</span>
            
            <span class="k">if</span> <span class="n">done</span><span class="p">:</span>
                <span class="k">break</span>
        
        <span class="c1"># Train from episodic memory</span>
        <span class="n">agent</span><span class="o">.</span><span class="n">train_from_episodic_memory</span><span class="p">()</span>
        
        <span class="c1"># Print progress</span>
        <span class="k">if</span> <span class="n">episode</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Episode </span><span class="si">{</span><span class="n">episode</span><span class="si">}</span><span class="s2">, Total Reward: </span><span class="si">{</span><span class="n">total_reward</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">run_episodic_memory_example</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="chapter-take-aways">
<h2>20.8 Chapter Take-aways<a class="headerlink" href="#chapter-take-aways" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Successful NeuroAI implementations focus on computational principles rather than precise biological details</p></li>
<li><p>The most effective implementations involve iterative refinement between neuroscience insights and AI implementations</p></li>
<li><p>Key areas where neuroscience has informed AI include attention mechanisms, memory systems, predictive processing, and neural data analysis</p></li>
<li><p>Effective cross-disciplinary collaboration requires establishing shared vocabulary and mutual education</p></li>
<li><p>Implementing neuroscience principles in AI often requires creative adaptations to match the constraints of current deep learning frameworks</p></li>
<li><p>The most successful projects demonstrate measurable improvements in performance, generalization, or sample efficiency</p></li>
</ul>
</section>
<section id="interactive-materials-and-exercises">
<h2>20.9 Interactive Materials and Exercises<a class="headerlink" href="#interactive-materials-and-exercises" title="Link to this heading">#</a></h2>
<p>To deepen your understanding of the case studies presented in this chapter, we’ve created several interactive examples and exercises. These materials allow you to explore key concepts through hands-on experimentation.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Access the <a class="reference internal" href="ch20_interactive.html"><span class="std std-doc">interactive notebook</span></a> to experiment with:</p>
<ol class="arabic simple">
<li><p><strong>PredNet Visualization</strong>: Adjust parameters to see how predictive coding works in practice</p></li>
<li><p><strong>Prioritized Experience Replay</strong>: Compare standard and prioritized replay in reinforcement learning</p></li>
<li><p><strong>Vision Transformer Attention</strong>: Visualize attention mechanisms on different image patches</p></li>
<li><p><strong>Interactive Glossary</strong>: Explore definitions with popup explanations of neural-AI connections</p></li>
</ol>
</div>
<p>The interactive examples include sliders to adjust parameters, visualizations that update in real-time, and explanatory annotations to help you connect theoretical concepts with their practical implementations.</p>
<section id="ai-assisted-learning">
<h3>AI-Assisted Learning<a class="headerlink" href="#ai-assisted-learning" title="Link to this heading">#</a></h3>
<p>We’ve also integrated Jupyter AI to enhance your learning experience. With Jupyter AI, you can:</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Explore the <a class="reference internal" href="jupyter_ai_demo.html"><span class="std std-doc">AI-Assisted Learning notebook</span></a> to:</p>
<ol class="arabic simple">
<li><p><strong>Generate Code</strong>: Get implementation help for neuroscience-inspired AI models</p></li>
<li><p><strong>Receive Explanations</strong>: Ask for clarification on complex concepts</p></li>
<li><p><strong>Debug Implementations</strong>: Fix and improve your code</p></li>
<li><p><strong>Create Visualizations</strong>: Generate custom visualizations for neural data</p></li>
</ol>
</div>
<p>This integration of AI assistance allows for a more dynamic, personalized learning experience that adapts to your specific interests and questions about the case studies.</p>
</section>
<section id="presentation-materials">
<h3>Presentation Materials<a class="headerlink" href="#presentation-materials" title="Link to this heading">#</a></h3>
<p>For educators and presenters, we’ve created a guide to developing slide presentations from the handbook content:</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Check out our <a class="reference internal" href="rise_slides_demo.html"><span class="std std-doc">RISE presentation guide</span></a> to learn how to:</p>
<ol class="arabic simple">
<li><p><strong>Create Interactive Slides</strong>: Transform notebook content into polished presentations</p></li>
<li><p><strong>Execute Live Code</strong>: Run code demonstrations during presentations</p></li>
<li><p><strong>Add Interactive Elements</strong>: Include widgets and visualizations in slides</p></li>
<li><p><strong>Customize Styling</strong>: Adjust themes and transitions for your audience</p></li>
</ol>
</div>
<p>RISE (Reveal.js - Jupyter/IPython Slideshow Extension) allows you to create engaging presentations directly from Jupyter notebooks, perfect for teaching the concepts covered in this chapter.</p>
</section>
</section>
<section id="further-reading">
<h2>20.10 Further Reading<a class="headerlink" href="#further-reading" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Hassabis, D., Kumaran, D., Summerfield, C., &amp; Botvinick, M. (2017). Neuroscience-inspired artificial intelligence. <em>Neuron, 95</em>(2), 245-258.</p></li>
<li><p>Kriegeskorte, N., &amp; Douglas, P. K. (2018). Cognitive computational neuroscience. <em>Nature Neuroscience, 21</em>(9), 1148-1160.</p></li>
<li><p>Zador, A. M. (2019). A critique of pure learning and what artificial neural networks can learn from animal brains. <em>Nature Communications, 10</em>(1), 1-7.</p></li>
<li><p>Richards, B. A., et al. (2019). A deep learning framework for neuroscience. <em>Nature Neuroscience, 22</em>(11), 1761-1770.</p></li>
<li><p>Marblestone, A. H., Wayne, G., &amp; Kording, K. P. (2016). Toward an integration of deep learning and neuroscience. <em>Frontiers in Computational Neuroscience, 10</em>, 94.</p></li>
<li><p>Botvinick, M., et al. (2020). Deep reinforcement learning and its neuroscientific implications. <em>Neuron, 107</em>(4), 603-616.</p></li>
</ul>
</section>
<div class="toctree-wrapper compound">
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "executablebooks/jupyter-book",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./part6"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="ch19_cognitive_neuro_dl.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Cognitive Neuroscience and Deep Learning</p>
      </div>
    </a>
    <a class="right-next"
       href="ch20_interactive.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Interactive Examples for Case Studies in NeuroAI</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#chapter-goals">Chapter Goals</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-from-theory-to-practice">20.1 Introduction: From Theory to Practice</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#case-study-deep-predictive-coding-networks">20.2 Case Study: Deep Predictive Coding Networks</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#background-and-motivation">20.2.1 Background and Motivation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implementation-prednet-architecture">20.2.2 Implementation: PredNet Architecture</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#results-and-evaluation">20.2.3 Results and Evaluation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#neuroscience-connection">20.2.4 Neuroscience Connection</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#limitations-and-future-directions">20.2.5 Limitations and Future Directions</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#case-study-hippocampal-replay-for-reinforcement-learning">20.3 Case Study: Hippocampal Replay for Reinforcement Learning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">20.3.1 Background and Motivation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implementation-prioritized-experience-replay">20.3.2 Implementation: Prioritized Experience Replay</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">20.3.3 Results and Evaluation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">20.3.4 Neuroscience Connection</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">20.3.5 Limitations and Future Directions</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#case-study-attention-mechanisms-in-vision-transformers">20.4 Case Study: Attention Mechanisms in Vision Transformers</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">20.4.1 Background and Motivation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implementation-vision-transformer">20.4.2 Implementation: Vision Transformer</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">20.4.3 Results and Evaluation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">20.4.4 Neuroscience Connection</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">20.4.5 Limitations and Future Directions</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#case-study-neural-data-analysis-with-latent-variable-models">20.5 Case Study: Neural Data Analysis with Latent Variable Models</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">20.5.1 Background and Motivation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implementation-latent-factor-analysis-via-dynamical-systems-lfads">20.5.2 Implementation: Latent Factor Analysis via Dynamical Systems (LFADS)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">20.5.3 Results and Evaluation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">20.5.4 Neuroscience Connection</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">20.5.5 Limitations and Future Directions</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lessons-from-successful-neuroai-integration">20.6 Lessons from Successful NeuroAI Integration</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#common-patterns-of-success">20.6.1 Common Patterns of Success</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#practical-implementation-strategies">20.6.2 Practical Implementation Strategies</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interdisciplinary-collaboration-best-practices">20.6.3 Interdisciplinary Collaboration Best Practices</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#practical-exercise-implementing-a-neuroscience-inspired-ai-component">20.7 Practical Exercise: Implementing a Neuroscience-Inspired AI Component</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#chapter-take-aways">20.8 Chapter Take-aways</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interactive-materials-and-exercises">20.9 Interactive Materials and Exercises</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ai-assisted-learning">AI-Assisted Learning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#presentation-materials">Presentation Materials</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#further-reading">20.10 Further Reading</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Richard Young
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2025.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>