# Chapter 9: Classical Machine-Learning Foundations

## 9.0 Chapter Goals
- Understand core machine learning principles and algorithms
- Connect ML approaches to learning in biological systems
- Implement key algorithms from scratch
- Apply classical ML to neuroscience problems

## 9.1 Learning Paradigms
- Supervised, unsupervised, and reinforcement learning
- Generative vs discriminative models
- Online vs batch learning
- Transfer learning and domain adaptation

## 9.2 Core ML Algorithms
- Linear models and logistic regression
- Support vector machines
- Decision trees and random forests
- Clustering algorithms (k-means, hierarchical)

## 9.3 Model Evaluation
- Cross-validation techniques
- Regularization approaches
- Bias-variance trade-off
- Evaluation metrics for different tasks

## 9.4 Feature Engineering
- Feature selection methods
- Dimensionality reduction
- Handling categorical variables
- Scaling and normalization

## 9.5 Neural Basis of ML
- Biological parallels to supervised learning
- Neurobiological clustering mechanisms
- Reinforcement learning in the brain
- Feature learning in sensory systems

## 9.6 Code Lab
- Implementing linear and logistic regression
- Building and evaluating decision trees
- Clustering neural activity patterns
- Feature selection for neural decoding

## 9.7 Take-aways
- ML algorithms formalize learning principles
- Different algorithms suit different problem types
- Feature engineering remains critical despite advances

## 9.8 Further Reading & Media
- Bishop (2006) - "Pattern Recognition and Machine Learning"
- Hastie, Tibshirani & Friedman - "The Elements of Statistical Learning"
- Niv (2009) - "Reinforcement learning in the brain"