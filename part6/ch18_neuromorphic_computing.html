
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Chapter 18: Neuromorphic Computing &#8212; The Neuroscience of AI</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'part6/ch18_neuromorphic_computing';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="canonical" href="https://neuroai-handbook.github.io/part6/ch18_neuromorphic_computing.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Chapter 19: Cognitive Neuroscience and Deep Learning" href="ch19_cognitive_neuro_dl.html" />
    <link rel="prev" title="Chapter 17: Brain-Computer Interfaces and Human-AI Interaction" href="ch17_bci_human_ai_interfaces.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/nai.png" class="logo__image only-light" alt="The Neuroscience of AI - Home"/>
    <script>document.write(`<img src="../_static/nai.png" class="logo__image only-dark" alt="The Neuroscience of AI - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    The Neuroscience of AI
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Cover</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../cover.html">Cover</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Front Matter</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../frontmatter/copyright.html">Copyright</a></li>
<li class="toctree-l1"><a class="reference internal" href="../frontmatter/acknowledgments.html">Acknowledgments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../frontmatter/about.html">About This Book</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part I · Brains &amp; Inspiration</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../part1/ch01_intro.html">Chapter 1: Introduction to Neuroscience ↔ AI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part1/ch02_neuro_foundations.html">Chapter 2: Neuroscience Foundations for AI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part1/ch03_spatial_navigation.html">Chapter 3: Spatial Navigation – Place &amp; Grid Cells</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part1/ch04_perception_pipeline.html">Chapter 4: Perception Pipeline – Visual Cortex → CNNs</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part II · Brains Meet Math &amp; Data</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../part2/ch05_brain_networks.html">Chapter 5: Default-Mode vs Executive Control Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part2/ch06_neurostimulation.html">Chapter 6: Neurostimulation &amp; Plasticity</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part2/ch07_information_theory.html">Chapter 7: Information Theory Essentials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part2/ch08_data_science_pipeline.html">Chapter 8: Data-Science Pipeline in Python</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part III · Learning Machines</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../part3/ch09_ml_foundations.html">Chapter 9: Classical Machine-Learning Foundations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part3/ch10_deep_learning.html">Chapter 10: Deep Learning: Training &amp; Optimisation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part3/ch11_sequence_models.html">Chapter 11: Sequence Models: RNN → Attention → Transformer</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part IV · Frontier Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../part4/ch12_large_language_models.html">Chapter 12: Large Language Models &amp; Fine-Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part4/ch13_multimodal_models.html">Chapter 13: Multimodal &amp; Diffusion Models</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part V · Ethics &amp; Futures</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../part5/ch15_ethical_ai.html">Chapter 15: Ethical AI - Considerations for NeuroAI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part5/ch16_future_directions.html">Chapter 16: Where Next for Neuro-AI?</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part VI · Advanced Applications</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="ch17_bci_human_ai_interfaces.html">Chapter 17: Brain-Computer Interfaces and Human-AI Interaction</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Chapter 18: Neuromorphic Computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="ch19_cognitive_neuro_dl.html">Chapter 19: Cognitive Neuroscience and Deep Learning</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="ch20_case_studies.html">Case Studies in NeuroAI</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="ch20_interactive.html">Interactive NeuroAI Case Studies</a></li>
<li class="toctree-l2"><a class="reference internal" href="jupyter_ai_demo.html">AI-Assisted Learning with Jupyter AI</a></li>
<li class="toctree-l2"><a class="reference internal" href="rise_slides_demo.html">Creating Presentations with RISE</a></li>


</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="ch21_ai_for_neuro_discovery.html">Chapter 21: AI for Neuroscience Discovery</a></li>
<li class="toctree-l1"><a class="reference internal" href="ch22_embodied_ai_robotics.html">Chapter 22: Embodied AI and Robotics</a></li>
<li class="toctree-l1"><a class="reference internal" href="ch23_lifelong_learning.html">Chapter 23: Lifelong Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="ch24_quantum_computing_neuroai.html">Chapter 24: Quantum Computing and NeuroAI</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Appendices</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../appendices/glossary.html">Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../appendices/math_python_refresher.html">Appendix A: Math &amp; Python Mini-Refresher</a></li>
<li class="toctree-l1"><a class="reference internal" href="../appendices/dataset_catalogue.html">Appendix B: Dataset Catalogue</a></li>
<li class="toctree-l1"><a class="reference internal" href="../appendices/colab_setup.html">Appendix C: Google Colab Setup for NeuroAI</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/edit/master/docs/part6/ch18_neuromorphic_computing.md" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fpart6/ch18_neuromorphic_computing.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/part6/ch18_neuromorphic_computing.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Chapter 18: Neuromorphic Computing</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#chapter-goals">18.0 Chapter Goals</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#neuromorphic-computing-principles">18.1 Neuromorphic Computing Principles</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#spiking-neural-networks">18.1.1 Spiking Neural Networks</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#resistive-computing-and-memristors">18.1.2 Resistive Computing and Memristors</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#event-based-sensors">18.1.3 Event-Based Sensors</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#brain-inspired-chips">18.1.4 Brain-Inspired Chips</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#applications-of-neuromorphic-computing">18.2 Applications of Neuromorphic Computing</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#edge-computing-and-iot">18.2.1 Edge Computing and IoT</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#robotics-and-autonomous-systems">18.2.2 Robotics and Autonomous Systems</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#brain-computer-interfaces">18.2.3 Brain-Computer Interfaces</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simulation-and-implementation">18.3 Simulation and Implementation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#software-frameworks-for-neuromorphic-computing">18.3.1 Software Frameworks for Neuromorphic Computing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#converting-anns-to-snns">18.3.2 Converting ANNs to SNNs</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#code-lab-spiking-neural-network">18.4 Code Lab: Spiking Neural Network</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#future-directions">18.5 Future Directions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hardware-advances">18.5.1 Hardware Advances</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#algorithms-and-learning">18.5.2 Algorithms and Learning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#system-integration">18.5.3 System Integration</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#take-aways">18.6 Take-aways</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#further-reading">18.7 Further Reading</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="chapter-18-neuromorphic-computing">
<h1>Chapter 18: Neuromorphic Computing<a class="headerlink" href="#chapter-18-neuromorphic-computing" title="Link to this heading">#</a></h1>
<p>This chapter delves into neuromorphic computing systems, hardware architectures inspired by the structure and function of biological neural systems. These approaches offer potentially revolutionary advantages in energy efficiency and computational capability for specific tasks.</p>
<div style="page-break-before:always;"></div>
<section id="chapter-goals">
<h2>18.0 Chapter Goals<a class="headerlink" href="#chapter-goals" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Understand the principles and advantages of neuromorphic computing</p></li>
<li><p>Explore spiking neural networks as a brain-inspired computational paradigm</p></li>
<li><p>Learn how resistive computing elements can implement synaptic-like behavior</p></li>
<li><p>Examine event-based sensing and processing paradigms</p></li>
<li><p>Implement and simulate a simple spiking neural network</p></li>
</ul>
</section>
<section id="neuromorphic-computing-principles">
<h2>18.1 Neuromorphic Computing Principles<a class="headerlink" href="#neuromorphic-computing-principles" title="Link to this heading">#</a></h2>
<p>Neuromorphic computing refers to hardware systems that implement neural processing principles directly in circuitry, rather than simulating them on conventional hardware. This approach can offer dramatic improvements in energy efficiency, especially for tasks like pattern recognition and sensory processing.</p>
<p><img alt="Neuromorphic Computing" src="../_images/neuromorphic_computing1.svg" /></p>
<p>Key characteristics of neuromorphic systems include:</p>
<ul class="simple">
<li><p><strong>Parallel processing</strong>: Massive parallelism similar to the brain’s architecture</p></li>
<li><p><strong>Co-located processing and memory</strong>: Avoiding the von Neumann bottleneck</p></li>
<li><p><strong>Event-driven computation</strong>: Computing only when needed, rather than at fixed clock cycles</p></li>
<li><p><strong>In-memory computing</strong>: Performing operations where data is stored</p></li>
<li><p><strong>Sparse, asynchronous signaling</strong>: Communication through discrete events rather than continuous values</p></li>
</ul>
<section id="spiking-neural-networks">
<h3>18.1.1 Spiking Neural Networks<a class="headerlink" href="#spiking-neural-networks" title="Link to this heading">#</a></h3>
<p>Traditional artificial neural networks use continuous activation values, but biological neurons communicate through discrete all-or-nothing action potentials (spikes). Spiking Neural Networks (SNNs) mimic this biological principle:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">matplotlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="k">class</span><span class="w"> </span><span class="nc">SpikingNeuron</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">tau_m</span><span class="o">=</span><span class="mf">10.0</span><span class="p">,</span> <span class="n">tau_ref</span><span class="o">=</span><span class="mf">2.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Simple Leaky Integrate-and-Fire neuron model</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        - threshold: Membrane potential threshold for spike generation</span>
<span class="sd">        - tau_m: Membrane time constant (ms)</span>
<span class="sd">        - tau_ref: Refractory period (ms)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span> <span class="o">=</span> <span class="n">threshold</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tau_m</span> <span class="o">=</span> <span class="n">tau_m</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tau_ref</span> <span class="o">=</span> <span class="n">tau_ref</span>
        
        <span class="c1"># State variables</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">membrane_potential</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_spike_time</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">t</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># Current time</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_current</span><span class="p">,</span> <span class="n">dt</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Update neuron state and check for spike</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        - input_current: Input current to the neuron</span>
<span class="sd">        - dt: Time step (ms)</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">        - 1 if neuron spikes, 0 otherwise</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">t</span> <span class="o">+=</span> <span class="n">dt</span>
        
        <span class="c1"># Check if in refractory period</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">t</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_spike_time</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tau_ref</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">0</span>
        
        <span class="c1"># Update membrane potential (leaky integration)</span>
        <span class="n">d_v</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">membrane_potential</span> <span class="o">+</span> <span class="n">input_current</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">tau_m</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">membrane_potential</span> <span class="o">+=</span> <span class="n">d_v</span> <span class="o">*</span> <span class="n">dt</span>
        
        <span class="c1"># Check for spike</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">membrane_potential</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">membrane_potential</span> <span class="o">=</span> <span class="mf">0.0</span>  <span class="c1"># Reset</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">last_spike_time</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">t</span>
            <span class="k">return</span> <span class="mi">1</span>
        
        <span class="k">return</span> <span class="mi">0</span>
</pre></div>
</div>
<p>Unlike rate-based ANNs, SNNs encode information in the precise timing of spikes and can be more energy-efficient by only computing when spikes occur. Information can be encoded in several ways:</p>
<ol class="arabic simple">
<li><p><strong>Rate coding</strong>: Information represented by the frequency of spikes</p></li>
<li><p><strong>Temporal coding</strong>: Information in the precise timing of spikes</p></li>
<li><p><strong>Population coding</strong>: Information distributed across multiple neurons</p></li>
<li><p><strong>Rank-order coding</strong>: Information in the order of neuron firing</p></li>
</ol>
</section>
<section id="resistive-computing-and-memristors">
<h3>18.1.2 Resistive Computing and Memristors<a class="headerlink" href="#resistive-computing-and-memristors" title="Link to this heading">#</a></h3>
<p>A key limitation in conventional computing is the energy cost of moving data between memory and processing units (the “von Neumann bottleneck”). In contrast, the brain co-locates memory and computation in synapses.</p>
<p>Memristors are resistive devices whose resistance changes based on the history of current flow through them. They can implement synaptic weights directly in hardware:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">Memristor</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">r_on</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">r_off</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">initial_state</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Simple memristor model</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        - r_on: Low resistance state (ohms)</span>
<span class="sd">        - r_off: High resistance state (ohms)</span>
<span class="sd">        - initial_state: Initial state variable (0-1)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">r_on</span> <span class="o">=</span> <span class="n">r_on</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">r_off</span> <span class="o">=</span> <span class="n">r_off</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state</span> <span class="o">=</span> <span class="n">initial_state</span>  <span class="c1"># Internal state variable (0-1)</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">get_resistance</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Calculate current resistance based on internal state&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">r_on</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">r_off</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">r_on</span><span class="p">)</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">voltage</span><span class="p">,</span> <span class="n">dt</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="n">learn_rate</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Update memristor state based on applied voltage</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        - voltage: Applied voltage</span>
<span class="sd">        - dt: Time step</span>
<span class="sd">        - learn_rate: Learning rate parameter</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Simplified nonlinear update rule</span>
        <span class="k">if</span> <span class="n">voltage</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Increase resistance (depression)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">state</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span> <span class="o">+</span> <span class="n">learn_rate</span> <span class="o">*</span> <span class="n">voltage</span> <span class="o">*</span> <span class="n">dt</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Decrease resistance (potentiation)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">state</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span> <span class="o">+</span> <span class="n">learn_rate</span> <span class="o">*</span> <span class="n">voltage</span> <span class="o">*</span> <span class="n">dt</span><span class="p">)</span>
</pre></div>
</div>
<p>Memristor crossbar arrays can implement matrix multiplication operations directly in hardware with orders of magnitude less energy than digital implementations. This is especially valuable for neural network inference, where the same weights are used repeatedly.</p>
<p>Benefits of memristor-based computation include:</p>
<ul class="simple">
<li><p><strong>Energy efficiency</strong>: 10-100× lower energy per operation</p></li>
<li><p><strong>Density</strong>: Higher integration density than CMOS transistors</p></li>
<li><p><strong>Non-volatility</strong>: Retaining state without power</p></li>
<li><p><strong>Analog computation</strong>: Native implementation of multiply-accumulate operations</p></li>
</ul>
</section>
<section id="event-based-sensors">
<h3>18.1.3 Event-Based Sensors<a class="headerlink" href="#event-based-sensors" title="Link to this heading">#</a></h3>
<p>Event-based sensors like Dynamic Vision Sensors (DVS) mimic the retina by only transmitting information when pixels detect changes in brightness:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">simulate_dvs_output</span><span class="p">(</span><span class="n">video_frames</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Simulate output of a Dynamic Vision Sensor from video frames</span>
<span class="sd">    </span>
<span class="sd">    Parameters:</span>
<span class="sd">    - video_frames: Sequence of image frames (T, H, W)</span>
<span class="sd">    - threshold: Change threshold for generating events</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">    - events: List of (x, y, t, polarity) tuples</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">events</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">prev_frame</span> <span class="o">=</span> <span class="n">video_frames</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    
    <span class="k">for</span> <span class="n">t</span><span class="p">,</span> <span class="n">frame</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">video_frames</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="mi">1</span><span class="p">):</span>
        <span class="c1"># Calculate log intensity change</span>
        <span class="n">log_diff</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">frame</span> <span class="o">+</span> <span class="mf">1e-6</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">prev_frame</span> <span class="o">+</span> <span class="mf">1e-6</span><span class="p">)</span>
        
        <span class="c1"># Generate ON events (positive changes)</span>
        <span class="n">on_events</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">log_diff</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">on_events</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">on_events</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">events</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>  <span class="c1"># x, y, time, polarity</span>
        
        <span class="c1"># Generate OFF events (negative changes)</span>
        <span class="n">off_events</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">log_diff</span> <span class="o">&lt;</span> <span class="o">-</span><span class="n">threshold</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">off_events</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">off_events</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">events</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>  <span class="c1"># x, y, time, polarity</span>
        
        <span class="n">prev_frame</span> <span class="o">=</span> <span class="n">frame</span>
    
    <span class="k">return</span> <span class="n">events</span>
</pre></div>
</div>
<p>This event-based approach drastically reduces data transmission and power requirements, enabling high-speed vision processing with minimal energy. Event-based sensors have several advantages:</p>
<ul class="simple">
<li><p><strong>High dynamic range</strong>: &gt;120dB vs. 60-70dB for conventional cameras</p></li>
<li><p><strong>High temporal resolution</strong>: Microsecond-level precision</p></li>
<li><p><strong>Low bandwidth</strong>: 10-100× less data than conventional video</p></li>
<li><p><strong>Low latency</strong>: Events transmitted immediately when detected</p></li>
<li><p><strong>Low power</strong>: 1000× more efficient than conventional imaging</p></li>
</ul>
</section>
<section id="brain-inspired-chips">
<h3>18.1.4 Brain-Inspired Chips<a class="headerlink" href="#brain-inspired-chips" title="Link to this heading">#</a></h3>
<p>Several neuromorphic hardware platforms have demonstrated remarkable efficiency:</p>
<ol class="arabic simple">
<li><p><strong>IBM TrueNorth</strong>: 1 million digital neurons with 256 million synapses, consuming only ~70mW of power.</p></li>
<li><p><strong>Intel Loihi</strong>: Implements on-chip learning with ~130,000 neurons and 130 million synapses per chip.</p></li>
<li><p><strong>SpiNNaker</strong>: Massively parallel architecture with ARM processors designed specifically for neural simulations.</p></li>
<li><p><strong>BrainScaleS</strong>: Analog/mixed-signal system operating at accelerated time scales.</p></li>
</ol>
<p>These systems achieve energy efficiencies 100-1000× better than conventional architectures for certain tasks:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">compare_energy_efficiency</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compare energy efficiency for image recognition task</span>
<span class="sd">    (based on published benchmarks)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">architectures</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;GPU (NVIDIA V100)&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;joules_per_inference&quot;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">:</span> <span class="mf">0.76</span><span class="p">},</span>
        <span class="s2">&quot;CPU (Intel Xeon)&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;joules_per_inference&quot;</span><span class="p">:</span> <span class="mf">5.0</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">:</span> <span class="mf">0.76</span><span class="p">},</span>
        <span class="s2">&quot;FPGA&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;joules_per_inference&quot;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">:</span> <span class="mf">0.75</span><span class="p">},</span>
        <span class="s2">&quot;Loihi&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;joules_per_inference&quot;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">:</span> <span class="mf">0.74</span><span class="p">},</span>
        <span class="s2">&quot;TrueNorth&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;joules_per_inference&quot;</span><span class="p">:</span> <span class="mf">0.0001</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">:</span> <span class="mf">0.70</span><span class="p">}</span>
    <span class="p">}</span>
    
    <span class="c1"># Calculate energy efficiency (accuracy per joule)</span>
    <span class="k">for</span> <span class="n">arch</span><span class="p">,</span> <span class="n">stats</span> <span class="ow">in</span> <span class="n">architectures</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">efficiency</span> <span class="o">=</span> <span class="n">stats</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="n">stats</span><span class="p">[</span><span class="s2">&quot;joules_per_inference&quot;</span><span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">arch</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">efficiency</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> accuracy/joule&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div style="page-break-before:always;"></div>
</section>
</section>
<section id="applications-of-neuromorphic-computing">
<h2>18.2 Applications of Neuromorphic Computing<a class="headerlink" href="#applications-of-neuromorphic-computing" title="Link to this heading">#</a></h2>
<p>Neuromorphic systems are particularly well-suited for specific applications:</p>
<section id="edge-computing-and-iot">
<h3>18.2.1 Edge Computing and IoT<a class="headerlink" href="#edge-computing-and-iot" title="Link to this heading">#</a></h3>
<p>Low-power neuromorphic chips are ideal for intelligent edge devices:</p>
<ul class="simple">
<li><p><strong>Sensor Processing</strong>: Processing sensor data locally with minimal power</p></li>
<li><p><strong>Anomaly Detection</strong>: Identifying unusual patterns without continuous transmission</p></li>
<li><p><strong>Keyword Spotting</strong>: Recognizing specific audio triggers</p></li>
<li><p><strong>Smart Cameras</strong>: Event-based vision for surveillance and monitoring</p></li>
</ul>
</section>
<section id="robotics-and-autonomous-systems">
<h3>18.2.2 Robotics and Autonomous Systems<a class="headerlink" href="#robotics-and-autonomous-systems" title="Link to this heading">#</a></h3>
<p>Neuromorphic computing enables efficient sensorimotor processing:</p>
<ul class="simple">
<li><p><strong>Real-time Control</strong>: Low-latency sensory processing and actuation</p></li>
<li><p><strong>Obstacle Avoidance</strong>: Fast processing of visual information for navigation</p></li>
<li><p><strong>Power Efficiency</strong>: Extended operation time on limited power budgets</p></li>
<li><p><strong>Adaptive Behavior</strong>: On-chip learning for environmental adaptation</p></li>
</ul>
</section>
<section id="brain-computer-interfaces">
<h3>18.2.3 Brain-Computer Interfaces<a class="headerlink" href="#brain-computer-interfaces" title="Link to this heading">#</a></h3>
<p>The low power and event-driven nature of neuromorphic systems makes them ideal for neural interfaces:</p>
<ul class="simple">
<li><p><strong>Neural Signal Processing</strong>: Efficient processing of sparse neural signals</p></li>
<li><p><strong>Closed-loop Stimulation</strong>: Real-time response to detected neural patterns</p></li>
<li><p><strong>Portable Medical Devices</strong>: Neurological monitoring with long battery life</p></li>
<li><p><strong>Neuroprosthetics</strong>: Direct processing of neural signals for prosthetic control</p></li>
</ul>
</section>
</section>
<section id="simulation-and-implementation">
<h2>18.3 Simulation and Implementation<a class="headerlink" href="#simulation-and-implementation" title="Link to this heading">#</a></h2>
<section id="software-frameworks-for-neuromorphic-computing">
<h3>18.3.1 Software Frameworks for Neuromorphic Computing<a class="headerlink" href="#software-frameworks-for-neuromorphic-computing" title="Link to this heading">#</a></h3>
<p>Several frameworks support the development and simulation of spiking neural networks:</p>
<ol class="arabic simple">
<li><p><strong>Brian2</strong>: Python-based simulator for spiking neural networks</p></li>
<li><p><strong>NEST</strong>: Simulator for large-scale networks of spiking neurons</p></li>
<li><p><strong>PyNN</strong>: API for simulator-independent specification of neural network models</p></li>
<li><p><strong>Nengo</strong>: Python library for building and simulating neural models</p></li>
<li><p><strong>BindsNET</strong>: SNN framework built on PyTorch</p></li>
<li><p><strong>Norse</strong>: Deep learning with spiking neural networks in PyTorch</p></li>
</ol>
</section>
<section id="converting-anns-to-snns">
<h3>18.3.2 Converting ANNs to SNNs<a class="headerlink" href="#converting-anns-to-snns" title="Link to this heading">#</a></h3>
<p>Converting traditional artificial neural networks to spiking neural networks allows leveraging existing deep learning methods:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">convert_ann_to_snn</span><span class="p">(</span><span class="n">ann_model</span><span class="p">,</span> <span class="n">simulation_time</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">dt</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert a trained ANN to a rate-based SNN</span>
<span class="sd">    </span>
<span class="sd">    Parameters:</span>
<span class="sd">    - ann_model: Trained artificial neural network</span>
<span class="sd">    - simulation_time: Simulation duration in ms</span>
<span class="sd">    - dt: Time step in ms</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">    - snn_model: Equivalent spiking neural network</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># In practice, this would involve:</span>
    <span class="c1"># 1. Extracting weights from ANN</span>
    <span class="c1"># 2. Creating appropriate SNN architecture</span>
    <span class="c1"># 3. Setting thresholds based on activation statistics</span>
    <span class="c1"># 4. Adjusting for rate-based operation</span>
    
    <span class="c1"># Placeholder implementation</span>
    <span class="n">snn_model</span> <span class="o">=</span> <span class="n">create_empty_snn_model</span><span class="p">()</span>
    
    <span class="c1"># For each layer in the ANN</span>
    <span class="k">for</span> <span class="n">layer_idx</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">ann_model</span><span class="o">.</span><span class="n">layers</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">):</span>
            <span class="c1"># Copy weights</span>
            <span class="n">weights</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="n">set_snn_weights</span><span class="p">(</span><span class="n">snn_model</span><span class="p">,</span> <span class="n">layer_idx</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
            
            <span class="c1"># Set appropriate thresholds based on activation statistics</span>
            <span class="n">activation_scale</span> <span class="o">=</span> <span class="n">estimate_activation_scale</span><span class="p">(</span><span class="n">ann_model</span><span class="p">,</span> <span class="n">layer_idx</span><span class="p">)</span>
            <span class="n">set_snn_thresholds</span><span class="p">(</span><span class="n">snn_model</span><span class="p">,</span> <span class="n">layer_idx</span><span class="p">,</span> <span class="n">activation_scale</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">snn_model</span>
</pre></div>
</div>
<p>Key challenges in ANN-to-SNN conversion include:</p>
<ul class="simple">
<li><p><strong>Activation function mapping</strong>: Converting ReLU to spike rates</p></li>
<li><p><strong>Threshold calibration</strong>: Setting appropriate firing thresholds</p></li>
<li><p><strong>Temporal dynamics</strong>: Handling the time dimension</p></li>
<li><p><strong>Training-aware conversion</strong>: Optimizing ANNs specifically for SNN conversion</p></li>
</ul>
</section>
</section>
<section id="code-lab-spiking-neural-network">
<h2>18.4 Code Lab: Spiking Neural Network<a class="headerlink" href="#code-lab-spiking-neural-network" title="Link to this heading">#</a></h2>
<p>Let’s implement a simple spiking neural network that demonstrates the key principles of neuromorphic computing:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">matplotlib.animation</span><span class="w"> </span><span class="kn">import</span> <span class="n">FuncAnimation</span>

<span class="k">class</span><span class="w"> </span><span class="nc">SpikingNeuralNetwork</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_input</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">,</span> <span class="n">n_output</span><span class="p">,</span> <span class="n">dt</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Simple Spiking Neural Network with LIF neurons</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        - n_input: Number of input neurons</span>
<span class="sd">        - n_hidden: Number of hidden neurons</span>
<span class="sd">        - n_output: Number of output neurons</span>
<span class="sd">        - dt: Simulation time step (ms)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_input</span> <span class="o">=</span> <span class="n">n_input</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_hidden</span> <span class="o">=</span> <span class="n">n_hidden</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_output</span> <span class="o">=</span> <span class="n">n_output</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dt</span> <span class="o">=</span> <span class="n">dt</span>
        
        <span class="c1"># Initialize random weights</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w_input_hidden</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="p">(</span><span class="n">n_hidden</span><span class="p">,</span> <span class="n">n_input</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w_hidden_output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="p">(</span><span class="n">n_output</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">))</span>
        
        <span class="c1"># Neuron parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v_rest</span> <span class="o">=</span> <span class="o">-</span><span class="mf">70.0</span>  <span class="c1"># resting potential (mV)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v_reset</span> <span class="o">=</span> <span class="o">-</span><span class="mf">75.0</span>  <span class="c1"># reset potential (mV)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v_threshold</span> <span class="o">=</span> <span class="o">-</span><span class="mf">55.0</span>  <span class="c1"># threshold potential (mV)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tau_m</span> <span class="o">=</span> <span class="mf">10.0</span>  <span class="c1"># membrane time constant (ms)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">refractory_period</span> <span class="o">=</span> <span class="mf">2.0</span>  <span class="c1"># refractory period (ms)</span>
        
        <span class="c1"># State variables</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v_hidden</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_rest</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v_output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_output</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_rest</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">refractory_time_hidden</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">refractory_time_output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_output</span><span class="p">)</span>
        
        <span class="c1"># Recording</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">spike_history_hidden</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">spike_history_output</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v_history_hidden</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v_history_output</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">t</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># Current time</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">reset_state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Reset network state&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v_hidden</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_hidden</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_rest</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v_output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_output</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_rest</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">refractory_time_hidden</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_hidden</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">refractory_time_output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_output</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">spike_history_hidden</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">spike_history_output</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v_history_hidden</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v_history_output</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">t</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_spikes</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Run one simulation step</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        - input_spikes: Binary array of input spikes (0 or 1)</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">        - output_spikes: Binary array of output spikes</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">t</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dt</span>
        
        <span class="c1"># Update hidden layer</span>
        <span class="c1"># Calculate input current from input layer spikes</span>
        <span class="n">input_current</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w_input_hidden</span><span class="p">,</span> <span class="n">input_spikes</span><span class="p">)</span>
        
        <span class="c1"># Check which neurons are not in refractory period</span>
        <span class="n">active_hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">refractory_time_hidden</span> <span class="o">&lt;=</span> <span class="mi">0</span>
        
        <span class="c1"># Update membrane potentials for active neurons</span>
        <span class="n">dv_hidden</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">v_hidden</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_rest</span> <span class="o">+</span> <span class="n">input_current</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">tau_m</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v_hidden</span><span class="p">[</span><span class="n">active_hidden</span><span class="p">]</span> <span class="o">+=</span> <span class="n">dv_hidden</span><span class="p">[</span><span class="n">active_hidden</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">dt</span>
        
        <span class="c1"># Check for spikes in hidden layer</span>
        <span class="n">hidden_spikes</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">v_hidden</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_threshold</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        
        <span class="c1"># Reset membrane potential and set refractory period for spiked neurons</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">hidden_spikes</span><span class="p">):</span>
            <span class="n">spike_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">hidden_spikes</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">v_hidden</span><span class="p">[</span><span class="n">spike_indices</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_reset</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">refractory_time_hidden</span><span class="p">[</span><span class="n">spike_indices</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">refractory_period</span>
        
        <span class="c1"># Decrement refractory time</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">refractory_time_hidden</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dt</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">refractory_time_hidden</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">refractory_time_hidden</span><span class="p">)</span>
        
        <span class="c1"># Update output layer (similar process)</span>
        <span class="n">output_current</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w_hidden_output</span><span class="p">,</span> <span class="n">hidden_spikes</span><span class="p">)</span>
        <span class="n">active_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">refractory_time_output</span> <span class="o">&lt;=</span> <span class="mi">0</span>
        
        <span class="n">dv_output</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">v_output</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_rest</span> <span class="o">+</span> <span class="n">output_current</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">tau_m</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v_output</span><span class="p">[</span><span class="n">active_output</span><span class="p">]</span> <span class="o">+=</span> <span class="n">dv_output</span><span class="p">[</span><span class="n">active_output</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">dt</span>
        
        <span class="n">output_spikes</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">v_output</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_threshold</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">output_spikes</span><span class="p">):</span>
            <span class="n">spike_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">output_spikes</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">v_output</span><span class="p">[</span><span class="n">spike_indices</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_reset</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">refractory_time_output</span><span class="p">[</span><span class="n">spike_indices</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">refractory_period</span>
            
        <span class="bp">self</span><span class="o">.</span><span class="n">refractory_time_output</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dt</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">refractory_time_output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">refractory_time_output</span><span class="p">)</span>
        
        <span class="c1"># Record history</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">spike_history_hidden</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">hidden_spikes</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">spike_history_output</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output_spikes</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v_history_hidden</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">v_hidden</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v_history_output</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">v_output</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span>
        
        <span class="k">return</span> <span class="n">output_spikes</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">run_simulation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_pattern</span><span class="p">,</span> <span class="n">simulation_time</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Run simulation for specified time with given input pattern</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        - input_pattern: Function that returns input spikes at each time step</span>
<span class="sd">        - simulation_time: Total simulation time (ms)</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">        - output_history: History of output spikes</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">steps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">simulation_time</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">dt</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset_state</span><span class="p">()</span>
        
        <span class="n">output_history</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">steps</span><span class="p">):</span>
            <span class="n">t</span> <span class="o">=</span> <span class="n">step</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">dt</span>
            <span class="n">input_spikes</span> <span class="o">=</span> <span class="n">input_pattern</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
            <span class="n">output_spikes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">input_spikes</span><span class="p">)</span>
            <span class="n">output_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output_spikes</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">output_history</span><span class="p">)</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">plot_activity</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">)):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Plot spike raster and membrane potentials&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">spike_history_hidden</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No simulation data to plot&quot;</span><span class="p">)</span>
            <span class="k">return</span>
        
        <span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        
        <span class="c1"># Convert spike history to arrays</span>
        <span class="n">spikes_hidden</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">spike_history_hidden</span><span class="p">)</span>
        <span class="n">spikes_output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">spike_history_output</span><span class="p">)</span>
        
        <span class="c1"># Time array</span>
        <span class="n">time</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">spikes_hidden</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">dt</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dt</span><span class="p">)</span>
        
        <span class="c1"># Plot hidden layer spikes</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_hidden</span><span class="p">):</span>
            <span class="n">spike_times</span> <span class="o">=</span> <span class="n">time</span><span class="p">[</span><span class="n">spikes_hidden</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span>
            <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">spike_times</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">spike_times</span><span class="p">)</span> <span class="o">*</span> <span class="n">i</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Hidden Neuron&#39;</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Hidden Layer Spike Raster&#39;</span><span class="p">)</span>
        
        <span class="c1"># Plot output layer spikes</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_output</span><span class="p">):</span>
            <span class="n">spike_times</span> <span class="o">=</span> <span class="n">time</span><span class="p">[</span><span class="n">spikes_output</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span>
            <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">spike_times</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">spike_times</span><span class="p">)</span> <span class="o">*</span> <span class="n">i</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Output Neuron&#39;</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Output Layer Spike Raster&#39;</span><span class="p">)</span>
        
        <span class="c1"># Plot membrane potentials</span>
        <span class="n">v_hidden</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">v_history_hidden</span><span class="p">)</span>
        <span class="n">v_output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">v_history_output</span><span class="p">)</span>
        
        <span class="c1"># Plot a few hidden neurons</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_hidden</span><span class="p">)):</span>
            <span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="n">v_hidden</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Neuron </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">v_threshold</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Threshold&#39;</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Membrane Potential (mV)&#39;</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Hidden Layer Membrane Potentials&#39;</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
        
        <span class="c1"># Plot all output neurons</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_output</span><span class="p">):</span>
            <span class="n">axs</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="n">v_output</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Neuron </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">v_threshold</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Threshold&#39;</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Time (ms)&#39;</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Membrane Potential (mV)&#39;</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Output Layer Membrane Potentials&#39;</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
        
        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">fig</span>
</pre></div>
</div>
<p>Let’s demonstrate this SNN with a simple pattern recognition task:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">run_snn_demo</span><span class="p">():</span>
    <span class="c1"># Create a simple SNN with 5 input, 10 hidden, and 2 output neurons</span>
    <span class="n">snn</span> <span class="o">=</span> <span class="n">SpikingNeuralNetwork</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    
    <span class="c1"># Define input patterns (simplified)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">pattern_1</span><span class="p">(</span><span class="n">t</span><span class="p">):</span>
        <span class="c1"># Pattern 1: neurons 0, 1, 2 active</span>
        <span class="n">period</span> <span class="o">=</span> <span class="mi">20</span>  <span class="c1"># ms</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span> <span class="k">if</span> <span class="n">t</span> <span class="o">%</span> <span class="n">period</span> <span class="o">&lt;</span> <span class="mi">5</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
                        <span class="mi">1</span> <span class="k">if</span> <span class="p">(</span><span class="n">t</span> <span class="o">%</span> <span class="n">period</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">3</span> <span class="ow">and</span> <span class="p">(</span><span class="n">t</span> <span class="o">%</span> <span class="n">period</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">8</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
                        <span class="mi">1</span> <span class="k">if</span> <span class="p">(</span><span class="n">t</span> <span class="o">%</span> <span class="n">period</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">6</span> <span class="ow">and</span> <span class="p">(</span><span class="n">t</span> <span class="o">%</span> <span class="n">period</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">12</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
                        <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">pattern_2</span><span class="p">(</span><span class="n">t</span><span class="p">):</span>
        <span class="c1"># Pattern 2: neurons 2, 3, 4 active</span>
        <span class="n">period</span> <span class="o">=</span> <span class="mi">20</span>  <span class="c1"># ms</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span>
                        <span class="mi">1</span> <span class="k">if</span> <span class="p">(</span><span class="n">t</span> <span class="o">%</span> <span class="n">period</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span> <span class="ow">and</span> <span class="p">(</span><span class="n">t</span> <span class="o">%</span> <span class="n">period</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">7</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
                        <span class="mi">1</span> <span class="k">if</span> <span class="p">(</span><span class="n">t</span> <span class="o">%</span> <span class="n">period</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">5</span> <span class="ow">and</span> <span class="p">(</span><span class="n">t</span> <span class="o">%</span> <span class="n">period</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">10</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
                        <span class="mi">1</span> <span class="k">if</span> <span class="p">(</span><span class="n">t</span> <span class="o">%</span> <span class="n">period</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">8</span> <span class="ow">and</span> <span class="p">(</span><span class="n">t</span> <span class="o">%</span> <span class="n">period</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">15</span> <span class="k">else</span> <span class="mi">0</span><span class="p">])</span>
    
    <span class="c1"># Run simulations with different input patterns</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Running simulation for pattern 1...&quot;</span><span class="p">)</span>
    <span class="n">snn</span><span class="o">.</span><span class="n">run_simulation</span><span class="p">(</span><span class="n">pattern_1</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
    <span class="n">fig1</span> <span class="o">=</span> <span class="n">snn</span><span class="o">.</span><span class="n">plot_activity</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">fig1</span><span class="o">.</span><span class="n">number</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Pattern 1 Response&quot;</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Running simulation for pattern 2...&quot;</span><span class="p">)</span>
    <span class="n">snn</span><span class="o">.</span><span class="n">run_simulation</span><span class="p">(</span><span class="n">pattern_2</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
    <span class="n">fig2</span> <span class="o">=</span> <span class="n">snn</span><span class="o">.</span><span class="n">plot_activity</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">fig2</span><span class="o">.</span><span class="n">number</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Pattern 2 Response&quot;</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    
    <span class="k">return</span> <span class="s2">&quot;SNN demo completed&quot;</span>
</pre></div>
</div>
</section>
<section id="future-directions">
<h2>18.5 Future Directions<a class="headerlink" href="#future-directions" title="Link to this heading">#</a></h2>
<p>Neuromorphic computing is evolving rapidly with several exciting research directions:</p>
<section id="hardware-advances">
<h3>18.5.1 Hardware Advances<a class="headerlink" href="#hardware-advances" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>3D Integration</strong>: Increasing neuron and synapse density through vertical stacking</p></li>
<li><p><strong>Novel Materials</strong>: Exploring phase-change memory, ferroelectric devices, and spintronic devices</p></li>
<li><p><strong>Hybrid Systems</strong>: Combining neuromorphic and conventional computing architectures</p></li>
<li><p><strong>Nanoscale Devices</strong>: Moving toward truly brain-like densities with nanoscale components</p></li>
</ul>
</section>
<section id="algorithms-and-learning">
<h3>18.5.2 Algorithms and Learning<a class="headerlink" href="#algorithms-and-learning" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Local Learning Rules</strong>: Developing biologically plausible learning algorithms that don’t require global backpropagation</p></li>
<li><p><strong>Temporal Coding</strong>: Moving beyond rate coding to leverage timing information</p></li>
<li><p><strong>Structural Plasticity</strong>: Algorithms that modify network topology, not just weights</p></li>
<li><p><strong>Neuromodulatory Influences</strong>: Incorporating attention, reward, and other modulatory effects</p></li>
</ul>
</section>
<section id="system-integration">
<h3>18.5.3 System Integration<a class="headerlink" href="#system-integration" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Sensorimotor Loops</strong>: Closing the loop between sensing and acting in neuromorphic systems</p></li>
<li><p><strong>Hybrid Learning</strong>: Combining traditional deep learning with neuromorphic approaches</p></li>
<li><p><strong>Multi-chip Systems</strong>: Scaling to brain-like numbers of neurons and synapses</p></li>
<li><p><strong>Standardized Interfaces</strong>: Developing common interfaces for neuromorphic hardware</p></li>
</ul>
</section>
</section>
<section id="take-aways">
<h2>18.6 Take-aways<a class="headerlink" href="#take-aways" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><strong>Neuromorphic computing mimics the brain’s architecture</strong> to achieve dramatic improvements in energy efficiency for specific types of computation.</p></li>
<li><p><strong>Spiking neural networks</strong> use discrete, event-based communication similar to biological neurons, enabling sparse computation.</p></li>
<li><p><strong>Resistive computing elements</strong> like memristors can implement synaptic weights directly in hardware, overcoming the von Neumann bottleneck.</p></li>
<li><p><strong>Event-based sensors</strong> drastically reduce data bandwidth and power requirements by only transmitting information when changes occur.</p></li>
<li><p><strong>Neuromorphic hardware platforms</strong> demonstrate 100-1000× improvements in energy efficiency for pattern recognition and sensory processing tasks.</p></li>
</ul>
</section>
<section id="further-reading">
<h2>18.7 Further Reading<a class="headerlink" href="#further-reading" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Davies, M., et al. (2018). <a class="reference external" href="https://ieeexplore.ieee.org/document/8259423">Loihi: A Neuromorphic Manycore Processor with On-Chip Learning</a>. IEEE Micro, 38(1), 82-99.</p></li>
<li><p>Schuman, C. D., et al. (2017). <a class="reference external" href="https://arxiv.org/abs/1705.06963">A Survey of Neuromorphic Computing and Neural Networks in Hardware</a>. arXiv preprint arXiv:1705.06963.</p></li>
<li><p>Diehl, P. U., et al. (2015). <a class="reference external" href="https://ieeexplore.ieee.org/document/7280696">Fast-classifying, high-accuracy spiking deep networks through weight and threshold balancing</a>. IEEE International Joint Conference on Neural Networks.</p></li>
<li><p>Tavanaei, A., et al. (2019). <a class="reference external" href="https://www.sciencedirect.com/science/article/pii/S0893608018303332">Deep learning in spiking neural networks</a>. Neural Networks, 111, 47-63.</p></li>
<li><p>Pfeiffer, M., &amp; Pfeil, T. (2018). <a class="reference external" href="https://www.frontiersin.org/articles/10.3389/fnins.2018.00774/full">Deep learning with spiking neurons: Opportunities and challenges</a>. Frontiers in Neuroscience, 12, 774.</p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "executablebooks/jupyter-book",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./part6"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="ch17_bci_human_ai_interfaces.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Chapter 17: Brain-Computer Interfaces and Human-AI Interaction</p>
      </div>
    </a>
    <a class="right-next"
       href="ch19_cognitive_neuro_dl.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Chapter 19: Cognitive Neuroscience and Deep Learning</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#chapter-goals">18.0 Chapter Goals</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#neuromorphic-computing-principles">18.1 Neuromorphic Computing Principles</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#spiking-neural-networks">18.1.1 Spiking Neural Networks</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#resistive-computing-and-memristors">18.1.2 Resistive Computing and Memristors</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#event-based-sensors">18.1.3 Event-Based Sensors</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#brain-inspired-chips">18.1.4 Brain-Inspired Chips</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#applications-of-neuromorphic-computing">18.2 Applications of Neuromorphic Computing</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#edge-computing-and-iot">18.2.1 Edge Computing and IoT</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#robotics-and-autonomous-systems">18.2.2 Robotics and Autonomous Systems</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#brain-computer-interfaces">18.2.3 Brain-Computer Interfaces</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simulation-and-implementation">18.3 Simulation and Implementation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#software-frameworks-for-neuromorphic-computing">18.3.1 Software Frameworks for Neuromorphic Computing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#converting-anns-to-snns">18.3.2 Converting ANNs to SNNs</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#code-lab-spiking-neural-network">18.4 Code Lab: Spiking Neural Network</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#future-directions">18.5 Future Directions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hardware-advances">18.5.1 Hardware Advances</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#algorithms-and-learning">18.5.2 Algorithms and Learning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#system-integration">18.5.3 System Integration</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#take-aways">18.6 Take-aways</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#further-reading">18.7 Further Reading</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Richard Young
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2025.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>