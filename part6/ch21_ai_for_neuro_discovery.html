
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Chapter 21: AI for Neuroscience Discovery &#8212; The Neuroscience of AI</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'part6/ch21_ai_for_neuro_discovery';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="canonical" href="https://neuroai-handbook.github.io/part6/ch21_ai_for_neuro_discovery.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Chapter 22: Embodied AI and Robotics" href="ch22_embodied_ai_robotics.html" />
    <link rel="prev" title="Creating Presentations with RISE" href="rise_slides_demo.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/nai.png" class="logo__image only-light" alt="The Neuroscience of AI - Home"/>
    <script>document.write(`<img src="../_static/nai.png" class="logo__image only-dark" alt="The Neuroscience of AI - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    The Neuroscience of AI
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Cover</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../cover.html">Cover</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part I · Brains &amp; Inspiration</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../part1/ch01_intro.html">Chapter 1: Introduction to Neuroscience ↔ AI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part1/ch02_neuro_foundations.html">Chapter 2: Neuroscience Foundations for AI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part1/ch03_spatial_navigation.html">Chapter 3: Spatial Navigation – Place &amp; Grid Cells</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part1/ch04_perception_pipeline.html">Chapter 4: Perception Pipeline – Visual Cortex → CNNs</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part II · Brains Meet Math &amp; Data</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../part2/ch05_brain_networks.html">Chapter 5: Default-Mode vs Executive Control Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part2/ch06_neurostimulation.html">Chapter 6: Neurostimulation &amp; Plasticity</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part2/ch07_information_theory.html">Chapter 7: Information Theory Essentials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part2/ch08_data_science_pipeline.html">Chapter 8: Data-Science Pipeline in Python</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part III · Learning Machines</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../part3/ch09_ml_foundations.html">Chapter 9: Classical Machine-Learning Foundations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part3/ch10_deep_learning.html">Chapter 10: Deep Learning: Training &amp; Optimisation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part3/ch11_sequence_models.html">Chapter 11: Sequence Models: RNN → Attention → Transformer</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part IV · Frontier Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../part4/ch12_large_language_models.html">Chapter 12: Large Language Models &amp; Fine-Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part4/ch13_multimodal_models.html">Chapter 13: Multimodal &amp; Diffusion Models</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part V · Ethics &amp; Futures</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../part5/ch15_ethical_ai.html">Chapter 15: Ethical AI - Considerations for NeuroAI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../part5/ch16_future_directions.html">Chapter 16: Where Next for Neuro-AI?</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part VI · Advanced Applications</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="ch17_bci_human_ai_interfaces.html">Brain-Computer Interfaces and Human-AI Interaction</a></li>
<li class="toctree-l1"><a class="reference internal" href="ch18_neuromorphic_computing.html">Chapter 18: Neuromorphic Computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="ch19_cognitive_neuro_dl.html">Cognitive Neuroscience and Deep Learning</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="ch20_case_studies.html">Case Studies in NeuroAI</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="ch20_interactive.html">Interactive NeuroAI Case Studies</a></li>
<li class="toctree-l2"><a class="reference internal" href="jupyter_ai_demo.html">AI-Assisted Learning with Jupyter AI</a></li>
<li class="toctree-l2"><a class="reference internal" href="rise_slides_demo.html">Creating Presentations with RISE</a></li>


</ul>
</details></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Chapter 21: AI for Neuroscience Discovery</a></li>
<li class="toctree-l1"><a class="reference internal" href="ch22_embodied_ai_robotics.html">Chapter 22: Embodied AI and Robotics</a></li>
<li class="toctree-l1"><a class="reference internal" href="ch24_quantum_computing_neuroai.html">Chapter 24: Quantum Computing and NeuroAI</a></li>
<li class="toctree-l1"><a class="reference internal" href="ch23_lifelong_learning.html">Chapter 23: Lifelong Learning</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Appendices</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../appendices/glossary.html">Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../appendices/math_python_refresher.html">Appendix A: Math &amp; Python Mini-Refresher</a></li>
<li class="toctree-l1"><a class="reference internal" href="../appendices/dataset_catalogue.html">Appendix B: Dataset Catalogue</a></li>
<li class="toctree-l1"><a class="reference internal" href="../appendices/colab_setup.html">Appendix C: Google Colab Setup for NeuroAI</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/edit/master/docs/part6/ch21_ai_for_neuro_discovery.md" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fpart6/ch21_ai_for_neuro_discovery.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/part6/ch21_ai_for_neuro_discovery.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Chapter 21: AI for Neuroscience Discovery</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#chapter-goals">21.0 Chapter Goals</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#neural-data-analysis-with-deep-learning">21.1 Neural Data Analysis with Deep Learning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#decoding-neural-activity">21.1.1 Decoding Neural Activity</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dimensionality-reduction-for-neural-data">21.1.2 Dimensionality Reduction for Neural Data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#time-series-analysis-for-neural-dynamics">21.1.3 Time Series Analysis for Neural Dynamics</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#brain-simulation-efforts">21.2 Brain Simulation Efforts</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#large-scale-neural-circuit-simulations">21.2.1 Large-Scale Neural Circuit Simulations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#brain-region-models">21.2.2 Brain Region Models</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#connectome-reconstruction">21.3 Connectome Reconstruction</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#electron-microscopy-analysis">21.3.1 Electron Microscopy Analysis</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#macro-scale-connectomics">21.3.2 Macro-Scale Connectomics</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#theory-development-through-modeling">21.4 Theory Development through Modeling</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#computational-models-of-cognition">21.4.1 Computational Models of Cognition</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#neural-circuit-mechanisms">21.4.2 Neural Circuit Mechanisms</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#neuromorphic-applications">21.5 Neuromorphic Applications</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#brain-inspired-learning-rules">21.5.1 Brain-Inspired Learning Rules</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#code-lab-neural-data-analysis">21.6 Code Lab: Neural Data Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#take-aways">21.7 Take-aways</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#further-reading">21.8 Further Reading</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="chapter-21-ai-for-neuroscience-discovery">
<h1>Chapter 21: AI for Neuroscience Discovery<a class="headerlink" href="#chapter-21-ai-for-neuroscience-discovery" title="Link to this heading">#</a></h1>
<p>This chapter examines how artificial intelligence is accelerating neuroscience research and enabling new discoveries about brain function and organization. While neuroscience has heavily inspired AI, AI is now increasingly being used to advance neuroscience in a virtuous cycle of innovation.</p>
<section id="chapter-goals">
<h2>21.0 Chapter Goals<a class="headerlink" href="#chapter-goals" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Understand how AI approaches are transforming neural data analysis</p></li>
<li><p>Explore computational brain simulations enabled by machine learning</p></li>
<li><p>Learn how AI assists in connectome reconstruction and cellular morphology analysis</p></li>
<li><p>Discover how machine learning helps develop theories of brain function</p></li>
<li><p>Implement neural data analysis tools using deep learning techniques</p></li>
</ul>
</section>
<section id="neural-data-analysis-with-deep-learning">
<h2>21.1 Neural Data Analysis with Deep Learning<a class="headerlink" href="#neural-data-analysis-with-deep-learning" title="Link to this heading">#</a></h2>
<p>The exponential growth in neural recording technologies has created a data analysis challenge that AI is uniquely positioned to address. Deep learning approaches can extract patterns and insights from complex, high-dimensional neural data that would be difficult or impossible to identify with traditional methods.</p>
<section id="decoding-neural-activity">
<h3>21.1.1 Decoding Neural Activity<a class="headerlink" href="#decoding-neural-activity" title="Link to this heading">#</a></h3>
<p>Deep learning models can decode neural activity to predict behavior, perception, or cognitive states:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">analyze_neural_recordings</span><span class="p">(</span><span class="n">spike_data</span><span class="p">,</span> <span class="n">behavior_data</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Use deep learning to analyze neural recording data</span>
<span class="sd">    </span>
<span class="sd">    Parameters:</span>
<span class="sd">    - spike_data: Neural spike recordings [neurons, time]</span>
<span class="sd">    - behavior_data: Behavioral measurements [time, features]</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">    - model: Trained neural decoder</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">optim</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
    
    <span class="c1"># Prepare data</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">spike_data</span><span class="o">.</span><span class="n">T</span>  <span class="c1"># [time, neurons]</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">behavior_data</span>  <span class="c1"># [time, features]</span>
    
    <span class="c1"># Split into train/test</span>
    <span class="n">split_idx</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">0.8</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:</span><span class="n">split_idx</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">split_idx</span><span class="p">:]</span>
    <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="n">split_idx</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">split_idx</span><span class="p">:]</span>
    
    <span class="c1"># Create and train a neural decoder</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">128</span><span class="p">),</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">),</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="p">)</span>
    
    <span class="c1"># Train the model</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
    
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    
    <span class="c1"># Evaluate</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">r2_scores</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">y_test</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span> <span class="n">y_pred</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span> 
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Average R² score: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">r2_scores</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
<p>These decoding models can reveal how neural populations represent information and how these representations evolve over time. Applications include:</p>
<ul class="simple">
<li><p><strong>Movement Decoding</strong>: Predicting limb trajectories from motor cortex activity</p></li>
<li><p><strong>Sensory Reconstruction</strong>: Reconstructing visual or auditory stimuli from brain activity</p></li>
<li><p><strong>Cognitive State Classification</strong>: Identifying decision-making processes, attention states, or memory formation</p></li>
</ul>
</section>
<section id="dimensionality-reduction-for-neural-data">
<h3>21.1.2 Dimensionality Reduction for Neural Data<a class="headerlink" href="#dimensionality-reduction-for-neural-data" title="Link to this heading">#</a></h3>
<p>Neural data is often high-dimensional, with recordings from hundreds or thousands of neurons. Deep learning approaches can identify lower-dimensional representations that capture the essential dynamics:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">neural_dimensionality_reduction</span><span class="p">(</span><span class="n">neural_data</span><span class="p">,</span> <span class="n">latent_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Reduce dimensionality of neural data using a variational autoencoder</span>
<span class="sd">    </span>
<span class="sd">    Parameters:</span>
<span class="sd">    - neural_data: Neural activity data [samples, neurons]</span>
<span class="sd">    - latent_dim: Dimension of latent space</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">    - encoder: Model that maps from neural activity to latent space</span>
<span class="sd">    - decoder: Model that maps from latent space to neural activity</span>
<span class="sd">    - latent_representations: Neural data in latent space</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">optim</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span>
    
    <span class="c1"># Normalize data</span>
    <span class="n">data_mean</span> <span class="o">=</span> <span class="n">neural_data</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">data_std</span> <span class="o">=</span> <span class="n">neural_data</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-6</span>
    <span class="n">normalized_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">neural_data</span> <span class="o">-</span> <span class="n">data_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">data_std</span>
    
    <span class="c1"># Convert to torch tensor</span>
    <span class="n">data_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">normalized_data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    
    <span class="c1"># Define VAE architecture</span>
    <span class="k">class</span><span class="w"> </span><span class="nc">VAE</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
        <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">):</span>
            <span class="nb">super</span><span class="p">(</span><span class="n">VAE</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
            
            <span class="c1"># Encoder</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fc_mu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fc_logvar</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span>
            
            <span class="c1"># Decoder</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fc4</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fc5</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">)</span>
        
        <span class="k">def</span><span class="w"> </span><span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
            <span class="n">h</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
            <span class="n">h</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">h</span><span class="p">))</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc_mu</span><span class="p">(</span><span class="n">h</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc_logvar</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        
        <span class="k">def</span><span class="w"> </span><span class="nf">reparameterize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">):</span>
            <span class="n">std</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">logvar</span><span class="p">)</span>
            <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">std</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">mu</span> <span class="o">+</span> <span class="n">eps</span> <span class="o">*</span> <span class="n">std</span>
        
        <span class="k">def</span><span class="w"> </span><span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
            <span class="n">h</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">z</span><span class="p">))</span>
            <span class="n">h</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc4</span><span class="p">(</span><span class="n">h</span><span class="p">))</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc5</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        
        <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
            <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reparameterize</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">z</span><span class="p">),</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span>
    
    <span class="c1"># Initialize model</span>
    <span class="n">input_dim</span> <span class="o">=</span> <span class="n">neural_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">vae</span> <span class="o">=</span> <span class="n">VAE</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span>
    
    <span class="c1"># Train VAE</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">vae</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
    
    <span class="c1"># VAE loss function</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">loss_function</span><span class="p">(</span><span class="n">recon_x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">):</span>
        <span class="n">BCE</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">recon_x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">)</span>
        <span class="n">KLD</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">logvar</span> <span class="o">-</span> <span class="n">mu</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="n">logvar</span><span class="o">.</span><span class="n">exp</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">BCE</span> <span class="o">+</span> <span class="n">KLD</span>
    
    <span class="c1"># Training loop</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">recon_batch</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span> <span class="o">=</span> <span class="n">vae</span><span class="p">(</span><span class="n">data_tensor</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">recon_batch</span><span class="p">,</span> <span class="n">data_tensor</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        
        <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s1">, Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nb">len</span><span class="p">(</span><span class="n">data_tensor</span><span class="p">)</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    
    <span class="c1"># Extract latent representations</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">mu</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">vae</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">data_tensor</span><span class="p">)</span>
        <span class="n">latent_representations</span> <span class="o">=</span> <span class="n">mu</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    
    <span class="c1"># Create encoder and decoder functions</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">encoder</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
        <span class="n">data_norm</span> <span class="o">=</span> <span class="p">(</span><span class="n">data</span> <span class="o">-</span> <span class="n">data_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">data_std</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">mu</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">vae</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">data_norm</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">mu</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">decoder</span><span class="p">(</span><span class="n">latent</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">recon</span> <span class="o">=</span> <span class="n">vae</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">latent</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
        <span class="n">recon_unnorm</span> <span class="o">=</span> <span class="n">recon</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="o">*</span> <span class="n">data_std</span> <span class="o">+</span> <span class="n">data_mean</span>
        <span class="k">return</span> <span class="n">recon_unnorm</span>
    
    <span class="k">return</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">latent_representations</span>
</pre></div>
</div>
<p>Dimensionality reduction techniques like variational autoencoders (VAEs) can:</p>
<ul class="simple">
<li><p>Identify low-dimensional neural manifolds that represent behavioral states</p></li>
<li><p>Reveal population-level dynamics not visible at the single-neuron level</p></li>
<li><p>Enable visualization of high-dimensional neural trajectories</p></li>
<li><p>Discover shared structure across different brain regions or subjects</p></li>
</ul>
</section>
<section id="time-series-analysis-for-neural-dynamics">
<h3>21.1.3 Time Series Analysis for Neural Dynamics<a class="headerlink" href="#time-series-analysis-for-neural-dynamics" title="Link to this heading">#</a></h3>
<p>Deep learning models are particularly effective for analyzing the temporal dynamics of neural activity:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">analyze_neural_dynamics</span><span class="p">(</span><span class="n">neural_time_series</span><span class="p">,</span> <span class="n">sequence_length</span><span class="o">=</span><span class="mi">50</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Analyze neural dynamics using a recurrent neural network</span>
<span class="sd">    </span>
<span class="sd">    Parameters:</span>
<span class="sd">    - neural_time_series: Neural activity over time [time, neurons]</span>
<span class="sd">    - sequence_length: Length of sequences for prediction</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">    - model: Trained RNN model for neural dynamics prediction</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">optim</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
    
    <span class="c1"># Prepare sequence data</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">create_sequences</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">seq_length</span><span class="p">):</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">-</span> <span class="n">seq_length</span><span class="p">):</span>
            <span class="n">X</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">seq_length</span><span class="p">])</span>
            <span class="n">y</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="n">seq_length</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">create_sequences</span><span class="p">(</span><span class="n">neural_time_series</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">)</span>
    
    <span class="c1"># Split into train/test</span>
    <span class="n">split_idx</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">0.8</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:</span><span class="n">split_idx</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">split_idx</span><span class="p">:]</span>
    <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="n">split_idx</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">split_idx</span><span class="p">:]</span>
    
    <span class="c1"># Define RNN model</span>
    <span class="k">class</span><span class="w"> </span><span class="nc">NeuralRNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
        <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">):</span>
            <span class="nb">super</span><span class="p">(</span><span class="n">NeuralRNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>
        
        <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
            <span class="n">lstm_out</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">lstm_out</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:])</span>
    
    <span class="c1"># Model parameters</span>
    <span class="n">input_size</span> <span class="o">=</span> <span class="n">neural_time_series</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># Number of neurons</span>
    <span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">64</span>
    <span class="n">output_size</span> <span class="o">=</span> <span class="n">input_size</span>
    
    <span class="c1"># Initialize model</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">NeuralRNN</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>
    
    <span class="c1"># Train model</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
    
    <span class="c1"># Convert to torch tensors</span>
    <span class="n">X_train_t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">y_train_t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">X_test_t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">y_test_t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    
    <span class="c1"># Training loop</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
        <span class="c1"># Forward pass</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_train_t</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_train_t</span><span class="p">)</span>
        
        <span class="c1"># Backward pass and optimize</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        
        <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Evaluate on test set</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">test_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_test_t</span><span class="p">)</span>
                <span class="n">test_loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">test_pred</span><span class="p">,</span> <span class="n">y_test_t</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s1">, Train Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">, Test Loss: </span><span class="si">{</span><span class="n">test_loss</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    
    <span class="c1"># Evaluate prediction performance</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_test_t</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">r2_scores</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">y_test</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span> <span class="n">y_pred</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span> 
                     <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Average R² score: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">r2_scores</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
<p>RNN-based models can:</p>
<ul class="simple">
<li><p>Predict future neural activity based on past patterns</p></li>
<li><p>Identify recurrent dynamics and attractor states</p></li>
<li><p>Characterize how external inputs perturb ongoing neural dynamics</p></li>
<li><p>Model the temporal evolution of neural representations</p></li>
</ul>
</section>
</section>
<section id="brain-simulation-efforts">
<h2>21.2 Brain Simulation Efforts<a class="headerlink" href="#brain-simulation-efforts" title="Link to this heading">#</a></h2>
<p>AI is enabling increasingly detailed and realistic simulations of brain activity, from single neurons to large-scale networks.</p>
<section id="large-scale-neural-circuit-simulations">
<h3>21.2.1 Large-Scale Neural Circuit Simulations<a class="headerlink" href="#large-scale-neural-circuit-simulations" title="Link to this heading">#</a></h3>
<p>AI-assisted models can simulate the activity of large populations of neurons:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">BrainRegionSimulation</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_neurons</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">connectivity_density</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Simplified brain region simulation</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        - n_neurons: Number of neurons to simulate</span>
<span class="sd">        - connectivity_density: Fraction of possible connections to create</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">n_neurons</span> <span class="o">=</span> <span class="n">n_neurons</span>
        
        <span class="c1"># Initialize neurons (simplified LIF model)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v_rest</span> <span class="o">=</span> <span class="o">-</span><span class="mf">70.0</span>  <span class="c1"># resting potential (mV)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v_threshold</span> <span class="o">=</span> <span class="o">-</span><span class="mf">55.0</span>  <span class="c1"># spike threshold (mV)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v_reset</span> <span class="o">=</span> <span class="o">-</span><span class="mf">75.0</span>  <span class="c1"># reset potential (mV)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tau</span> <span class="o">=</span> <span class="mf">20.0</span>  <span class="c1"># membrane time constant (ms)</span>
        
        <span class="c1"># State variables</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_rest</span>  <span class="c1"># membrane potentials</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">refractory_time</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">)</span>  <span class="c1"># time until end of refractory period</span>
        
        <span class="c1"># Generate random connectivity matrix</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">connectivity_density</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span>
            <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">,</span> <span class="n">n_neurons</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="o">-</span><span class="n">p</span><span class="p">,</span> <span class="n">p</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="c1"># Scale weights and ensure no self-connections</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="p">(</span><span class="n">n_neurons</span><span class="p">,</span> <span class="n">n_neurons</span><span class="p">))</span>
        <span class="n">np</span><span class="o">.</span><span class="n">fill_diagonal</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        
        <span class="c1"># 80% excitatory, 20% inhibitory</span>
        <span class="n">inh_neurons</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.2</span> <span class="o">*</span> <span class="n">n_neurons</span><span class="p">),</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="n">inh_neurons</span><span class="p">]</span> <span class="o">*=</span> <span class="o">-</span><span class="mi">5</span>
        
        <span class="c1"># Record spikes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">spike_times</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">current_time</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">external_input</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dt</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Simulate one time step</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        - external_input: External current to each neuron</span>
<span class="sd">        - dt: Time step (ms)</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">        - spikes: Boolean array indicating which neurons spiked</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">current_time</span> <span class="o">+=</span> <span class="n">dt</span>
        
        <span class="c1"># Default to no external input</span>
        <span class="k">if</span> <span class="n">external_input</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">external_input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_neurons</span><span class="p">)</span>
        
        <span class="c1"># Update membrane potentials</span>
        <span class="n">non_refractory</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">refractory_time</span> <span class="o">&lt;=</span> <span class="mi">0</span>
        
        <span class="c1"># Decay potential toward rest</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v</span><span class="p">[</span><span class="n">non_refractory</span><span class="p">]</span> <span class="o">+=</span> <span class="n">dt</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">v</span><span class="p">[</span><span class="n">non_refractory</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_rest</span><span class="p">)</span> <span class="o">+</span> 
                                        <span class="n">external_input</span><span class="p">[</span><span class="n">non_refractory</span><span class="p">])</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">tau</span>
        
        <span class="c1"># Check for spikes</span>
        <span class="n">spiked</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">v</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_threshold</span><span class="p">)</span>
        
        <span class="c1"># Record spikes</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">spiked</span><span class="p">)[</span><span class="mi">0</span><span class="p">]:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">spike_times</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_time</span><span class="p">)</span>
        
        <span class="c1"># Reset membrane potential and set refractory period for spiked neurons</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v</span><span class="p">[</span><span class="n">spiked</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_reset</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">refractory_time</span><span class="p">[</span><span class="n">spiked</span><span class="p">]</span> <span class="o">=</span> <span class="mf">2.0</span>  <span class="c1"># 2ms refractory period</span>
        
        <span class="c1"># Decrement refractory time</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">refractory_time</span> <span class="o">-=</span> <span class="n">dt</span>
        
        <span class="c1"># Add synaptic inputs from spiking neurons</span>
        <span class="n">synaptic_input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">spiked</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v</span><span class="p">[</span><span class="n">non_refractory</span><span class="p">]</span> <span class="o">+=</span> <span class="n">synaptic_input</span><span class="p">[</span><span class="n">non_refractory</span><span class="p">]</span>
        
        <span class="k">return</span> <span class="n">spiked</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">duration</span><span class="p">,</span> <span class="n">input_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Run simulation for specified duration</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        - duration: Simulation duration (ms)</span>
<span class="sd">        - input_fn: Function that returns external input at each time step</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">        - spike_times: List of spike times for each neuron</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">steps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">duration</span> <span class="o">/</span> <span class="mf">0.1</span><span class="p">)</span>  <span class="c1"># Assuming dt=0.1</span>
        
        <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">steps</span><span class="p">):</span>
            <span class="n">t</span> <span class="o">=</span> <span class="n">step</span> <span class="o">*</span> <span class="mf">0.1</span>
            
            <span class="c1"># Get external input if provided</span>
            <span class="n">external_input</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="n">input_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">external_input</span> <span class="o">=</span> <span class="n">input_fn</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
            
            <span class="bp">self</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">external_input</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">spike_times</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">plot_raster</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">neuron_subset</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">time_range</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Plot spike raster for simulated neurons</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        - neuron_subset: List of neuron indices to plot (default: first 100)</span>
<span class="sd">        - time_range: Time range to plot as [start, end] (default: all)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
        
        <span class="c1"># Default to plotting first 100 neurons</span>
        <span class="k">if</span> <span class="n">neuron_subset</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">neuron_subset</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_neurons</span><span class="p">))</span>
        
        <span class="c1"># Create figure</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
        
        <span class="c1"># Plot spikes for each neuron</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">neuron_idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">neuron_subset</span><span class="p">):</span>
            <span class="n">spikes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">spike_times</span><span class="p">[</span><span class="n">neuron_idx</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">time_range</span><span class="p">:</span>
                <span class="n">spikes</span> <span class="o">=</span> <span class="p">[</span><span class="n">t</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">spikes</span> <span class="k">if</span> <span class="n">time_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">t</span> <span class="o">&lt;=</span> <span class="n">time_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">spikes</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">spikes</span><span class="p">)</span> <span class="o">*</span> <span class="n">i</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;|&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
        
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Time (ms)&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Neuron index&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Spike Raster Plot&#39;</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">time_range</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">time_range</span><span class="p">)</span>
            
        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>Large-scale simulations enable:</p>
<ul class="simple">
<li><p>Testing hypotheses about neural circuit function</p></li>
<li><p>Exploring emergent dynamics in complex networks</p></li>
<li><p>Investigating how network structure shapes activity patterns</p></li>
<li><p>Simulating the effects of interventions like stimulation or pharmacology</p></li>
</ul>
</section>
<section id="brain-region-models">
<h3>21.2.2 Brain Region Models<a class="headerlink" href="#brain-region-models" title="Link to this heading">#</a></h3>
<p>AI is helping develop increasingly detailed models of specific brain regions:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">create_cortical_column_model</span><span class="p">(</span><span class="n">n_layers</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">neurons_per_layer</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a simplified model of a cortical column</span>
<span class="sd">    </span>
<span class="sd">    Parameters:</span>
<span class="sd">    - n_layers: Number of cortical layers</span>
<span class="sd">    - neurons_per_layer: Neurons per layer</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">    - model: Cortical column simulation model</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
    
    <span class="n">n_neurons</span> <span class="o">=</span> <span class="n">n_layers</span> <span class="o">*</span> <span class="n">neurons_per_layer</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">BrainRegionSimulation</span><span class="p">(</span><span class="n">n_neurons</span><span class="o">=</span><span class="n">n_neurons</span><span class="p">,</span> <span class="n">connectivity_density</span><span class="o">=</span><span class="mf">0.15</span><span class="p">)</span>
    
    <span class="c1"># Modify connectivity to reflect cortical architecture</span>
    <span class="c1"># Reset weights</span>
    <span class="n">model</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_neurons</span><span class="p">,</span> <span class="n">n_neurons</span><span class="p">))</span>
    
    <span class="c1"># Layer-specific connection probabilities</span>
    <span class="n">connection_probs</span> <span class="o">=</span> <span class="p">{</span>
        <span class="c1"># (pre_layer, post_layer): probability</span>
        <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span> <span class="mf">0.15</span><span class="p">,</span>  <span class="c1"># Layer 1 → Layer 1</span>
        <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span> <span class="mf">0.2</span><span class="p">,</span>   <span class="c1"># Layer 1 → Layer 2/3</span>
        <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span> <span class="mf">0.2</span><span class="p">,</span>   <span class="c1"># Layer 2/3 → Layer 2/3</span>
        <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">):</span> <span class="mf">0.15</span><span class="p">,</span>  <span class="c1"># Layer 2/3 → Layer 4</span>
        <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">):</span> <span class="mf">0.1</span><span class="p">,</span>   <span class="c1"># Layer 2/3 → Layer 5</span>
        <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span> <span class="mf">0.05</span><span class="p">,</span>  <span class="c1"># Layer 4 → Layer 2/3</span>
        <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">):</span> <span class="mf">0.15</span><span class="p">,</span>  <span class="c1"># Layer 4 → Layer 4</span>
        <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">):</span> <span class="mf">0.2</span><span class="p">,</span>   <span class="c1"># Layer 4 → Layer 5</span>
        <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">):</span> <span class="mf">0.15</span><span class="p">,</span>  <span class="c1"># Layer 5 → Layer 5</span>
        <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">):</span> <span class="mf">0.2</span><span class="p">,</span>   <span class="c1"># Layer 5 → Layer 6</span>
        <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span> <span class="mf">0.05</span><span class="p">,</span>  <span class="c1"># Layer 5 → Layer 2/3 (feedback)</span>
        <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">):</span> <span class="mf">0.05</span><span class="p">,</span>  <span class="c1"># Layer 6 → Layer 4</span>
        <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">):</span> <span class="mf">0.1</span><span class="p">,</span>   <span class="c1"># Layer 6 → Layer 6</span>
    <span class="p">}</span>
    
    <span class="c1"># Create connections based on probabilities</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">pre_layer</span><span class="p">,</span> <span class="n">post_layer</span><span class="p">),</span> <span class="n">prob</span> <span class="ow">in</span> <span class="n">connection_probs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">pre_start</span> <span class="o">=</span> <span class="n">pre_layer</span> <span class="o">*</span> <span class="n">neurons_per_layer</span>
        <span class="n">pre_end</span> <span class="o">=</span> <span class="p">(</span><span class="n">pre_layer</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">neurons_per_layer</span>
        <span class="n">post_start</span> <span class="o">=</span> <span class="n">post_layer</span> <span class="o">*</span> <span class="n">neurons_per_layer</span>
        <span class="n">post_end</span> <span class="o">=</span> <span class="p">(</span><span class="n">post_layer</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">neurons_per_layer</span>
        
        <span class="c1"># Random connectivity based on probability</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">post_start</span><span class="p">,</span> <span class="n">post_end</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">pre_start</span><span class="p">,</span> <span class="n">pre_end</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">prob</span><span class="p">:</span>
                    <span class="c1"># Excitatory or inhibitory based on pre-synaptic neuron</span>
                    <span class="n">is_inhibitory</span> <span class="o">=</span> <span class="p">(</span><span class="n">j</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>  <span class="c1"># ~20% inhibitory neurons</span>
                    <span class="n">weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span> <span class="k">if</span> <span class="n">is_inhibitory</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">)</span>
                    <span class="n">model</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">weight</span>
    
    <span class="c1"># Create thalamic input function</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">thalamic_input</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">target_layer</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Simulate periodic thalamic input to layer 4&quot;&quot;&quot;</span>
        <span class="n">input_vec</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">)</span>
        
        <span class="c1"># Target mainly layer 4 (index 2)</span>
        <span class="n">target_start</span> <span class="o">=</span> <span class="n">target_layer</span> <span class="o">*</span> <span class="n">neurons_per_layer</span>
        <span class="n">target_end</span> <span class="o">=</span> <span class="p">(</span><span class="n">target_layer</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">neurons_per_layer</span>
        
        <span class="c1"># Periodic input (every 100ms)</span>
        <span class="k">if</span> <span class="n">t</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">&lt;</span> <span class="mi">5</span><span class="p">:</span>
            <span class="c1"># Random subset of neurons in target layer</span>
            <span class="n">target_neurons</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span>
                <span class="nb">range</span><span class="p">(</span><span class="n">target_start</span><span class="p">,</span> <span class="n">target_end</span><span class="p">),</span> 
                <span class="n">size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">neurons_per_layer</span> <span class="o">*</span> <span class="mf">0.2</span><span class="p">),</span>
                <span class="n">replace</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>
            <span class="n">input_vec</span><span class="p">[</span><span class="n">target_neurons</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">target_neurons</span><span class="p">))</span>
        
        <span class="k">return</span> <span class="n">input_vec</span>
    
    <span class="c1"># Store the input function with the model</span>
    <span class="n">model</span><span class="o">.</span><span class="n">thalamic_input</span> <span class="o">=</span> <span class="n">thalamic_input</span>
    
    <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
<p>Brain region models enable:</p>
<ul class="simple">
<li><p><strong>Structure-Function Analysis</strong>: Relating anatomical organization to functional properties</p></li>
<li><p><strong>Inter-Region Integration</strong>: Understanding how different brain areas interact</p></li>
<li><p><strong>Hierarchical Processing</strong>: Modeling information flow through layered structures</p></li>
<li><p><strong>Computational Comparisons</strong>: Relating brain regions to artificial neural network architectures</p></li>
</ul>
</section>
</section>
<section id="connectome-reconstruction">
<h2>21.3 Connectome Reconstruction<a class="headerlink" href="#connectome-reconstruction" title="Link to this heading">#</a></h2>
<p>AI techniques are dramatically accelerating efforts to map the brain’s wiring diagram (connectome) at multiple scales.</p>
<section id="electron-microscopy-analysis">
<h3>21.3.1 Electron Microscopy Analysis<a class="headerlink" href="#electron-microscopy-analysis" title="Link to this heading">#</a></h3>
<p>Electron microscopy (EM) allows imaging of neural tissue at nanometer resolution, capturing synaptic connections. AI is essential for analyzing the enormous datasets this produces:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">segment_neural_images</span><span class="p">(</span><span class="n">electron_microscopy_images</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Segment neurons in electron microscopy images using deep learning</span>
<span class="sd">    </span>
<span class="sd">    Parameters:</span>
<span class="sd">    - electron_microscopy_images: 3D stack of EM images</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">    - segmentation: 3D segmentation map</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
    
    <span class="c1"># Create a 3D U-Net model for segmentation</span>
    <span class="k">class</span><span class="w"> </span><span class="nc">UNet3D</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
        <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
            <span class="nb">super</span><span class="p">(</span><span class="n">UNet3D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
            <span class="c1"># Simplified placeholder for the model architecture</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv3d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv3d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            
        <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
            <span class="c1"># Simplified forward pass</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">x</span>
    
    <span class="n">model</span> <span class="o">=</span> <span class="n">UNet3D</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>  <span class="c1"># 3 output channels: background, membrane, cell interior</span>
    
    <span class="c1"># Process image stack in 3D patches</span>
    <span class="n">patch_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
    <span class="n">segmentation</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">electron_microscopy_images</span><span class="p">)</span>
    
    <span class="c1"># Simplified inference (in practice, would need proper patch handling)</span>
    <span class="k">for</span> <span class="n">z</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">electron_microscopy_images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">patch_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">//</span><span class="mi">2</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">electron_microscopy_images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">patch_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">//</span><span class="mi">2</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">electron_microscopy_images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">patch_size</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">//</span><span class="mi">2</span><span class="p">):</span>
                <span class="c1"># Extract patch</span>
                <span class="n">z_end</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">z</span> <span class="o">+</span> <span class="n">patch_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">electron_microscopy_images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                <span class="n">y_end</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">y</span> <span class="o">+</span> <span class="n">patch_size</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">electron_microscopy_images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
                <span class="n">x_end</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">patch_size</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">electron_microscopy_images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
                
                <span class="n">patch</span> <span class="o">=</span> <span class="n">electron_microscopy_images</span><span class="p">[</span><span class="n">z</span><span class="p">:</span><span class="n">z_end</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span><span class="n">y_end</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span><span class="n">x_end</span><span class="p">]</span>
                
                <span class="c1"># Zero-pad if necessary</span>
                <span class="k">if</span> <span class="n">patch</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">patch_size</span><span class="p">:</span>
                    <span class="n">padded</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">patch_size</span><span class="p">)</span>
                    <span class="n">padded</span><span class="p">[:</span><span class="n">patch</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">:</span><span class="n">patch</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">:</span><span class="n">patch</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]]</span> <span class="o">=</span> <span class="n">patch</span>
                    <span class="n">patch</span> <span class="o">=</span> <span class="n">padded</span>
                
                <span class="c1"># Predict segmentation</span>
                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                    <span class="n">input_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">patch</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                    <span class="n">prediction</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                
                <span class="c1"># Update segmentation (handle overlap with averaging)</span>
                <span class="n">segmentation</span><span class="p">[</span><span class="n">z</span><span class="p">:</span><span class="n">z_end</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span><span class="n">y_end</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span><span class="n">x_end</span><span class="p">]</span> <span class="o">=</span> <span class="n">prediction</span><span class="p">[:</span><span class="n">z_end</span><span class="o">-</span><span class="n">z</span><span class="p">,</span> <span class="p">:</span><span class="n">y_end</span><span class="o">-</span><span class="n">y</span><span class="p">,</span> <span class="p">:</span><span class="n">x_end</span><span class="o">-</span><span class="n">x</span><span class="p">]</span>
    
    <span class="c1"># Post-process to get instance segmentation (simplified)</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">skimage.measure</span><span class="w"> </span><span class="kn">import</span> <span class="n">label</span>
    <span class="n">instance_seg</span> <span class="o">=</span> <span class="n">label</span><span class="p">(</span><span class="n">segmentation</span> <span class="o">==</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># Assuming channel 2 is cell interior</span>
    
    <span class="k">return</span> <span class="n">instance_seg</span>
</pre></div>
</div>
<p>AI-powered connectome reconstruction enables:</p>
<ul class="simple">
<li><p>Automated segmentation of neurons in EM volumes</p></li>
<li><p>Tracing of neurites through complex tissue samples</p></li>
<li><p>Identification of synaptic connections</p></li>
<li><p>Statistical analysis of connectivity patterns</p></li>
</ul>
</section>
<section id="macro-scale-connectomics">
<h3>21.3.2 Macro-Scale Connectomics<a class="headerlink" href="#macro-scale-connectomics" title="Link to this heading">#</a></h3>
<p>AI also helps analyze macro-scale connectivity using techniques like diffusion MRI:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">analyze_structural_connectivity</span><span class="p">(</span><span class="n">dti_data</span><span class="p">,</span> <span class="n">parcellation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Analyze structural connectivity from diffusion MRI data</span>
<span class="sd">    </span>
<span class="sd">    Parameters:</span>
<span class="sd">    - dti_data: Diffusion tensor imaging data</span>
<span class="sd">    - parcellation: Brain region parcellation</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">    - connectivity_matrix: Structural connectivity matrix</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">dipy.tracking.utils</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">utils</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">dipy.tracking.streamline</span><span class="w"> </span><span class="kn">import</span> <span class="n">Streamlines</span>
    
    <span class="c1"># Placeholder for actual tractography implementation</span>
    <span class="c1"># In practice, this would use proper DTI processing tools</span>
    
    <span class="c1"># Simulate streamlines</span>
    <span class="n">n_streamlines</span> <span class="o">=</span> <span class="mi">10000</span>
    <span class="n">n_regions</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">parcellation</span><span class="p">))</span> <span class="o">-</span> <span class="mi">1</span>  <span class="c1"># Excluding background</span>
    
    <span class="c1"># Create random streamlines for demonstration</span>
    <span class="n">streamlines</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_streamlines</span><span class="p">):</span>
        <span class="c1"># Random streamline with 100 points</span>
        <span class="n">streamline</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">dti_data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">streamlines</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">streamline</span><span class="p">)</span>
    
    <span class="c1"># Convert to DIPY Streamlines object</span>
    <span class="n">streamlines</span> <span class="o">=</span> <span class="n">Streamlines</span><span class="p">(</span><span class="n">streamlines</span><span class="p">)</span>
    
    <span class="c1"># Compute connectivity matrix (region x region)</span>
    <span class="n">M</span><span class="p">,</span> <span class="n">grouping</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">connectivity_matrix</span><span class="p">(</span>
        <span class="n">streamlines</span><span class="p">,</span> <span class="n">parcellation</span><span class="p">,</span> 
        <span class="n">return_mapping</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">mapping_as_streamlines</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>
    
    <span class="c1"># Normalize by region size</span>
    <span class="n">region_sizes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">parcellation</span><span class="o">.</span><span class="n">flat</span><span class="p">)[</span><span class="mi">1</span><span class="p">:]</span>  <span class="c1"># Exclude background</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_regions</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_regions</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">region_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">region_sizes</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">M</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">M</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">region_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">region_sizes</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
    
    <span class="k">return</span> <span class="n">M</span>
</pre></div>
</div>
<p>Macro-scale connectome analysis reveals:</p>
<ul class="simple">
<li><p><strong>Brain network topology</strong>: The large-scale organization of brain networks</p></li>
<li><p><strong>Structural connectivity patterns</strong>: How different brain regions connect to each other</p></li>
<li><p><strong>Individual differences</strong>: How connectivity varies across subjects or clinical populations</p></li>
<li><p><strong>Structure-function relationships</strong>: How structural connectivity constrains functional dynamics</p></li>
</ul>
</section>
</section>
<section id="theory-development-through-modeling">
<h2>21.4 Theory Development through Modeling<a class="headerlink" href="#theory-development-through-modeling" title="Link to this heading">#</a></h2>
<p>Beyond data analysis, AI helps develop computational theories of brain function by building models that explain neural data.</p>
<section id="computational-models-of-cognition">
<h3>21.4.1 Computational Models of Cognition<a class="headerlink" href="#computational-models-of-cognition" title="Link to this heading">#</a></h3>
<p>Bayesian and probabilistic models can capture how the brain performs inference under uncertainty:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">BayesianInferenceBrain</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sensory_noise</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">prior_mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">prior_var</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Model of Bayesian inference in the brain</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        - sensory_noise: Standard deviation of sensory noise</span>
<span class="sd">        - prior_mean: Prior belief about the mean of the variable</span>
<span class="sd">        - prior_var: Prior belief about the variance of the variable</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sensory_noise</span> <span class="o">=</span> <span class="n">sensory_noise</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prior_mean</span> <span class="o">=</span> <span class="n">prior_mean</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prior_var</span> <span class="o">=</span> <span class="n">prior_var</span>
        
        <span class="c1"># Current belief</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">belief_mean</span> <span class="o">=</span> <span class="n">prior_mean</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">belief_var</span> <span class="o">=</span> <span class="n">prior_var</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">update_belief</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Update beliefs using Bayes&#39; rule</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        - observation: New sensory observation</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">        - posterior_mean: Updated belief mean</span>
<span class="sd">        - posterior_var: Updated belief variance</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Compute precision (inverse variance)</span>
        <span class="n">prior_precision</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">belief_var</span>
        <span class="n">obs_precision</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sensory_noise</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
        
        <span class="c1"># Bayesian update (for Gaussian variables)</span>
        <span class="n">posterior_precision</span> <span class="o">=</span> <span class="n">prior_precision</span> <span class="o">+</span> <span class="n">obs_precision</span>
        <span class="n">posterior_var</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">posterior_precision</span>
        
        <span class="n">posterior_mean</span> <span class="o">=</span> <span class="n">posterior_var</span> <span class="o">*</span> <span class="p">(</span>
            <span class="n">prior_precision</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">belief_mean</span> <span class="o">+</span> 
            <span class="n">obs_precision</span> <span class="o">*</span> <span class="n">observation</span>
        <span class="p">)</span>
        
        <span class="c1"># Update beliefs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">belief_mean</span> <span class="o">=</span> <span class="n">posterior_mean</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">belief_var</span> <span class="o">=</span> <span class="n">posterior_var</span>
        
        <span class="k">return</span> <span class="n">posterior_mean</span><span class="p">,</span> <span class="n">posterior_var</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">predict_observation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generate predicted observations based on current belief</span>
<span class="sd">        </span>
<span class="sd">        Parameters:</span>
<span class="sd">        - n_samples: Number of samples to generate</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">        - samples: Predicted observations</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
        
        <span class="c1"># Sample from current belief</span>
        <span class="n">samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">belief_mean</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">belief_var</span><span class="p">),</span> <span class="n">n_samples</span><span class="p">)</span>
        
        <span class="c1"># Add sensory noise</span>
        <span class="n">samples</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">sensory_noise</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">samples</span>
</pre></div>
</div>
</section>
<section id="neural-circuit-mechanisms">
<h3>21.4.2 Neural Circuit Mechanisms<a class="headerlink" href="#neural-circuit-mechanisms" title="Link to this heading">#</a></h3>
<p>AI helps identify circuit mechanisms that explain observed neural activity patterns:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">infer_circuit_mechanisms</span><span class="p">(</span><span class="n">neural_activity</span><span class="p">,</span> <span class="n">behaviors</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Infer underlying circuit mechanisms from neural recordings</span>
<span class="sd">    </span>
<span class="sd">    Parameters:</span>
<span class="sd">    - neural_activity: Neural activity recordings [neurons, time]</span>
<span class="sd">    - behaviors: Behavioral measurements [time, behaviors]</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">    - circuit_model: Inferred circuit model</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">optim</span>
    
    <span class="n">n_neurons</span> <span class="o">=</span> <span class="n">neural_activity</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">n_behaviors</span> <span class="o">=</span> <span class="n">behaviors</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="c1"># Define a circuit model</span>
    <span class="k">class</span><span class="w"> </span><span class="nc">CircuitModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
        <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_neurons</span><span class="p">,</span> <span class="n">n_latent</span><span class="p">,</span> <span class="n">n_behaviors</span><span class="p">):</span>
            <span class="nb">super</span><span class="p">(</span><span class="n">CircuitModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_neurons</span> <span class="o">=</span> <span class="n">n_neurons</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_latent</span> <span class="o">=</span> <span class="n">n_latent</span>
            
            <span class="c1"># Recurrent weights</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">W_rec</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">,</span> <span class="n">n_neurons</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.1</span><span class="p">)</span>
            
            <span class="c1"># Input weights</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">W_in</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">,</span> <span class="n">n_behaviors</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.1</span><span class="p">)</span>
            
            <span class="c1"># Readout weights</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">W_out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_behaviors</span><span class="p">,</span> <span class="n">n_neurons</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.1</span><span class="p">)</span>
            
            <span class="c1"># Latent dynamics</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">W_latent</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_latent</span><span class="p">,</span> <span class="n">n_latent</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">W_latent_to_neurons</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">,</span> <span class="n">n_latent</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">W_neurons_to_latent</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_latent</span><span class="p">,</span> <span class="n">n_neurons</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.1</span><span class="p">)</span>
            
            <span class="c1"># Biases</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">b_neurons</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">b_latent</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_latent</span><span class="p">))</span>
        
        <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_t</span><span class="p">,</span> <span class="n">r_t</span><span class="p">,</span> <span class="n">z_t</span><span class="p">):</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;Single timestep update&quot;&quot;&quot;</span>
            <span class="c1"># Update latent state</span>
            <span class="n">z_next</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_latent</span><span class="p">,</span> <span class="n">z_t</span><span class="p">)</span> <span class="o">+</span> 
                <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_neurons_to_latent</span><span class="p">,</span> <span class="n">r_t</span><span class="p">)</span> <span class="o">+</span> 
                <span class="bp">self</span><span class="o">.</span><span class="n">b_latent</span>
            <span class="p">)</span>
            
            <span class="c1"># Update neural activity</span>
            <span class="n">r_next</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_rec</span><span class="p">,</span> <span class="n">r_t</span><span class="p">)</span> <span class="o">+</span> 
                <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_in</span><span class="p">,</span> <span class="n">x_t</span><span class="p">)</span> <span class="o">+</span> 
                <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_latent_to_neurons</span><span class="p">,</span> <span class="n">z_t</span><span class="p">)</span> <span class="o">+</span> 
                <span class="bp">self</span><span class="o">.</span><span class="n">b_neurons</span>
            <span class="p">)</span>
            
            <span class="c1"># Generate output</span>
            <span class="n">y_next</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_out</span><span class="p">,</span> <span class="n">r_next</span><span class="p">)</span>
            
            <span class="k">return</span> <span class="n">r_next</span><span class="p">,</span> <span class="n">z_next</span><span class="p">,</span> <span class="n">y_next</span>
        
        <span class="k">def</span><span class="w"> </span><span class="nf">run_simulation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">steps</span><span class="p">,</span> <span class="n">initial_r</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">initial_z</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;Run simulation for multiple timesteps&quot;&quot;&quot;</span>
            <span class="k">if</span> <span class="n">initial_r</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">initial_r</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_neurons</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">initial_z</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">initial_z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_latent</span><span class="p">)</span>
            
            <span class="n">r_t</span> <span class="o">=</span> <span class="n">initial_r</span>
            <span class="n">z_t</span> <span class="o">=</span> <span class="n">initial_z</span>
            
            <span class="c1"># Store activity</span>
            <span class="n">r_history</span> <span class="o">=</span> <span class="p">[</span><span class="n">r_t</span><span class="p">]</span>
            <span class="n">z_history</span> <span class="o">=</span> <span class="p">[</span><span class="n">z_t</span><span class="p">]</span>
            <span class="n">y_history</span> <span class="o">=</span> <span class="p">[]</span>
            
            <span class="c1"># Run simulation</span>
            <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">steps</span><span class="p">):</span>
                <span class="n">x_t</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="k">if</span> <span class="n">t</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                <span class="n">r_t</span><span class="p">,</span> <span class="n">z_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x_t</span><span class="p">,</span> <span class="n">r_t</span><span class="p">,</span> <span class="n">z_t</span><span class="p">)</span>
                
                <span class="n">r_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">r_t</span><span class="p">)</span>
                <span class="n">z_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">z_t</span><span class="p">)</span>
                <span class="n">y_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_t</span><span class="p">)</span>
            
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">r_history</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">z_history</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">y_history</span><span class="p">)</span>
    
    <span class="c1"># Prepare data</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">behaviors</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">neural_activity</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># [time, neurons]</span>
    
    <span class="c1"># Create model</span>
    <span class="n">n_latent</span> <span class="o">=</span> <span class="mi">10</span>  <span class="c1"># Number of latent variables</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">CircuitModel</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">,</span> <span class="n">n_latent</span><span class="p">,</span> <span class="n">n_behaviors</span><span class="p">)</span>
    
    <span class="c1"># Define loss function and optimizer</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
    
    <span class="c1"># Train model</span>
    <span class="n">n_steps</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
        <span class="c1"># Reset initial state</span>
        <span class="n">r0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">)</span>
        <span class="n">z0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_latent</span><span class="p">)</span>
        
        <span class="c1"># Forward pass</span>
        <span class="n">r_pred</span><span class="p">,</span> <span class="n">z_pred</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">run_simulation</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="n">r0</span><span class="p">,</span> <span class="n">z0</span><span class="p">)</span>
        
        <span class="c1"># Computer loss (compare predicted to actual neural activity)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">r_pred</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">Y</span><span class="p">[:</span><span class="n">n_steps</span><span class="p">])</span>
        
        <span class="c1"># Backward pass and optimize</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        
        <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">, Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
</section>
</section>
<section id="neuromorphic-applications">
<h2>21.5 Neuromorphic Applications<a class="headerlink" href="#neuromorphic-applications" title="Link to this heading">#</a></h2>
<p>AI-derived insights about the brain can be applied to develop new neuromorphic computing architectures.</p>
<section id="brain-inspired-learning-rules">
<h3>21.5.1 Brain-Inspired Learning Rules<a class="headerlink" href="#brain-inspired-learning-rules" title="Link to this heading">#</a></h3>
<p>Learning algorithms inspired by neuroscience can be more efficient than backpropagation:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">train_with_local_learning_rule</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Train a neural network using a local Hebbian-like learning rule</span>
<span class="sd">    </span>
<span class="sd">    Parameters:</span>
<span class="sd">    - network: Neural network to train</span>
<span class="sd">    - inputs: Training inputs</span>
<span class="sd">    - targets: Training targets</span>
<span class="sd">    - epochs: Number of training epochs</span>
<span class="sd">    - learning_rate: Learning rate</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">    - network: Trained network</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
    
    <span class="c1"># Simple 2-layer network</span>
    <span class="n">W1</span> <span class="o">=</span> <span class="n">network</span><span class="p">[</span><span class="s1">&#39;W1&#39;</span><span class="p">]</span>  <span class="c1"># Input → Hidden weights</span>
    <span class="n">W2</span> <span class="o">=</span> <span class="n">network</span><span class="p">[</span><span class="s1">&#39;W2&#39;</span><span class="p">]</span>  <span class="c1"># Hidden → Output weights</span>
    
    <span class="c1"># Activation function</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>
    
    <span class="c1"># Derivative of sigmoid</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">dsigmoid</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">y</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="n">total_error</span> <span class="o">=</span> <span class="mi">0</span>
        
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)):</span>
            <span class="c1"># Forward pass</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">target</span> <span class="o">=</span> <span class="n">targets</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            
            <span class="c1"># Hidden layer</span>
            <span class="n">hidden_in</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W1</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
            <span class="n">hidden_out</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">hidden_in</span><span class="p">)</span>
            
            <span class="c1"># Output layer</span>
            <span class="n">output_in</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W2</span><span class="p">,</span> <span class="n">hidden_out</span><span class="p">)</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">output_in</span><span class="p">)</span>
            
            <span class="c1"># Calculate error</span>
            <span class="n">error</span> <span class="o">=</span> <span class="n">target</span> <span class="o">-</span> <span class="n">output</span>
            <span class="n">total_error</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">error</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
            
            <span class="c1"># Local learning rule (simplified)</span>
            <span class="c1"># Output layer: Error-modulated Hebbian</span>
            <span class="n">dW2</span> <span class="o">=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">error</span> <span class="o">*</span> <span class="n">dsigmoid</span><span class="p">(</span><span class="n">output</span><span class="p">),</span> <span class="n">hidden_out</span><span class="p">)</span>
            
            <span class="c1"># Hidden layer: Simplified error projection</span>
            <span class="n">hidden_error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W2</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">error</span> <span class="o">*</span> <span class="n">dsigmoid</span><span class="p">(</span><span class="n">output</span><span class="p">))</span>
            <span class="n">dW1</span> <span class="o">=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">hidden_error</span> <span class="o">*</span> <span class="n">dsigmoid</span><span class="p">(</span><span class="n">hidden_out</span><span class="p">),</span> <span class="n">x</span><span class="p">)</span>
            
            <span class="c1"># Update weights</span>
            <span class="n">W1</span> <span class="o">+=</span> <span class="n">dW1</span>
            <span class="n">W2</span> <span class="o">+=</span> <span class="n">dW2</span>
        
        <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">, Error: </span><span class="si">{</span><span class="n">total_error</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="n">network</span><span class="p">[</span><span class="s1">&#39;W1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">W1</span>
    <span class="n">network</span><span class="p">[</span><span class="s1">&#39;W2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">W2</span>
    
    <span class="k">return</span> <span class="n">network</span>
</pre></div>
</div>
<p>Local learning rules have several advantages:</p>
<ul class="simple">
<li><p><strong>Biological plausibility</strong>: They better match how the brain learns</p></li>
<li><p><strong>Energy efficiency</strong>: They require less information to be transmitted</p></li>
<li><p><strong>Hardware compatibility</strong>: They’re easier to implement in neuromorphic systems</p></li>
<li><p><strong>Continual learning</strong>: They can adapt to new data without catastrophic forgetting</p></li>
</ul>
</section>
</section>
<section id="code-lab-neural-data-analysis">
<h2>21.6 Code Lab: Neural Data Analysis<a class="headerlink" href="#code-lab-neural-data-analysis" title="Link to this heading">#</a></h2>
<p>Let’s implement a complete pipeline for neural data analysis:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">neural_data_analysis_pipeline</span><span class="p">(</span><span class="n">neural_data_file</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    End-to-end pipeline for neural data analysis</span>
<span class="sd">    </span>
<span class="sd">    Parameters:</span>
<span class="sd">    - neural_data_file: Path to neural recording data file</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">    - results: Analysis results and visualizations</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.decomposition</span><span class="w"> </span><span class="kn">import</span> <span class="n">PCA</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.manifold</span><span class="w"> </span><span class="kn">import</span> <span class="n">TSNE</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">optim</span>
    
    <span class="c1"># Load data (simulated for this example)</span>
    <span class="c1"># In practice, would load from file</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">n_neurons</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="n">n_timepoints</span> <span class="o">=</span> <span class="mi">1000</span>
    <span class="n">n_trials</span> <span class="o">=</span> <span class="mi">50</span>
    <span class="n">n_conditions</span> <span class="o">=</span> <span class="mi">5</span>
    
    <span class="c1"># Create simulated data</span>
    <span class="c1"># Shape: [trials, neurons, time]</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_trials</span><span class="p">,</span> <span class="n">n_neurons</span><span class="p">,</span> <span class="n">n_timepoints</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.1</span>
    
    <span class="c1"># Add condition-specific patterns</span>
    <span class="n">conditions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_conditions</span><span class="p">,</span> <span class="n">n_trials</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">condition</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">conditions</span><span class="p">):</span>
        <span class="c1"># Create condition-specific neural pattern</span>
        <span class="n">pattern</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">)</span>
        <span class="n">active_neurons</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">pattern</span><span class="p">[</span><span class="n">active_neurons</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span>
        
        <span class="c1"># Add pattern to neural activity with temporal dynamics</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_timepoints</span><span class="p">):</span>
            <span class="k">if</span> <span class="mi">200</span> <span class="o">&lt;=</span> <span class="n">t</span> <span class="o">&lt;</span> <span class="mi">700</span><span class="p">:</span>  <span class="c1"># Active during middle of trial</span>
                <span class="n">scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">((</span><span class="n">t</span> <span class="o">-</span> <span class="mi">200</span><span class="p">)</span> <span class="o">/</span> <span class="mi">500</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">*</span> <span class="mi">3</span>  <span class="c1"># Modulation</span>
                <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="n">t</span><span class="p">]</span> <span class="o">+=</span> <span class="n">pattern</span> <span class="o">*</span> <span class="n">scale</span>
    
    <span class="c1"># Add trial-to-trial variability</span>
    <span class="n">data</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_trials</span><span class="p">,</span> <span class="n">n_neurons</span><span class="p">,</span> <span class="n">n_timepoints</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.2</span>
    
    <span class="c1"># Create behavior data (e.g., reaction times)</span>
    <span class="n">behavior</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_trials</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">condition</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">conditions</span><span class="p">):</span>
        <span class="c1"># Condition affects reaction time</span>
        <span class="n">behavior</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">+</span> <span class="n">condition</span> <span class="o">*</span> <span class="mf">0.1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">()</span> <span class="o">*</span> <span class="mf">0.1</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Data loaded: </span><span class="si">{</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> (trials, neurons, time)&quot;</span><span class="p">)</span>
    
    <span class="c1"># 1. Basic neural analysis</span>
    
    <span class="c1"># Calculate trial-averaged firing rates</span>
    <span class="n">condition_avg</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_conditions</span><span class="p">,</span> <span class="n">n_neurons</span><span class="p">,</span> <span class="n">n_timepoints</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_conditions</span><span class="p">):</span>
        <span class="n">condition_idx</span> <span class="o">=</span> <span class="n">conditions</span> <span class="o">==</span> <span class="n">c</span>
        <span class="n">condition_avg</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">condition_idx</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    
    <span class="c1"># Plot average firing rates for selected neurons</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
    <span class="n">selected_neurons</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">n_neurons</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">neuron_idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">selected_neurons</span><span class="p">):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_conditions</span><span class="p">):</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">condition_avg</span><span class="p">[</span><span class="n">c</span><span class="p">,</span> <span class="n">neuron_idx</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Condition </span><span class="si">{</span><span class="n">c</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Neuron </span><span class="si">{</span><span class="n">neuron_idx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Trial-averaged firing rates&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Time (ms)&quot;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;firing_rates.png&quot;</span><span class="p">)</span>
    
    <span class="c1"># 2. Dimensionality reduction</span>
    
    <span class="c1"># Reshape data for PCA [trials*time, neurons]</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_neurons</span><span class="p">)</span>
    
    <span class="c1"># Run PCA</span>
    <span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">X_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    
    <span class="c1"># Reshape back to [trials, time, components]</span>
    <span class="n">X_pca</span> <span class="o">=</span> <span class="n">X_pca</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">n_trials</span><span class="p">,</span> <span class="n">n_timepoints</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
    
    <span class="c1"># Plot top 3 PCs for different conditions</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_conditions</span><span class="p">):</span>
        <span class="n">condition_idx</span> <span class="o">=</span> <span class="n">conditions</span> <span class="o">==</span> <span class="n">c</span>
        <span class="n">X_c</span> <span class="o">=</span> <span class="n">X_pca</span><span class="p">[</span><span class="n">condition_idx</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Average across trials</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">c</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">pc</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_c</span><span class="p">[:,</span> <span class="n">pc</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;PC</span><span class="si">{</span><span class="n">pc</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Condition </span><span class="si">{</span><span class="n">c</span><span class="si">}</span><span class="s2"> - Top 3 PCs&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;PC Value&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">c</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">c</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Time (ms)&quot;</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;pca_analysis.png&quot;</span><span class="p">)</span>
    
    <span class="c1"># 3. Neural decoding</span>
    
    <span class="c1"># Prepare data for decoding (use middle timepoint activity)</span>
    <span class="n">middle_idx</span> <span class="o">=</span> <span class="n">n_timepoints</span> <span class="o">//</span> <span class="mi">2</span>
    <span class="n">X_decode</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">middle_idx</span><span class="p">]</span>  <span class="c1"># [trials, neurons]</span>
    <span class="n">y_decode</span> <span class="o">=</span> <span class="n">conditions</span>
    
    <span class="c1"># Split into train/test</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
        <span class="n">X_decode</span><span class="p">,</span> <span class="n">y_decode</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
    <span class="p">)</span>
    
    <span class="c1"># Simple decoder (multinomial logistic regression)</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LogisticRegression</span>
    <span class="n">decoder</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">multi_class</span><span class="o">=</span><span class="s1">&#39;multinomial&#39;</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">)</span>
    <span class="n">decoder</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    
    <span class="c1"># Evaluate</span>
    <span class="n">train_score</span> <span class="o">=</span> <span class="n">decoder</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">test_score</span> <span class="o">=</span> <span class="n">decoder</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Decoding accuracy - Train: </span><span class="si">{</span><span class="n">train_score</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">, Test: </span><span class="si">{</span><span class="n">test_score</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="c1"># Identify most informative neurons</span>
    <span class="n">coef</span> <span class="o">=</span> <span class="n">decoder</span><span class="o">.</span><span class="n">coef_</span>  <span class="c1"># [classes, features]</span>
    <span class="n">importance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">coef</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Sum across classes</span>
    <span class="n">top_neurons</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">importance</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">][:</span><span class="mi">10</span><span class="p">]</span>  <span class="c1"># Top 10 neurons</span>
    
    <span class="c1"># 4. Dynamic neural trajectory visualization</span>
    
    <span class="c1"># Use t-SNE to visualize neural dynamics</span>
    <span class="c1"># Get trial-averaged activity for each condition</span>
    <span class="n">X_tsne</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_conditions</span> <span class="o">*</span> <span class="n">n_timepoints</span><span class="p">,</span> <span class="n">n_neurons</span><span class="p">))</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_conditions</span> <span class="o">*</span> <span class="n">n_timepoints</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_conditions</span><span class="p">):</span>
        <span class="n">X_tsne</span><span class="p">[</span><span class="n">c</span> <span class="o">*</span> <span class="n">n_timepoints</span><span class="p">:(</span><span class="n">c</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">n_timepoints</span><span class="p">]</span> <span class="o">=</span> <span class="n">condition_avg</span><span class="p">[</span><span class="n">c</span><span class="p">]</span><span class="o">.</span><span class="n">T</span>  <span class="c1"># [time, neurons]</span>
        <span class="n">labels</span><span class="p">[</span><span class="n">c</span> <span class="o">*</span> <span class="n">n_timepoints</span><span class="p">:(</span><span class="n">c</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">n_timepoints</span><span class="p">]</span> <span class="o">=</span> <span class="n">c</span>
    
    <span class="c1"># Run t-SNE</span>
    <span class="n">tsne</span> <span class="o">=</span> <span class="n">TSNE</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">X_embedded</span> <span class="o">=</span> <span class="n">tsne</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_tsne</span><span class="p">)</span>
    
    <span class="c1"># Plot trajectories</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
    <span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="s1">&#39;purple&#39;</span><span class="p">,</span> <span class="s1">&#39;orange&#39;</span><span class="p">]</span>
    
    <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_conditions</span><span class="p">):</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">labels</span> <span class="o">==</span> <span class="n">c</span>
        <span class="n">traj</span> <span class="o">=</span> <span class="n">X_embedded</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">traj</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">traj</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;o-&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">c</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> 
                 <span class="n">markersize</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Condition </span><span class="si">{</span><span class="n">c</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        
        <span class="c1"># Mark start and end points</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">traj</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">traj</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">c</span><span class="p">],</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">traj</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">traj</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;s&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">c</span><span class="p">],</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Neural Trajectories in t-SNE Space&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;neural_trajectories.png&quot;</span><span class="p">)</span>
    
    <span class="c1"># 5. Behavior prediction</span>
    
    <span class="c1"># Try to predict behavior from neural activity</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">Ridge</span>
    
    <span class="c1"># Use average firing rates in the middle 200ms</span>
    <span class="n">mid_start</span><span class="p">,</span> <span class="n">mid_end</span> <span class="o">=</span> <span class="n">n_timepoints</span><span class="o">//</span><span class="mi">2</span> <span class="o">-</span> <span class="mi">100</span><span class="p">,</span> <span class="n">n_timepoints</span><span class="o">//</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">100</span>
    <span class="n">X_behavior</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">mid_start</span><span class="p">:</span><span class="n">mid_end</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># [trials, neurons]</span>
    
    <span class="c1"># Split data</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
        <span class="n">X_behavior</span><span class="p">,</span> <span class="n">behavior</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
    <span class="p">)</span>
    
    <span class="c1"># Train ridge regression</span>
    <span class="n">regressor</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
    <span class="n">regressor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    
    <span class="c1"># Predict and evaluate</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">r2_score</span>
    <span class="n">r2</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Behavior prediction R² score: </span><span class="si">{</span><span class="n">r2</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="c1"># Plot predictions vs actual</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="nb">min</span><span class="p">(</span><span class="n">y_test</span><span class="p">),</span> <span class="nb">max</span><span class="p">(</span><span class="n">y_test</span><span class="p">)],</span> <span class="p">[</span><span class="nb">min</span><span class="p">(</span><span class="n">y_test</span><span class="p">),</span> <span class="nb">max</span><span class="p">(</span><span class="n">y_test</span><span class="p">)],</span> <span class="s1">&#39;k--&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Actual Behavior&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Predicted Behavior&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Neural Prediction of Behavior (R² = </span><span class="si">{</span><span class="n">r2</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;behavior_prediction.png&quot;</span><span class="p">)</span>
    
    <span class="c1"># Return results</span>
    <span class="n">results</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;n_neurons&quot;</span><span class="p">:</span> <span class="n">n_neurons</span><span class="p">,</span>
        <span class="s2">&quot;n_trials&quot;</span><span class="p">:</span> <span class="n">n_trials</span><span class="p">,</span>
        <span class="s2">&quot;n_conditions&quot;</span><span class="p">:</span> <span class="n">n_conditions</span><span class="p">,</span>
        <span class="s2">&quot;decoding_accuracy&quot;</span><span class="p">:</span> <span class="n">test_score</span><span class="p">,</span>
        <span class="s2">&quot;behavior_prediction_r2&quot;</span><span class="p">:</span> <span class="n">r2</span><span class="p">,</span>
        <span class="s2">&quot;top_neurons&quot;</span><span class="p">:</span> <span class="n">top_neurons</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span>
        <span class="s2">&quot;pca_explained_variance&quot;</span><span class="p">:</span> <span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
    <span class="p">}</span>
    
    <span class="k">return</span> <span class="n">results</span>
</pre></div>
</div>
</section>
<section id="take-aways">
<h2>21.7 Take-aways<a class="headerlink" href="#take-aways" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><strong>AI techniques are transforming neural data analysis</strong>, enabling the extraction of meaningful patterns from complex recordings of brain activity.</p></li>
<li><p><strong>Deep learning models make powerful decoders</strong> that can predict behavior, perception, and cognitive states from neural activity.</p></li>
<li><p><strong>Dimensionality reduction reveals low-dimensional neural manifolds</strong> that capture the essential dynamics of neural population activity.</p></li>
<li><p><strong>Computational simulations advance our understanding</strong> of how neural circuits process information and generate behavior.</p></li>
<li><p><strong>AI-powered connectome reconstruction</strong> is mapping the brain’s wiring diagram at multiple scales, from synapses to large-scale networks.</p></li>
<li><p><strong>Neuromorphic computing applies brain-inspired principles</strong> to create more efficient and adaptive AI systems.</p></li>
</ul>
</section>
<section id="further-reading">
<h2>21.8 Further Reading<a class="headerlink" href="#further-reading" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Richards, B.A., et al. (2019). <a class="reference external" href="https://www.nature.com/articles/s41593-019-0520-2">A deep learning framework for neuroscience</a>. Nature Neuroscience, 22(11), 1761-1770.</p></li>
<li><p>Glaser, J.I., et al. (2020). <a class="reference external" href="https://eneuro.org/content/7/4/ENEURO.0506-19.2020">Machine learning for neural decoding</a>. eNeuro, 7(4).</p></li>
<li><p>Pandarinath, C., et al. (2018). <a class="reference external" href="https://www.nature.com/articles/s41592-018-0109-9">Inferring single-trial neural population dynamics using sequential auto-encoders</a>. Nature Methods, 15(10), 805-815.</p></li>
<li><p>Helmstaedter, M., et al. (2013). <a class="reference external" href="https://www.nature.com/articles/nature12346">Connectomic reconstruction of the inner plexiform layer in the mouse retina</a>. Nature, 500(7461), 168-174.</p></li>
<li><p>Berman, G.J., et al. (2016). <a class="reference external" href="https://www.pnas.org/content/113/42/11943">Predictability and hierarchy in Drosophila behavior</a>. PNAS, 113(42), 11943-11948.</p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "executablebooks/jupyter-book",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./part6"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="rise_slides_demo.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Creating Presentations with RISE</p>
      </div>
    </a>
    <a class="right-next"
       href="ch22_embodied_ai_robotics.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Chapter 22: Embodied AI and Robotics</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#chapter-goals">21.0 Chapter Goals</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#neural-data-analysis-with-deep-learning">21.1 Neural Data Analysis with Deep Learning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#decoding-neural-activity">21.1.1 Decoding Neural Activity</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dimensionality-reduction-for-neural-data">21.1.2 Dimensionality Reduction for Neural Data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#time-series-analysis-for-neural-dynamics">21.1.3 Time Series Analysis for Neural Dynamics</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#brain-simulation-efforts">21.2 Brain Simulation Efforts</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#large-scale-neural-circuit-simulations">21.2.1 Large-Scale Neural Circuit Simulations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#brain-region-models">21.2.2 Brain Region Models</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#connectome-reconstruction">21.3 Connectome Reconstruction</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#electron-microscopy-analysis">21.3.1 Electron Microscopy Analysis</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#macro-scale-connectomics">21.3.2 Macro-Scale Connectomics</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#theory-development-through-modeling">21.4 Theory Development through Modeling</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#computational-models-of-cognition">21.4.1 Computational Models of Cognition</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#neural-circuit-mechanisms">21.4.2 Neural Circuit Mechanisms</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#neuromorphic-applications">21.5 Neuromorphic Applications</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#brain-inspired-learning-rules">21.5.1 Brain-Inspired Learning Rules</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#code-lab-neural-data-analysis">21.6 Code Lab: Neural Data Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#take-aways">21.7 Take-aways</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#further-reading">21.8 Further Reading</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Richard Young
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2025.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>